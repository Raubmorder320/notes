# Определитель

Порядок перестановки -- наименьшее общее кратное длин циклов, отвечающих этой перестановке
## Знак перестановки
Текущая глава будет посвящена определителям. Как известно из курса аналитической геометрии, определитель матрицы из $\mathbb{R}^n$ равен ориентированному объёму параллелепипеда на векторах строк данной матрицы. Иными словами можно сказать, что определитель -- это объём со знаком. Проблема встаёт с выбором этого знака.

**Группа перестановок**
Группой перестановок называют множество $S_n$ различных **биективных** отображений вида $s: \{1,2,...n\} \rightarrow \{1,2,...n\}$. Операция в данной группе -- композиция отображений. Перестановки принято записывать в виде:
$$\begin{bmatrix}1&2&3&4\\ 3&4&2&1\end{bmatrix}$$
В дальнейшем нам потребуются говорить про знак (чётность и нечётность) перестановок. Введём следующие обозначения
Пусть есть гомоморфизм $\alpha: S_n \rightarrow \{-1,1\} = \mathbb{Z}^*$. Определим в таком случае перестановку, отображающуюся в 1, как чётную, а в -1, как нечётную.

**Транспозиция**
Рассмотрим перестановку $t_{ij} \in S_n$, в которой два элемента i и j меняются местами, а все остальные элементы остаются на месте. (Пример: $t_{0,1}$ = (1,2,3,4) -> (2,1,3,4)). Такая перестановка называется транспозицией. Если транспозиция меняет местами два соседних элемента, то она называется элементарной.

**Предложение**
Любую перестановку можно представить в виде композиции элементарных транспозиций.
**Доказательство**
1. Заметим, что композиция с элементарной транспозицией просто меняет положение элемента в образе перестановки:
   Пусть $s: (1,...,n)\longrightarrow (s(1),...,s(i),s(j),...,s(n))$
   Применим композицию: $s\circ t_{ij} = (1,...,i,j,...,n)\longrightarrow (1,...,j,i,...,n)\longrightarrow (s(1),...,s(j),s(i),...,s(n))$
   То есть мы просто поменяли местами элементы в $Im(s)$.
2. Введём индукцию по n. Пусть n = 2. Представимость очевидна (перестановок две, одна из них легко представима через другую). Теперь рассмотрим $s:(1,...,n)\longrightarrow (s(1),...s(l-1),1,s(l+1),...,n)$, то есть 1 = s(l). Композицией с элементарными транспозициями ($t_{l,l-1}\circ t_{l-1,l-2}\circ ...\circ t_{1,2}$) мы "перекинем" эту единицу из образа s "в начало" так, что получится: 1 = s(1).
3. Делаем теперь индукционный переход. Сузим отображение s на оставшиеся элементы, которые мы ещё не перевели: $s|_{\{2,3,...,n\}}: \{2,3,...,n\}\longrightarrow \{2,3,...,n\}$ (мы не совсем "по определению" сужаем ещё и область значений. Мы имеем право так делать, потому что после предыдущей серии композиций мы удостоверились, что если q < 2, то и s(q) < 2. Таким образом мы также научились рассматривать перестановки из $S_{n}$, которые переводят 1 -> 1, как перестановки $S_{n-1}$). При этом получившуюся $S_{n-1}$ можно представить в виде композиции элементарных транспозиций по ИП. Получаем s -> id -> s. Важно отметить, что $t_{ij}^{-1} = t_{ij}$.

Получим одно из определений знака перестановки: Если в данном разложении перестановки получится чётное число сомножителей, то она чётная, если нечётное, соотвественно, нечётное. Однако данное разложение неединственно и нужно доказывать корректность определения.

Перед доказательством важной теоремы рассмотрим ещё лемму:
**Лемма 1**
Возьмём случайную транспозицию и домножим её слева и справа на взаимно обратные перестановки (в теории групп такое действие называется сопряжением). Получим транспозицию, при этом такую, что она меняет элементы g(i) и g(j) местами: $$g\circ t_{ij}\circ g^{-1} = t_{g(i),g(j)}$$
В частности:
$$\exists g:\;g\circ t_{1,2}\circ g^{-1} = t_{i,j}$$
**Доказательство**
Производим вычисление явным образом
1. Вычислим $(g\circ t_{ij}\circ g^{-1})(g(i)) = (g\circ t_{ij})(g^{-1}(g(i))) = (g\circ t_{ij})(i) = g(j)$
2. Аналогично получим, что $(g\circ t_{ij}\circ g^{-1})(g(j)) = g(i)$
3. Для $k \neq g(i),g(j)$: $(g\circ t_{ij}\circ g^{-1})(g(k)) = (g\circ t_{ij})(k) = g(k)$
Последнее же является частным случаем доказанного

**Теорема**
Существует единственный нетривиальный гомоморфизм $\alpha$.
**Единственность**
Покажем, что если $\alpha: S_n \rightarrow \mathbb{Z}^*$ является гомоморфизмом, то $\alpha(s) = (-1)^r$, где r -- количество сомножителей в разложении на транспозиции (уже не обязательно элементарные)
1. Раз $\alpha$ является гомоморфизмом, то $\alpha(s^{-1}\circ s) = \alpha(s^{-1})\alpha(s) = \alpha(id) = 1$, а значит $\alpha(s^{-1})=\alpha(s)$. Получается, что $\alpha(s\circ t\circ s^{-1}) = \alpha(s)\alpha(t)\alpha(s^{-1})= \alpha(t)$
2. При этом мы знаем, что $\alpha(t_{1,2}) = \alpha(t_{ij})$\[1]. Получится, что $\alpha(t)=1$ или $\alpha(t) = -1$. В первом случае (по предложению) получим тривиальный гомоморфизм. Во втором -- идентичность всех гомоморфизмов и их форма в виде $(-1)^r$ в случае наличия представления
**Существование**
Построим такой гомоморфизм. Как известно, он единственный. Для чёткости мы его обозначим специальным образом:$$\text{sgn}(s): S_n\rightarrow \mathbb{Z}^*$$
1. Рассмотрим кольцо $\mathbb{Z}[x_1, x_2, ..., x_n$]. Если задана некоторая перестановка $s\in S_n$, то можно перенумеровать многочлены в соответствии с ней, то есть $^sf: \mathbb{Z}[x_1,...,x_n]\rightarrow \mathbb{Z}[x_1,...,x_n]$, в котором $f(x_1,...,x_n)\longrightarrow ^sf(x_{s(1)},...,x_{s(n)})$.
2. Такое отображение является автоморфизмом (гомоморфизмом самого на себя). (очевидно)
3. $^t(^sf) = ^{(ts)}f$. Доказательство: Пусть $(^sf) = g$. $^tg = g(x_{t(1)},...,x_{t(n)}) = ^sf(x_{t(1)},...,x_{t(n)}) = f(x_{t(s(1))},...,x_{t(s(n))}) = f(x_{t\circ s(1)},...,x_{t\circ s(n)}) = ^{(ts)}f$. 
4. Рассмотрим кососимметричный многочлен: $V(x_1, ..., x_n) = \prod_{i<j} (x_i - x_j)$. Пример такого многочлена: $V(x_1, x_2, x_3) = (x_1 - x_2)(x_1 - x_3)(x_2 - x_3)$. Очевидно, что $V\times V$ будет уже симметричным
5. Заметим, что $^sV = \prod_{i<j}(x_{s(i)} - x_{s(j)}) = \pm V$. Тогда положим $\text{sgn}(s): ^sV = \text{sgn}(s)V$. По вышесказанному получится, что: $\text{sgn}(ts)V = ^{(ts)}V = \text{sgn}(t)\text{sgn}(s)V$, 
6. Пусть i<j. Тогда $(x_{s(i)} - x_{s(j)})$ входит в $V$ с тем же знаком, что и в $^sV$, если $s(i)<s(j)$, а иначе -- с противоположным. Получается, что $\frac{^sV}{V} = \frac{\prod_{i<j}(x_{s(i)} - x_{s(j)})}{\prod_{i<j}E_{ij}(x_{s(i)} - x_{s(j)})} = \prod_{i<j}E_{ij} = (-1)^r$, где r -- число инверсий, где $E_{ij} = (1)[s(i) < s(j)] + (-1)[s(i) > s(j)]$ 
**Пояснение**
1. По предыдущей лемме всегда можно отыскать такую перестановку, что $g\circ t_{12}\circ g^{-1}=t_{ij}$. Отсюда и получится, что знак любой транспозиции равен знаку элементарной транспозиции

**Неупорядоченные пары индексов**
Рассмотрим $C_n^2$ неупорядоченных пар индексов. Неупорядоченная пара {i,j} образует инверсию в перестановке $s\in S_n$, если i<j => s(i)>s(j). Количество инверсий = кол-во пар индексов, образующих инверсию. Это количество обозначается как $\text{Inv}(s)$. Знак перестановки: $\text{sgn}(s) = (-1)^{\text{Inv}(s)}$. В качестве упражнения можно доказать связь этой формулы и основной, выведенной формулы $\text{sgn}(s) = (-1)^r$.

**Пример**
Вычислим знак перестановки: $\text{sgn}(s: \{1,2,...,n-1,n\} \longrightarrow \{2,3,...,n,1\})$. Он равен $(-1)^{n-1}$. Посчитать это можно или через число инверсий, или через число транспозиций.
## Определитель. Свойства определителя
В данном курсе будет дано определение определителя через явную формулу. Аксиоматическое определение определителя будет дано на втором курсе.
Исторически определители появились как способы решения системы линейных уравнений.

**Формула полного развёртывания**
$$A\in M_n(R), \;R -\text{ коммутативное кольцо с 1 [хотя технически можно и без неё]}$$
$$\text{Определитель } A= \det(A) = |A| = \sum_{s\in S_n} \text{sgn}(s)a_{1,s(1)}a_{2,s(2)}...a_{n,s(n)}$$
Важно обратить внимание, почему такая сумма по всем перестановкам задаёт значение в единственном виде:
- Выбор n элементов по одному из каждой строчки и каждого столбца задаёт биективное отображение из множества строчек в множество столбцов. Раз так, то договоримся обозначать эту биекцию s(i) (i --> s(i), то есть на i строке мы выбрали элемент, который принадлежит s(i) столбцу).

**Пример**
- Известный из курса аналитической геометрии определитель матрицы 2х2: $$\det(A_{\in M_2(R)}) = \text{sgn}(s:\{1,2\}\longrightarrow\{1.2\})a_{11}a_{22} + \text{sgn}(s:\{1,2\}\longrightarrow\{2,1\})a_{12}a_{21} = a_{11}a_{22} - a_{12}a_{21}$$
- Также известный рисунок определителя матрицы 3х3. Рассмотрим лишь одну из данных перестановок: $s:\{1,2,3\}\longrightarrow\{3,1,2\}$. Данная перестановка задаёт цикл длины три, что, как было показано в предыдущем параграфе, даст знак $(-1)^{3-1} = 1$. В результате получится слагаемое $$\text{sgn}(s)a_{13}a_{21}a_{32} = +a_{13}a_{21}a_{32}$$
  ![[Pasted image 20240219014319.png]]
- Важно, что никаких "простых" рисунков вроде рисунка для матрицы 3х3 и 2х2 для матриц больших порядков не существует. Там нужно "честно" считать знаки через перестановки

**Свойства определителя**
1. $\det A^T = \det A$
В прошлом параграфе было доказано, что $sgn(s^{-1})=sgn(s)$. После транспонирования матрицы: $\det A^T = \sum_{s\in S_n} \text{sgn}(s)a_{s(1),1}...a_{s(n),n} = \sum_{s^{-1}\in S_n} \text{sgn}(s)a_{1,s^{-1}(1)}...a_{1,s^{-1}(n)} = \det A$.
2. Линейность по каждой строчке: Пусть по данной матрице А построено две другие матрицы A' и A'', что i-ая строчка Aio = A'io + A''io, остальные строчки Ako = A'ko = A''ko. Тогда $detA = detA'+detA''$. Аналогично для умножения на скаляр: если есть две матрицы А и А', где все строчки кроме i-й равны, а i-ая строчка матрицы A' равна i-й строчке матрицы А, умноженной на $\lambda$, то $det A' = \lambda det A$
Доказательство напрямую через формулу. Следствием этого же доказательства является то, что при наличии нулевой строчки определитель матрицы равен нулю. 
Слово "линейность" тут означает следующее: представим определитель как функцию вида $R^n\times...\times R^n \longrightarrow R$. Тогда при фиксации n-1 строки мы получим функцию от $R^n$, которая должна быть линейным отображением
3. Определитель матрицы с двумя равными строчками равен нулю (кососимметричность определителя). При перестановке двух строчек местами определитель меняет знак
Рассмотрим $S_n\longrightarrow S_n,\;\;s\mapsto s\times t_{ij}$. Это отображение должно поменять знак перестановки:
пусть $A_n = \{s\in S_n\;|\; sgn(s)=1\}$. Тогда $S_n = A_n \cup A_n\times t_{ij}$
Теперь разделим сумму в определителе на две суммы: На сумму по чётным перестановкам и нечётным перестановкам. $detA = \sum_{s\in A_n}a_{1,s(1)}...a_{n,s(n)}-\sum_{s\in A_n}a_{1,st_{ij}(1)}...a_{n,st_{ij}(n)}$. Раз две строчки \[скажем, i и j] равны друг другу, то $a_{j,st_{ij}(j)}=a_{j,s(i)} = a_{i,s(i)}\;\;\land\;\;a_{i,st_{ij}(i)}=a_{i,s(j)}=a_{j,s(j)}$. В остальных случаях (не i, не j строка) ничего не меняется. В силу этого оказывается, что произведения, стоящие под знаками суммы, равны. Поэтому получится ноль.

Вторая же часть данного пункта справедлива по следующей причине: Возьмём две матрицы, A и A', которые будут отличаться только тем, что i и j строки A соответствуют j и i строке А'. В таком случае определитель суммы данных матриц равен нулю по равенству двух строк. Раскладывая по линейности получим, что $0=detA + detA'$, откуда следует противоположность их знаков и равенство по модулю.
4. Определитель матрицы, в которой одна из строк является линейной комбинацией других строк, равен нулю
Это потому, что такую матрицу можно элементарными преобразованиями (которые не меняют определитель) свести к матрице с нулевой строкой 
## Билинейные отображения. Теорема единственности
**Замечание относительно кососимметричности**:
$V,W$ -- векторные пространства над полем $F$.
$$\displaylines{f:V\times V\rightarrow W \;\;\text{Билинейно}:= \text{$f$ линейно по обоим аргументам:}\\
\begin{aligned} \forall v_1,v'_1,v_2,v'_2\in V:f(\alpha v_1+v'_1,v_2)&=\alpha f(v_1,v_2)+f(v'_1,v_2)\\
f(v_1,\alpha v_2 + v'_2)&=\alpha f(v_1,v_2)+f(v_1,v'_2)\end{aligned}}$$
Оказывается, что оба свойства кососимметричности практически идентичны друг другу:
1. Билинейное отображение называется **кососимметричным**, если $\forall v\in V:f(v,v)=0$. Из этого следует, что $\forall u,v \in V: f(v,u)=-f(u,v)$ (доказательство тривиальное через представление $v$ в определении как суммы двух векторов и раскрытия по билинейности).
2. Обратное следствие верно, если $1+1\ne 0$ в данном поле $F$. Это важно, потому что: $f(v,v)=-f(v,v)\Rightarrow f(v,v)\times(1+1)=0$, где множитель $(1+1)$ должен быть обратимым, чтобы на него можно было сократить и привести его к виду определения. 
Определитель же при этом является полилинейным \[аналогично билинейному можно определить трилинейное и т.д. отображение, которое сводится к билинейному фиксированием некоторых переменных] отображением (уже доказано, когда говорили про линейность) над V -- пространством строк. При этом при фиксировании всех аргументах, кроме двух, получится билинейное отображение.  
Иначе:
- Пусть $V = F^n$ - пространство строк. Тогда $(v_1,v_2,...,v_n)\in V\times V\times ...\times V$ задаёт матрицу с данными строками, то есть между данным декартовым пространством пространств строк и множеством матриц существует биекция. А по данной матрице мы вычисляем (как отображение) определитель как элемент из $W$

**Теорема единственности**
$$\begin{aligned}
1.&V=F^n\\
2.&f:V\times\text{n раз, сколько в $F^n$}...\times V\longrightarrow F\\
3.&\text{$f$ полилинейно}\\
4.&\text{$f$ кососимметрично}\\
5.&\text{$f(E_n)$=1}\end{aligned}
\;\;\Rightarrow\;\;\forall A\in M_n(F):\;\;f(A)=\det A $$

**Пояснение**
- Существование определителя доказано выше тем, что мы его отдельно определяли. 
- Сами действия с таким отображением можно представить как некоторого рода умножение между векторами, то есть как некоторое подобие скалярного произведения. 
- Определитель имеет смысл **только для квадратным матриц**.
- Работаем с полем $F$. Вообще говоря, определение определителя матрицы даётся на коммутативным кольцом, что не сильно меняет ход рассуждений.
**Доказательство**
Рассмотрим некоторое $A$. $v_j = a_{j1}e_1 + ... + a_{jn}e_n$ - j-ая строка данной матрицы, где $e_i = (0,...,\overset{i}{1},...,0)$ -- элемент стандартного базиса пространства строчек. Пусть $f$ - полилинейное кососимметричное отображение. Тогда: $f(A)=f(v_1,...,v_n)=f(...,a_{j1}e_1+...+a_{jn}e_n,...)$. Раскрывая по полилинейности данное равенство получаем: $\sum_{i_1,i_2,...,i_n=1}^na_{i_1}...a_{i_n}f(e_{i_1},...,e_{i_n})$. ($n^n$ слагаемых). Однако, по кососимметричности, если два индекса равны друг другу, то результат работы равен нулю (потому что будут два одинаковых $e_{i_k}$ как аргументы $f$, что и даст ноль). Иными словами мы получим:
$$\sum_{s\in S,s=\begin{bmatrix}1&2&...&n\\i_1&i_2&...&i_n\end{bmatrix}}a_{1,s(1)}...a_{n,s(n)}f(e_{s(1)},...,e_{s(n)})$$
При этом достаточно очевидно (по кососимметричности, при транспозиции элементов значение меняется на -1), что $f(e_{s(1)},...,e_{s(n)})=sgn(s)f(e_{1},...,e_{n})$. Это можно доказать также индукцией по количеству сомножителей транспозиций, на которые раскладывается $s$
- База индукции: если $s$ -- одна транспозиция, то всё получается напрямую по кососиммеричности.
- Далее оказывается, что при представлении $s$ через $s'\times t_{ij}$ знак перестановки вместе со знаком самой функции меняется на противоположный. Следовательно, это происходит при любой перестановке.
Таким образом:
$$\displaylines{\sum_{s\in S,s=\begin{bmatrix}1&2&...&n\\i_1&i_2&...&i_n\end{bmatrix}}a_{1,s(1)}...a_{n,s(n)}f(e_{s(1)},...,e_{s(n)})=\sum_{s\in S}a_{1,s(1)}...a_{n,s(n)}sgn(s)f(e_1,...,e_n)=\\
=\sum_{s\in S}a_{1,s(1)}...a_{n,s(n)}sgn(s)f(E)=\sum_{s\in S}a_{1,s(1)}...a_{n,s(n)}sgn(s)}$$
## Минор. Разложение определителя по минорам
Рассмотрим следующие свойства определителя:
**Свойство 0**
$$det
\begin{bmatrix}
a_{11}&X&X&...&X\\
0&b_{11}&b_{12}&...&b_{1,n-1}\\
0&b_{21}&b_{22}&...&b_{2,n-1}\\
...&...&...&...&...\\
0&b_{n-1,1}&b_{n-1,2}&...&b_{n-1,n-1}
\end{bmatrix}=a_{11}detB$$
**Доказательство**
Это следует напрямую из формулы полного развёртывания.
Для начала, ради удобства, транспонируем матрицу (очевидно что и матрица B транспонируется). Получим матрицу формата $A=\begin{bmatrix}a_{11}&0\\ X&B^T\end{bmatrix}$. Далее:
$$\sum_{s\in S}a_{1,s(1)}...a_{n,s(n)}sgn(s)=\sum_{s\in S,\;s(1)=1}a_{11}...a_{n,s(n)}sgn(s)$$
Также у нас имеется биекция между группой перестановок с фиксированным переходом одного элемента в другой (тут это $s(1)=1$) с группой перестановок с размерностью меньшей на единицу. Пусть это будет перестановки $g\in G=S_{n-1}$. Получим:$$\sum_{s\in S,\;s(1)=1}a_{11}...a_{n,s(n)}sgn(s)=a_{11}\sum_{g\in G=S_{n-1}}b_{1g(1)}...b_{n-1,g(1)}sgn(g)=a_{11}detB^T=a_{11}detB$$
**Определение минора матрицы**
$A\in M_{mn}(R)$. Данная матрица задана на $I\times J = \{1,...,n\}\times\{1,...,m\}$. Тогда определитель подматрицы $A'$ на $\{i_1,...,i_{k}\}_{\subset I}\times \{j_1,...,j_{k}\}_{\subset J}$ (иногда записывается как  $A_{\{i_1,...,i_k\}}^{\{j_1,...,j_k\}}$)называется **минором** размера $k\times k$ матрицы $A$. Если при этом выбросить (из квадратной матрицы размера $n\times n$) $i$ строку и $j$ столбец, то получим минор размера $(n-1)\times (n-1)$, обозначаемый как $M_{ijA}$.

**Свойство 1**
$A\in M_n(R),\;\;i,j\in \{1,...,n\}$. Обозначим:
$$A^{ij}=\displaylines{
\begin{matrix}
&&j
\end{matrix}\\
\begin{matrix}
\;\\\;\\\;\\
i\\\;\\\;\\
\end{matrix}
\begin{bmatrix}
X&X&X&0&X&X\\
X&X&X&0&X&X\\
X&X&X&0&X&X\\
0&0&0&1&0&0\\
X&X&X&0&X&X\\
X&X&X&0&X&X\\
\end{bmatrix}}$$
(Все элементы $A^{ij}$, кроме стоящих на $i$ строке и $j$ столбце совпадают с элементами $A$).
Тогда:
$$detA^{ij}=(-1)^{i+j}M_{ijA}$$
(называется алгебраическим дополнением элемента $a_{ij}$ \[далее в виде $A^{ij}$ будет писаться значение определителя, а не сама матрица]).
**Доказательство**
Переставим $i$ строчку на первое место за $i-1$ транспозиций. Переставим $j$ строчку на первое место за $j-1$ транспозиций. Получим изменение лишь знака определителя, причём изменение вида $(-1)^{i+j-2}=(-1)^{i+j}$. Не учитывая знак определитель равен искомому минору просто по определению и нулевому свойству.
**Замечание**
На самом деле достаточно "обратить в ноль" только элементы строки (столбца), остальное оставить каким угодно. Потому что такую "испорченную" матрицу можно получить из данной элементарными преобразованиями, которые, как известно, не меняют определителя.

**Разложение на миноры**
$$detA = \sum_{j=1}^na_{kj}detA^{kj}$$
Аналогично для столбца
$$detA = \sum_{i=1}^na_{ik}detA^{ik}$$
**Пояснение**
Для простоты запоминания, какой знак у минора брать, можно запомнить картинку, которую называют "шахматной раскраской": $\begin{bmatrix} +&-&+&... \\ -&+&-&... \\ +&-&+&... \\ -&+&-&... \\ ...&...&...&... \\\end{bmatrix}$
**Доказательство**
По определению и свойству линейности:
$$
\displaylines{
det\begin{bmatrix}
X&X&X&X\\
X&X&X&X\\
X&X&X&X\\
X&X&X&X\\
\end{bmatrix} = det
\begin{bmatrix}
a_{11}&X&X&X\\
0&X&X&X\\
0&X&X&X\\
0&X&X&X\\
\end{bmatrix}+det\begin{bmatrix}
0&X&X&X\\
X&X&X&X\\
X&X&X&X\\
X&X&X&X\\
\end{bmatrix} =
\\
= 
det
\begin{bmatrix}
a_{11}&X&X&X\\
0&X&X&X\\
0&X&X&X\\
0&X&X&X\\
\end{bmatrix}+det\begin{bmatrix}
0&a_{12}&X&X\\
X&0&X&X\\
X&0&X&X\\
X&0&X&X\\
\end{bmatrix} + det\begin{bmatrix}
0&0&X&X\\
X&X&X&X\\
X&X&X&X\\
X&X&X&X\\
\end{bmatrix} =
\\
=
det
\begin{bmatrix}
a_{11}&X&X&X\\
0&X&X&X\\
0&X&X&X\\
0&X&X&X\\
\end{bmatrix}+det\begin{bmatrix}
0&a_{12}&X&X\\
X&0&X&X\\
X&0&X&X\\
X&0&X&X\\
\end{bmatrix} + det\begin{bmatrix}
0&0&a_{13}&X\\
X&X&0&X\\
X&X&0&X\\
X&X&0&X\\
\end{bmatrix} + 
det\begin{bmatrix}
0&0&0&X\\
X&X&X&X\\
X&X&X&X\\
X&X&X&X\\
\end{bmatrix}=
\\
det
\begin{bmatrix}
a_{11}&X&X&X\\
0&X&X&X\\
0&X&X&X\\
0&X&X&X\\
\end{bmatrix}+det\begin{bmatrix}
0&a_{12}&X&X\\
X&0&X&X\\
X&0&X&X\\
X&0&X&X\\
\end{bmatrix} + det\begin{bmatrix}
0&0&a_{13}&X\\
X&X&0&X\\
X&X&0&X\\
X&X&0&X\\
\end{bmatrix} + \\ +
det\begin{bmatrix}
0&0&0&a_{14}\\
X&X&X&0\\
X&X&X&0\\
X&X&X&0\\
\end{bmatrix} + 
det\begin{bmatrix}
0&0&0&0\\
X&X&X&X\\
X&X&X&X\\
X&X&X&X\\
\end{bmatrix} = \\ = 
a_{11}detA^{11}+a_{12}detA^{12}+a_{13}detA^{13}+a_14detA^{14}+0
}$$
(тут скорее демонстрация процесса, само доказательство должно быть чуть более общим: в случайной строке, для случайной матрицы и т.д.)
Для разложения по столбцу -- переходим к транспонированной матрице

**Предложение**
Алгебраическое дополнение l-й строки не изменится, если поменять эту строку строку
$$(k\ne l)\;\;\;\;\;\sum a_{ki}A^{li}=0$$
**Доказательство**
В условии мы фактически поменяли l строку на k строку. То есть в матрице теперь две равные строки. То есть теперь определитель матрицы (а ему и равна указанная сумма) равен нулю
## Дополнительные свойства определителя
**Свойство 1**
Определитель треугольной матрицы равен произведению диагональных элементов
$$det
\begin{bmatrix}
a_{11}&X&X&...&X\\
0&a_{22}&X&...&X\\
0&0&a_{33}&...&X\\
...&...&...&...&...\\
0&0&0&...&a_{nn}
\end{bmatrix}=\prod_{i=1}^na_{ii}$$

**Свойство 2**
Определитель блочно-треугольной матрицы равен произведению определителей блоков (на картинке диагональных матриц три, но вообще это общее свойство, соответственно, это обобщение первого свойства: в нём блоки имеют размер 1х1).
$$det
\begin{bmatrix}
A_k&X&X\\
0&A_l&X\\
0&0&A_m\\
\end{bmatrix}=detA_kdetA_ldetA_m$$
**Пояснение**
- Вообще говоря, здесь имеет смысл сначала дать определение блочной матрицы. Изначальное определение (квадратной) матрицы -- это отображение $I\times I\rightarrow R$. Теперь же ты рассмотрим непересекающееся (дизъюнктное) объединение (разбиение) $I=I'\cup I''$. Тогда изначальное декартово произведение превращается в: $I'\times I' \cup I'\times I'' \cup I''\times I' \cup I''\times I''\rightarrow R$, что то же самое, что задание по отдельности отображений $I'\times I''\rightarrow R$ и т.д.
- Также изначальное определение подразумевало отображение в одно множество, то есть каждый элемент матрицы должен был быть элементом некоторого одного кольца. Однако теперь видно, что матрица может быть задана и как отображение в отображение, то есть элементы матрицы могут иметь разную природу. 
**Доказательство свойств**
1. **Первое свойство**. Методом математической индукции по свойству ноль (писал незадолго до минора)
2. **Второе свойство**. Проведём индукцию по размеру блоков. Для блоков 1х1 доказано (свойство 1)
   - (k-1 -> k). Транспонируем матрицу. Получим $A = \begin{bmatrix}A&0 \\ X&B \end{bmatrix}$. Теперь возьмём её определитель и разложим: $\det A = a_{11}\det \begin{bmatrix} \begin{bmatrix}1&...&0\\X&X&X\\X&X&X \end{bmatrix}& 0 \\ X&B \end{bmatrix} + ... + a_{1k}\det \begin{bmatrix} \begin{bmatrix}0&...&1\\X&X&X\\X&X&X \end{bmatrix}& 0 \\ X&B \end{bmatrix} = \sum_{j=0}^k a_{1j} (-1)^{j+1}\det \begin{bmatrix}A^{1j}&0 \\ X&B \end{bmatrix}$ 
   - По индукционному предположению, применённому к определителям из разложения (раз мы удалили строку и столбец, теперь матрица размером на 1 меньше): $\det A = \sum_{j=1}^k a_{1j}\det A^{1j} \det B = \det B (\sum_{j=1}^k a_{1j}\det A^{1j}) = \det B \det A$.
   - Этот пункт доказательства можно сначала провести для матриц с размерами блоков nxn и 1x1, а после для nxn + mxm, "выворачивая" матрицу, то есть переводя с помощью ЭП нижний блок на верх (а верхний -- вниз).
   - Теперь индукция по количеству блоков (изначально на двух рассмотрели). Для перехода достаточно объединить несколько блоков в один большой
## Определитель произведения
**Определитель произведения**
$$A,B\in M_n(F):\;\;\;\;\;\;\;\; \det (AB) = (\det A) (\det B)$$
**Пояснение**
- По некоторой причине это работает и для коммутативного кольца. Однако это отдельное доказательство. Здесь доказываем для поля
- Для лучшего понимания рассматриваем несколько доказательств данного факта
**Первое доказательство**
- Если $A$ обратима, значит, она записывается в виде $A = (\prod V_i)D$, $D$ -- диагональная, где вместо единиц на диагонали стоят какие-то случайные значения. Тогда $\det A = \det (\prod V_j)D = \prod d_i$. Тогда $\det AB = \det (\prod V_j)(DB) = \det DB = \prod d_i \det B = \det A \det B$
- Если А не обратима, то она не может быть сведена к полноценному ступенчатому виду. Это означает, что элементарными преобразованиями она сводится к матрице с нулевой строчкой. То есть имеет определитель, равный нулю. Тогда всё произведение определителей равно нулю. С другой стороны, произведение такой необратимой матрицы тоже даст необратимую матрицу. Тогда получится ноль и в определителе произведения
**Второе доказательство**
- Рассмотрим функцию: $f(X)=f(X_{1,\circ},...,X_{n,\circ}) = \det (XB)$. Это полилинейная, кососимметричная функция (кососимметрия: произведение Х на В, если у Х две строки одинаковы, даст также одинаковые две строки, то есть определитель ноль; полилинейность очевидна из полилинейности определителя \[не забываем, что надо отработать произведение, что достаточно просто, и что надо сказать про умножение на скаляр, что тоже просто])
- По теореме о единственности: $f(X) = \det X f(E) \Rightarrow \det (XB) = \det (X) \det (EB)$.
**Третье полу-доказательство (для комм кольца R)**
- Рассмотрим вспомогательную блочную матриц`у размера 2n на 2n $\begin{bmatrix} E&A \\ B&0 \end{bmatrix}$. Её определитель равен: $\det Z = (-1)^n det \begin{bmatrix} A&E \\ 0&B \end{bmatrix} = \det A \det B$. С другой стороны, элементарными преобразованиями она приводится к виду $\begin{bmatrix} E&A \\ 0&-BA \end{bmatrix}$, определитель которой равен $(-1)^n \det BA$.
## Присоединённая (взаимная) матрица. Формулы Крамера
Рассмотрим следующую матрицу:
$$\displaylines{\begin{bmatrix}\
a_{11}&...&a_{1n}\\
...&...&...\\
a_{n1}&...&a_{nn}
\end{bmatrix}
\times
\begin{bmatrix}\
A^{11}&...&A^{n1}\\
...&...&...\\
A^{1n}&...&A^{nn}
\end{bmatrix}
=
\begin{bmatrix}\
\sum_{j=1}^na_{1j}A^{1j}&...&\sum_{j=1}^na_{1j}A^{nj}\\
...&...&...\\
\sum_{j=1}^na_{nj}A^{1j}&...&\sum_{j=1}^na_{nj}A^{nj}
\end{bmatrix}
=
\begin{bmatrix}\
\det A&...&0\\
...&...&...\\
0&...&\det A
\end{bmatrix}
= \\\\ =(\det A)\times E
}
$$
(разложение по столбцам выглядит похожим образом, только домножается слева)
Матрица, на которую мы умножали исходную (матрица, _транспонированная_ от матрицы, составленной из алгебраических дополнений) называется присоединённой к (взаимной с) матрице $A$. Обозначение: $\text{adj} A$ или $\tilde{A}$. Формула: $\tilde{a}_{ij}=A_{ji}$. То есть сейчас было продемонстрировано, что:$$A\times \tilde{A} = \tilde{A}\times A = (\det A)\times E$$
**Следствие**
Если $A\in M_n(R)$ над коммутативным кольцом, то:
$$\det A \in R^* \Rightarrow\exists\;A^{-1}\in M_n(R):\;\;A^{-1}=(\det A)^{-1} (\text{adj}A)$$
**В том числе (для матриц 2х2)**
$$\begin{bmatrix}\
a&b\\
c&d\\
\end{bmatrix}^{-1}
=
\frac{1}{ad-bc}
\begin{bmatrix}\
d&-b\\
-c&a\\
\end{bmatrix}$$

**Следствие из теоремы об определителе произведения (обратное утверждение)**
$$\exists A^{-1}\in M_n(R)\;\Rightarrow\;(\det A) \in R^*$$
**Доказательство**
$AB=E\;\Rightarrow\;\det A \det B = 1\;\Rightarrow\; (\det A)^{-1}=\det B$

**Формулы Крамера** для решения СЛУ:
$$\displaylines{A\overline{x}=\overline{b} \text{ имеет единственное решение} \Rightarrow \overline{x}=A^{-1}\overline{b}=(\det A)^{-1} \times(\text{adj}A)\times \overline{b}\\\Longrightarrow x_i=\frac{\sum_{j=1}^n b_jA^{ji}}{\det A}=\frac{\text{Определитель матрицы $A$, где $i$-ый столбец заменён на $\overline{b}$}}{\det A}=\frac{\Delta_k}{\Delta}
}$$
## Определитель Вандермонда
**Мотивация**
Возникает, когда мы решаем интерполяционную задачу:
$$\begin{aligned}
1.&\;\;p(x)\in \mathbb{F}[x]\\
2.&\;\;\deg p \le n-1\\
3.&\;\;\text{Заданы: } p(x_1)=b_1,p(x_2)=b_2,...,p(x_n)=b_n
\end{aligned}$$
Записывается это как:
$$\begin{cases}
\;a_0+a_1X+...+a_nX^{n-1}=b_1 \\
\; a_0+a_1X+...+a_nX^{n-1}=b_2 \\
\;...\\
\; a_0+a_1X+...+a_nX^{n-1}=b_n \\
\end{cases}
\Rightarrow
\begin{bmatrix}
1&x_1&x_1^2&...&x_1^{n-1}\\
1&x_2&x_2^2&...&x_2^{n-1}\\
...&...&...&...&...\\
1&x_n&x_n^2&...&x_n^{n-1}\\
\end{bmatrix}
\begin{bmatrix}
a_0\\
a_1\\
...\\
a_n\\
\end{bmatrix}
=
\begin{bmatrix}
b_0\\
b_1\\
...\\
b_n\\
\end{bmatrix}$$
Нам требуется найти искомые коэффициенты. По правилу Крамера, нам необходимо для этого высчитать определитель матрицы коэффициентов
**Теорема**
Оказывается, что:
$$\det\begin{bmatrix}
1&1&...&1\\
x_1&x_2&...&x_n\\
...&...&...&...\\
x_1^{n-1}&...&...&x_n^{n-1}
\end{bmatrix}
=\prod_{1\le i<j\le n}(x_i-x_j)
$$
**Доказательство**
- Докажем по индукции. База тривиальна. 
- Вычтем из каждой строчки предыдущую, домноженную на $x_1$, начиная снизу. Получим, что первый столбец определителя превратился в почти-нулевой:$$\displaylines{\det\begin{bmatrix}
1&1&...&1\\
x_1&x_2&...&x_n\\
...&...&...&...\\
x_1^{n-1}&...&...&x_n^{n-1}
\end{bmatrix}\Longrightarrow
\det\begin{bmatrix}
1&1&...&1\\
0&x_2-x_1&...&x_n-x_1\\
...&...&...&...\\
0&x_2^{n-1}-x_1x_2^{n-2}&...&x_n^{n-1}-x_1x_n^{n-2}
\end{bmatrix}\Longrightarrow
\\\\
\Longrightarrow
\det\begin{bmatrix}
1&1&.&1\\
0&x_2-x_1&.&x_n-x_1\\
...&...&.&...\\
0&x_2^{n-2}(x_2-x_1)&.&x_n^{n-2}(x_n-x_1)
\end{bmatrix}\overset{\text{Разл. по 1й строке}}{=}\\\\
=1\times\det\begin{bmatrix}
x_2-x_1&.&x_n-x_1\\
...&.&...\\
x_2^{n-2}(x_2-x_1)&.&x_n^{n-2}(x_n-x_1)
\end{bmatrix}=\prod_{j>1}(x_j-x_1)\det
\begin{bmatrix}
1&.&1\\
...&.&...\\
x_2^{n-2}&.&x_n^{n-2}
\end{bmatrix}=
\\\\
=\prod_{j>1}(x_j-x_1)\prod_{2\le i< j\le n}(x_j-x_i)= \prod_{1\le i<j\le n}(x_i-x_j)
}$$

**Простой способ вычисления определителя Вандермонда**
- Рассмотрим данный определитель. Мы вполне можем сказать, что это будет некоторый многочлен, причём:
$$\det\begin{bmatrix}
1&1&...&1\\
x_1&x_2&...&x_n\\
...&...&...&...\\
x_1^{n-1}&...&...&x_n^{n-1}
\end{bmatrix}=F(x_1,x_2,...,x_n)\in\mathbb{Z}[x_1,...,x_n]$$
- Причём данный многочлен будет ещё и однородный \[1]. 
- Данный многочлен, очевидно (свойство определителя), кососимметрический
- Более того, при фиксировании в данном многочлене всех переменных кроме двух (назовём их $X$ и $Y$), получим, что данный многочлен делится на $(X-Y)$\[2]. Из этого делается вывод, что многочлен делится на все разности двух разных переменных (типа $(x_j-x_i),i\ne j$)
- Ну а раз оно делится на каждый такой линейный полином, то делится и на их произведение\[3].
- Тогда: $\overset{\deg = \frac{n(n-1)}{n}}{F(x_1,x_2,...,x_n)}=c(x_1,x_2,...,x_n)\overset{\deg = \frac{n(n-1)}{n}}{\prod_{1\le i<j\le n}(x_i-x_j)}$. А раз степени слева и справа равны, то $c(x_1,...,x_n)=\text{ const}$.
- Сравним множители перед одночленом $x_2x_3^2...x_n^{n-1}$. В определителе коэфф перед ним будет 1, такой же коэфф будет и в произведении, указанном под (prod). Значит: $c(x_1,...,x_n)=1$.\[4]
**Пояснение**
1. Однородный - все суммы степеней одночленов равны ($y^3+2x^2y$ однородный, $y^4+2qwz$ не однородный). В данном случае степень всех одночленов $\frac{n(n-1)}{2}$
2. Потому что справедливо такое замечание: $g(x,y)\in \mathbb Z: g(x,x)=0\;\;\Rightarrow\;\;g(x,y)=(x-y)h(x,y)$. Это является следствием теоремы Безу (достаточно представить $R[X,Y]=R[X][Y]=T[Y]$ и рассмотреть нужное условие). #PURGE ![[Pasted image 20240404042706.png]]
3. Этот факт отсылает к достаточно очевидной, но всё ещё не доказанной теореме. В целом понятно, что если в некоторой ОЦ $x$ делится на $a,b$ и при этом $(a,b)=1$, то $x$ делится на их произведение. Однако до сих пор в курсе это было доказано лишь для ОГИ, а данное тут кольцо ею не является. 

Аналогичным методом вычисляется и [определитель Коши](https://ru.wikipedia.org/wiki/%D0%9C%D0%B0%D1%82%D1%80%D0%B8%D1%86%D0%B0_%D0%9A%D0%BE%D1%88%D0%B8_(%D0%BB%D0%B8%D0%BD%D0%B5%D0%B9%D0%BD%D0%B0%D1%8F_%D0%B0%D0%BB%D0%B3%D0%B5%D0%B1%D1%80%D0%B0)), [ещё ссылка](https://old.mccme.ru/ium//postscript/f13/f13-smirnov-hse-schur-02.pdf)

## Ранг матрицы по минорам
**Ранг по минорам**
Пусть $A\in M_{mn}(F)$, $F$ - поле \[1]. **Рангом по минорам** называется наибольший размер ненулевого $k\times k$ минора. В таком случае и все миноры большего размера равны нулю\[2]
**Пояснение**
1. Условие на поле важное, потому что теорию про ранг мы объясняли в терминах поля, а не кольца. В общем случае не существует полноценной теории ранга для комм. колец
2. На самом деле достаточно проверить, что минор kxk не равен нулю, а при добавлении к нему любых строчки и столбца он становится равным нулю. Тогда и все остальные миноры больших порядков также нулевые

**Теорема**
Ранг матрицы по минорам совпадает с рангом матрицы (по строчкам или столбцам)
**Доказательство**
- Докажем, что $\text{rank}_{\text{minor}}(A)\le \text{rank}_{\text{стр}}(A)$. Пусть ранг по строкам матрицы $A$ равен $k$. Это значит, что любая $k+1$ строка даёт ЛЗ систему. Это же значит, что в любом миноре размера $k+1$ (и больше) будут ЛЗ строки, а значит определитель такого минора будет равен нулю. Следовательно, максимальное значение для ранга по минорам матрицы это $k$
- Докажем, что $\text{rank}_{\text{minor}}(A)\ge \text{rank}_{\text{стр}}(A)=\text{rank}_{\text{стл}}(A)$. То есть если есть $k$ ЛНЗ строк, то найдётся и некоторый ненулевой минор размера kxk. Выберем k ЛНЗ строк и столбцов. Так мы получим матрицу kxk с ЛНЗ строками и столбами, а значит она обратима, то есть её определитель не может быть равен нулю
- Докажем, что $\text{rank}_{\text{minor}}(A)\ge \text{rank}_{\text{стр}}(A)$ (без ссылки на равенство строчного и столбцового ранга). Для этого докажем, что если есть такая подматрица kxk, что любой её окаймляющий минор равен нулю, то тогда все строки матрицы $A$ лежит в линейной оболочке строк из этой матрицы. Для этого возьмём некоторую строку и столбец $A$. Рассмотрим окаймляющий минор, который, по изначальному предположению равен нулю, а значит его строки ЛЗ (при том, что изначально строки были ЛЗ). А это (это очевидно из теоремы в линейной алгебре\[лемма о добавлении]) означает, что данная строчка является ЛК изначальных, значит, принадлежит линейной оболочке строк матрицы. При этом сама строчка случайная, любая добавленная строка делает систему строк ЛЗ.
- Покажем, что она не просто является ЛК, но ещё и ЛК, не зависящей от выбора столбца для добавления (коэффициенты остаются теми же). Возьмём и выбросим добавленный столбец. Это не повлияет на то, что система ЛНЗ, а значит она всё так же будет допускать однозначное разложение (в линейную комбинацию). Разложение в данной матрице не будет при этом допускать различий из-за того самого столбца, потому что его выбросили, а разложение единственно. Она в этой матрице без столбца будет раскладываться в линейную комбинацию с теми же коэффициентами, что и в исходной матрице со столбцом
**Пояснение**
- В некотором роде данная теорема может служить заменой доказательству равенства строчного и столбцового ранга
# Линейные операторы
Достаточно важной является задача выбора наиболее удачной системы координат. В случае, когда речь шла про отображение между двумя линейными пространствами, было оговорено, что можно выбрать такие два базиса, что матрица линейного отображения между двумя базисами принимала вид $\begin{bmatrix}[E_r]&|&[0]\\ -& &- \\ [0]&|&[0] \end{bmatrix}$ (окаймлённая единичная матрица)
Здесь будет рассматриваться отображение из линейного пространства в само себя. Такие отображения часто называют **линейными операторами**. Задача здесь сводится к выбору одного (а не двух, как в задаче для отображения между разными векторными пространствами) базиса, что матрица будет выглядеть наиболее красивым образом (нередко - просто диагонально)
## Собственные числа матрицы
**Собственный вектор**
Пусть $\mathcal{A}:V\rightarrow V$ линейный оператор. Тогда вектор $v\in V$ называется **собственным вектором** для линейного оператора $\mathcal{A}$, что:
1. $v\ne0$
2. $\mathcal{A}(v)\in\langle v \rangle$\[1]
**Пояснение**
1. Это означает, что найдется такое $a\in F$: $\mathcal{A}(v)=av$ ($F$ - поле, над которым построено $V$). То есть при применении ЛОп вектор растягивается или сжимается
**Собственное число**
При этом число $a\in F$ такое, что $\exists v\in V: \mathcal{A(v)}=av$, называется **собственным числом**

**Теорема**
Собственные векторы, отвечающие различным собственным числам, ЛНЗ. То есть
$$\begin{cases}
\mathcal{A}(u_1)=\lambda_1 u_1\\
\mathcal{A}(u_2)=\lambda_2 u_2\\
...\\
\mathcal{A}(u_n)=\lambda_n u_n\end{cases},\;\;\forall i\ne j:\;\;\lambda_i\ne \lambda_j,\;u_i\ne u_j\;\;\Rightarrow\;\;\{u_i\}_{i=1}^n\;\text{ЛНЗ набор}$$
**Доказательство**
- Допустим, не ЛНЗ набор. Рассмотрим самое короткое\[1] соотношение линейной зависимости: $\sum_{j=0}^k \gamma_{i_j}u_{i_j}=0$.
- Применим оператор к обоим частям. Получим: $\sum_{j=0}^k \gamma_{i_j}\mathcal{A}(u_{i_j})=\sum_{j=0}^k \gamma_{i_j}\lambda_{i_j}u_{i_j}=0$, то есть другое соотношение ЛЗ. Теперь у нас имеется два соотношения формата: $\begin{cases}\sum_{j=0}^k \gamma_{i_j}u_{i_j}=0\\\sum_{j=0}^k \gamma_{i_j}\lambda_{i_j}u_{i_j}=0\end{cases}$. Домножим верхнее соотношение на $\lambda_{i_1}$ и вычтем. Один из членов ЛЗ сократится, при этом новое соотношение так же будет соотношением ЛЗ, но с меньшим числом членов. Изначально предполагалось, что данное соотношение минимальное. Противоречие
**Пояснение**
1. То есть минимальное число слагаемых. То есть выбросили все слагаемые не равные нулю

**Собственный столбец**
Пусть $A\in M_n(F),\;\;L_A:\underset{\overline{x}\;\;\mapsto\;\;A\times \overline{x}}{F^n\rightarrow F^n}$. Тогда: 
1. Собственный вектор ЛОп $L_A$ называется собственным столбцом матрица $A$.  
2. Собственный число   ЛОп $L_A$ называется собственным числом     матрицы $A$.

**Диагонализируемость**
ЛОп называется диагонализируемым, если существует базис, в котором матрица данного ЛОп принимает диагональный вид
**Пояснение**
Подчёркнуто различие диагональзируемости (свойство ЛОп) и диагональности (свойство его матрицы). Не стоит путать эти названия

**Предложение**
Рассмотрим различные собственные числа ЛОп:
$$\begin{cases}
\mathcal{A}(u_1)=\lambda_1 u_1\\
\mathcal{A}(u_2)=\lambda_2 u_2\\
...\\
\mathcal{A}(u_n)=\lambda_n u_n\end{cases}
\;\;\;\;\;\displaylines{\text{Если при этом $\{u_i\}_{i=1}^n$ ЛНЗ и $n=\dim V$, то этот набор}\\\text{является базисом в векторном пространстве V, причём}\\\text{матрица данного ЛОп $\mathcal{A}$ равна:}\\
\begin{bmatrix}\lambda_1&0&...&0\\0&\lambda_2&...&0\\...&...&...&...\\0&0&...&\lambda_n\end{bmatrix}}$$
## Характеристический многочлен
Необходимость в них возникает тогда, когда необходимо найти собственные числа матрицы $A$.
Фактически это значит следующее: раз $\lambda$ является собственным числом, то тогда $A\overline{x}=\lambda\overline{x}$, откуда понятным образом следует $(A-\lambda E)\overline{x}=0$. То есть получается, что $\lambda$ является СЧ тогда и только тогда, когда ОСЛУ $(A-\lambda E)\overline{x}=0$ имеет нетривиальное решение. А возможно это тогда, когда \[по теореме о ядра и образа]: $\text{rank}(A-\lambda E)<n$, то есть $A-\lambda E$ не обратима, то есть её определитель равен нулю.
В общем говоря, это можно воспринимать как некоторое уравнение на $\lambda$. Если раскрыть определитель по определению, получится некоторый многочлен от $\lambda$.

**Характеристический многочлен**
Для $A\in M_n(F)$ можно рассмотреть матрицу формата $A\in M_n(F[t])$\[1]. Также можно в этом же кольце можно рассмотреть матрицу вида $tE=\begin{bmatrix}t&0&...&0\\0&t&...&0\\...&...&...&...\\0&0&...&t\end{bmatrix}\in M_n(F[t])$. Тогда $\det (A-tE)\;\;\;\in F[t]$. Данный многочлен называется характеристическим многочленом матрицы $A$ и обозначается как $\chi_A(t)$. Тогда\[2] же:
$$\lambda\text{ собственное число матрицы $A$}\;\;\Leftrightarrow\;\;\text{$\lambda$ корень $\chi_A(t)$}$$
**Пояснение**
1. Важным является то, что любую матрицу над полем можно рассмотреть как матрицу в большем поле, то есть, например, матрицу над $\mathbb{R}$ можно рассмотреть как матрицу над $\mathbb{C}$. Многочлены можно рассмотреть так же. А когда говорят про собственные числа некоторой вещественной матрицы нередко подразумевают в том числе комплексные СЧ.
2. Из этого следует $\chi_A(\lambda)=\det (A-\lambda E)$, что не очевидно (потому что сначала подсчитать определитель, а потом подставить число и сначала подставить число, а потом посчитать определитель, вообще говоря, разные вещи). Для доказательства этого достаточно продемонстрировать коммутативность диаграммы $$\begin{CD}
M_n(F[t]) @>{\det}>> F[t]\\
@V{ev_{\lambda}}VV @V{ev_{\lambda}}VV \\
M_n(F) @>{\det}>> F
\end{CD}$$ Это можно доказать, указав, что $ev_{\lambda}:\;F[t]\longrightarrow F$ это гомоморфизм колец. То есть сохраняет арифметические операции, а $\det$ это сложная арифметическая операция (много сложений и умножений по формуле полного развёртывания)

**Предложение**
Пусть $A$ и $A'$ - это матрицы одного и того же ЛОп для разных базисов ($\{v_i\}_{i=1}^n,\{v'_i\}_{i=1}^n$ соответственно). Тогда $\chi_A(t)=\chi_{A'}(t)$ называется **характеристическим многочленом линейного оператора $\mathcal{A}$**.
**Доказательство**
- Почти очевидно. Известно, что $A'=C^{-1}AC$, где $C$ - матрица перехода $\{v\}C=\{v'\}$. Дальше можно заметить, что $\det (C^{-1}AC - tE) = \det (C^{-1}AC - C^{-1}tEC)$\[1] $=\det (C^{-1}(A-tE)C)$ $=\det C^{-1} \det(A-tE) \det C = \det(A-tE)\det(C^{-1}C)=\chi_A(t)$. 
**Пояснение**
1. Это работает, потому что с единичной (и скалярной матрицы) подобное сопряжение гарантированно даст ту же самую матрицу
**Следствие**
- $\lambda$ является собственным числом оператора тогда и только тогда, когда $\chi_A(\lambda)$. Доказательство заключается в коммутативности диаграммы $$\begin{CD}
V @>{\mathcal{A}}>> V\\
@V{\backsimeq}VV @V{\backsimeq}VV \\
F^n @>{A}>> F^n
	\end{CD}$$ где $v\in V \text{ собств. вектор }\mathcal{A}\;\;\Leftrightarrow v=(v_1,...v_n)\begin{bmatrix}x_1\\ x_2 \\...\\ x_n\end{bmatrix},\;\text{при этом }(x_i)^T\text{ это собств. столбец матрицы } A$, то есть $A\overline{x}=\lambda\overline{x}\;\Leftrightarrow\;\mathcal{A}(\theta(\overline{x}))=\lambda\theta(\overline{x})$. (Это следует из $A = [\mathcal{A}]_{v_i}^{v'_i}\;\;\Leftrightarrow A\overline{x}=\theta^{-1}(\mathcal{A}(\theta(\overline{x}))$)

**Свойства характеристического многочлена**
1. $A\in M_n(F)$, то $\chi_A(t)=(-1)^nt^n+....$, то есть $\deg \chi_A(t)$ равна размерности пространства. Это очевидно из формулы полного развёртывания (будет $(a_{11}-t)...(a_{nn}-t)+F_{n-2}[t]$, так как кроме главной диагонали там будет максимум $n-2$ элементов)
2. У характеристического многочлена свободный член равен $\det A$, а коэффициент перед $t^{n-1}$ равен $(-1)^{n-1}(a_{11} + a_{22}+...+a_{nn})=(-1)^{n-1}Tr(A)$.  Первый пункт вообще говоря очевиден, так как свободный член равен $\chi_A(0)=\det (A-0E)=\det A$. Второй пункт доказывается так: по первому пункту видно форму получившегося многочлена. Видно, что она состоит из произведения скобок и многочлена степени $n-2$, который на данный коэффициент не влияет. Ну и простым следствием произведения скобок и становится данный факт
3. Если $\chi_{\mathcal{A}}(t)=\prod_{i=1}^n(\lambda_i-t)$, где все лямбды различные, то $\mathcal{A}$ - диагонализуем. Это правда потому, что корнями являются только сами данные собственные числа, каждому из которых соответствует собственный вектор матрицы $\mathcal{A}$, каждый из таких векторов линейно независим, а значит, можно составить такую диагональную матрицу.
**Пояснение**
1. След $Tr(A)$ матриц $Tr(AB)=Tr(BA)$. А также $\chi_{AB}(t)=(-1)^{m-n}t^{m-n}\chi_{BA}(t)$. А также $Tr(A+A')=Tr(A)+Tr(A')$ (а также можно выносить и скаляр). А также $f:\;Lin(V,V)\rightarrow F$ линейный функционал: $f(C^{-1}\mathcal{A}C)=f(\mathcal{A})\;\;\forall \mathcal{A},C$, то существует такое $c$, что $f=cTr$. Аналогично: $f:\;M_n(F)\rightarrow F$, что оно линейное отображение: $f(aA)=af(A),f(A+A')=f(A)+f(A')$, то существует такое $c$, что $f=cTr$. 
## Приложение к линейным рекуррентам
**Линейный рекуррент** (или линейно рекуррентная последовательность)
Последовательность $\{a\}_{k=0}^\infty\in F$ называется **линейной рекуррентой глубины n**, если существует $c_0,...c_{n-1}\in F$, что $\forall k:\;\;a_{k+n}=c_{k-1}a_{k+n-1} + c_{k-2}a_{k+n-2} + ... c_0a_{k}$, то есть каждый член выражается как линейную комбинацию предыдущих элементов с фиксированными коэффициентами.
**Пояснение**
- Линейный рекуррент глубины 1 - геометрическая прогрессия $a_{k+1}=c_0a_k$

**Характеристическое уравнение линейной рекурренты**
Это многочлен вида $t^{n}-c_{n-1}t^{n-1}-...-c_1t-c_0$.
- Пример: характеристический многочлен геометрической прогрессии: $t-q$. ($q$ - её шаг)

**Предложение**
Зафиксируем $p(t)=t^{n}-c_{n-1}t^{n-1}-...-c_1t-c_0$. Пространство линейных рекуррент с характеристическим уравнением вида $p(t)$ является пространством и имеет размерность $n$.
**Доказательство**
- Любая такая последовательность однозначно задаётся первыми $n$ членами (все остальные считаются через многочлен)
- Рассмотрим последовательность $(1,0,0,...,0,X,X...),(0,1,0,0,...,0,X,X,...)$ и тд. Любая последовательность первых $n$ членов может быть задана с помощью линейных комбинаций таких вот последовательностей, как выше. Тогда их можно рассмотреть как базис пространства.
- Тот факт, что такие последовательности ЛНЗ очевиден, ведь даже первые $n$ членов у такой последовательности ЛНЗ. Доказательство того, что такая система последовательностей является порождающей системой, очевидно, потому что при вычитании из любой последовательности её линейного разложения даст ноль: $(a_1,a_2,...)-a_1(1,0,...)-(a_2)(0,1,...)-...=(0,....)$. Опять же, достаточно посчитать первые $n$ членов, ведь остальные считаются через многочлен, то есть будут равны нулю
____
Проверить, что множество последовательностей, удовлетворяющих линейно-рекуррентному соотношению (ЛРС) является подпространством
____

**Оператор сдвига**
На пространстве $F^\infty$ есть оператор сдвига влево: $S:\;F^\infty\underset{(a_0,a_1,...)\mapsto(a_1,a_2,...)}{\longrightarrow}F^\infty$.
Аналогично можно ввести оператор сдвига вправо. На свободное место ставят ноль.
Достаточно очевидно, что оператор сдвига является линейным оператором.

**Предложение**
$Lin(V,V)$ - ассоциативное с единицей кольцо с операциями сложения и композиции. При этом оно содержит базовое поле: $F\subset Lin(V,V)$ (так как $\lambda\in F \longmapsto [v\mapsto\lambda v]$). Если $f\in F[y]$, то в данный многочлен можно подставить линейный оператор $f(\mathcal{A})$. (потому что всегда можно подставить некоторый элемент большего поля, чем $F$).
**Доказательство**
Тривиально. Тут же встречается термин [гомотетия](https://ru.wikipedia.org/wiki/%D0%93%D0%BE%D0%BC%D0%BE%D1%82%D0%B5%D1%82%D0%B8%D1%8F).

**Замечание**
Подпространство последовательностей, удовлетворяющее линейно-рекуррентному соотношению, с характеристическим многочленом $p(t)$ - это $\text{ker} (p(S))$.
**Доказательство**
- Подставим: $(S^{n}-c_nS^{n-1}-...-c_1S-c_0*\text{Id})(a)$. На $k$-й позиции будет стоять: $S^n(a)-c_nS^n(a)-...$=$a_{k+n}-c_{k+1}a_{n+k-1}-...=a_{k+n} -a_{k+n}=0$.

**Замечание**
Собственные векторы операторы сдвига - это геометрические прогрессии. (потому что S(a)=qa, сдвинуть влево = умножить, что очев свойство геом прогрессии. Демонстрация: \[2,4,8,16,...] ->\[4,8,16,...])

**Лемма**
Если f(t) делится на g(t), то тогда $\ker f(t) \supset \ker g(t)$.
**Доказательство**
- Известно, что f(t)=h(t)g(t)
- Сюда можно подставить ЛОп S.\[1]
- По определению: $f(S)(x)=(h(S)g(S))(x)=h(S)[g(S)(x)]$. Таким образом подстановка любой последовательности из кёрнела $g$\[2] отобразит её в ноль, а любая нулевая последовательность отобразится в ноль через $h$, то есть попадёт в кёрнел $f$. 
**Пояснение**
1. Этот момент не очевиден потому, что подстановка в многочлен ранее была определена над коммутативным кольцом. Пространство же линейных отображений, в котором лежит S, таковым не является (это ассоциативное кольцо). На самом же деле S лежит в коммутативном подкольце этого кольца линейных отображений: в кольце всех многочленов от S. Оно коммутативно потому, что коэффициенты данного многочлена - это элементы над полем $F$, тем же самым, над каким построено и пространство $Lin(V,V)$. Таким образом, скаляры - это гомотетии $Lin(V,V)$ и они перестановочны с S.
2. Напомню, что это все такие последовательности, что данный g(t) их характеристический многочлен
**Следствие**
- Если $q$ корень $f(t)$, то все геометрические прогрессии с шагом $q$ лежат в $\ker f(S)$.
**Замечание**
Обратное тоже верно: если последовательности из $\ker g(S)$ удовлетворяют ещё и $f(t)$, то $\ker g(t) \subset \ker f(t)$ и f(t) делится на g(t). Доказать это можно через теорему о линейном представлении НОД: $$A(t)f(t)+B(t)g(t)=d(t)$$Нам точно известно, что $\ker f(t) \supset \ker g(t) \supset \ker d(t)$ (g точно делится на свой же НОД). Допустим, они не равны. Тогда можно подставить S и подставит такую последовательность, что слева будет ноль, а справа - ненулевая последовательность, что некорректно. Значит, $\ker g(t)=\ker d(t)$. Это означает, что полиномы одинаковой степени: разная степень даст разную размерность пространств. Получается, что в худшем случае они отличаются в константу раз: $g(t)=\alpha d(t)\Rightarrow \frac{1}{\alpha}g(t)=d(t)$. Последние и означает, что f делится на g 

**Замечание**
Форма записи $\ker p(S)$ отныне может использоваться как обозначение некоторого пространства линейно-рекуррентных последовательностей с характеристическим многочленом p(t), то есть последовательности, которые можно записать в форме:$$p(t)=t^n-c_{n-1}t^{n-1}-...-c_1t-c_0\;\;\Rightarrow\;\;a_{k+n}=c_{k-1}a_{k+n-1} + c_{k-2}a_{k+n-2} + ... c_0a_{n}$$
**Теорема**
Пусть $f(t)$ раскладывается на линейные множители. Тогда общее решение ЛРС с характеристическим уравнением $f(t)$ имеет вид $a_k=\alpha_1\lambda_1^k+...+\alpha_n\lambda_n^k$ с некоторыми параметрами $\alpha_i$.\[1]
**Доказательство**
- Размерность равна количеству линейных сомножителей. Рассмотрим для каждой $\lambda$ геометрическую прогрессию формата $(1,\lambda,\lambda^2,...)$. Каждая из них лежит в кёрнеле\[2] Одновременно с этим они все линейно независимы\[3]. Нашли макс. ЛНЗ систему, то есть нашли базис. Всё остальное -- ЛК из них. Как в условии
**Пояснение**
1. Для конкретно заданной последовательности вполне можно найти данные параметры через СЛУ 
2. их характеристический многочлен $t-\lambda$, $f(t)$ делится не него по условию, дальше смотри лемму выше
3. Это собственные векторы оператора сдвига. Получается, что они либо ЛНЗ, либо отличаются на $\gamma$, но они отличаются не на неё

**Пример с числами Фибоначчи**
Раз $F_{n+2}=F_n+F_{n+1}$, то их характеристический многочлен $f(t)=t^2-t-1=(t-\frac{1-\sqrt5}{2})(t-\frac{1+\sqrt5}{2})$. Отсюда общая формула: $F_k=X(\frac{1-\sqrt5}{2})^k + Y(\frac{1+\sqrt5}{2})^k$. Решая СЛУ можно получить, что $X=-\frac{1}{\sqrt5},Y=\frac{1}{\sqrt5}$
Такое же соотношение можно найти и в [формуле Бине](https://ru.wikipedia.org/wiki/%D0%A7%D0%B8%D1%81%D0%BB%D0%B0_%D0%A4%D0%B8%D0%B1%D0%BE%D0%BD%D0%B0%D1%87%D1%87%D0%B8#%D0%A4%D0%BE%D1%80%D0%BC%D1%83%D0%BB%D0%B0_%D0%91%D0%B8%D0%BD%D0%B5)

**Предложение**
Пусть имеется $p(t)$ характеристический многочлен и стандартный базис формата $e_i=(\overset{0}{0},...,0,\overset{i}{1},0,...0,\overset{n}{c_i})$ в пространстве $\ker p(S)$. Вычислим матрицу ЛОп $S$ в этом базисе.
Её внешний вид:$$M_{p(t)}^T=\begin{bmatrix}
0&1&0&0&...&0\\
0&0&1&0&...&0\\
0&0&0&1&...&0\\
...&...&...&...&...&...\\
0&0&0&0&...&1\\
c_0&c_1&c_2&c_3&...&c_{n-1}\\
\end{bmatrix}$$Что очевидно по теореме о внешнем виде матрицы ЛО (каждый $i$ столбец - образ $e_i$ в операторе S, то есть $S(e_i)$.
Можно непосредственно свести вывод формулы $k$-го члена линейно рекуррентной последовательности к вопросу диагонализации данной матрицы:
$$\begin{bmatrix}
0&1&0&0&...&0\\
0&0&1&0&...&0\\
0&0&0&1&...&0\\
...&...&...&...&...&...\\
0&0&0&0&...&1\\
c_0&c_1&c_2&c_3&...&c_{n-1}\\
\end{bmatrix}
\begin{bmatrix}
a_k\\
a_{k+1}\\
a_{k+2}\\
...\\
a_{k+n-2}\\
a_{k+n-1}\\
\end{bmatrix}=
\begin{bmatrix}
a_{k+1}\\
a_{k+2}\\
a_{k+3}\\
...\\
a_{k+n-1}\\
a_{k+n}\\
\end{bmatrix}$$
Из этого следует, что:
$$\begin{bmatrix}
0&1&0&0&...&0\\
0&0&1&0&...&0\\
0&0&0&1&...&0\\
...&...&...&...&...&...\\
0&0&0&0&...&1\\
c_0&c_1&c_2&c_3&...&c_{n-1}\\
\end{bmatrix}^k
\begin{bmatrix}
a_0\\
a_{1}\\
a_{2}\\
...\\
a_{n-2}\\
a_{n-1}\\
\end{bmatrix}=
\begin{bmatrix}
a_{k}\\
a_{k+1}\\
a_{k+2}\\
...\\
a_{k+n-2}\\
a_{k+n-1}\\
\end{bmatrix}$$
Пусть мы диагонализировали данную матрицу: $M_{p(t)}^T=C\begin{bmatrix}\lambda_1&0&..&0\\0&\lambda_2&..\\..&..&..\\0&0&..&\lambda_n\end{bmatrix}C^{-1}$. Матрица перехода должна быть составлена из собственных столбцов - они же геометрические прогрессии, а для возведения в $k$ степень достаточно просто возвести в неё данный коэффициенты $\lambda$.

**Замечание**
Характеристический многочлен $M_{p(t)}$ равен $(-1)^np(t)$. Разложим по первому столбцу определитель $\det (M_{p(t)}^T-tE)$.
Рассмотрим доказательство по индукции.
- n=2 $\det M_{p(t)}^T=\det \begin{bmatrix}-t&1\\c_0&c_1-t\end{bmatrix}=-t(c_1-t)-c_0=t^2-c_1t-c_0$
- n-1->n: $\det M_{p(t)}^T=(-1)^n(-t)(t^{n-1}-c_{n-1}t^{n-2}-...-c_2t-c_0)+(-1)^n(c_0)=(-1)^np(t)$.
## * Пример применения линейно-рекуррентной последовательности
___
Рассмотрим следующую задачу: посчитать определитель следующей матрицы ([матрица Тёплица](https://ru.wikipedia.org/wiki/%D0%9C%D0%B0%D1%82%D1%80%D0%B8%D1%86%D0%B0_%D0%A2%D1%91%D0%BF%D0%BB%D0%B8%D1%86%D0%B0)размера $n\times n$):$$\begin{bmatrix}
2&1&0&0&0&\cdots&0\\
1&2&1&0&0&\cdots&0\\
0&1&2&1&0&\cdots&0\\
0&0&1&2&1&\cdots&0\\
\cdots&\cdots&\cdots&\cdots&\cdots&\cdots&\cdots\\
0&0&0&0&0&\cdots&2\\
\end{bmatrix}$$
Можно заметить, что данный определитель считается рекуррентно. Обозначим за определитель такой матрицы $A_n$. Тогда $A_n = 2A_{n-1}-A_{n-2}=3A_{n-2}-2A_{n-3}=...$ Вручную можно проверить определители некоторых матриц для первых $n$: $A_4=5,\;A_3=4$. Из этого же следует, что $A_2=3,\;A_1=2$ 
Можно (достаточно просто) найти чисто итерационное решение $(n-3)A_4-(n-4)A_3=5(n-3)-4(n-4)=n+1$
Однако в более общем виде можно применить некоторые знания про ЛРП

**Замечание**
По теореме, изложенной в параграфе выше, существует формула (может существовать) для нахождения общего члена ЛРП. 
Для решения нужно рассмотреть характеристический многочлен ЛРП. В данном случае: $t^2-2t+1$. 
- Если многочлен имеет линейное разложение, то для каждого корня $c_i$ достаточно найти такие числа $A_i$, что $x_n=\sum_{\text{Корни }\chi} A_ic_i^n$. Если есть кратный член, то каждой паре достаточно сопоставить одно слагаемое $(A_i+B_in)c_i^n$.
В нашем случае имеем один корень. То есть в нашем случае общий вид: $x_n=(A+Bn)1^n=A+Bn$. Методом подстановки для некоторых членов (достаточно первых двух) находим коэффициенты $A=1$ и $B=1$.
Важное замечание: корни могут быть и комплексные!
____
## Теорема Гамильтона-Кэли
**Теорема**
Пусть $R$ - коммутативное кольцо (или поле). Рассмотрим коэффициенты из $R$: $R\hookrightarrow M_n(R),\;\;c\longmapsto \begin{bmatrix}c&0&..&0\\0&c&..&0\\..&..&..&..\\0&0&..&c\end{bmatrix}=cE_n$. Для многочлена $p(t)$ и $A\in M_n(R)$ определено значение $p(A)$. Нужно доказать, что $\chi_A(A)=0$.
**Доказательство** для $\mathbb{C}$
- Индукция по размеру матрицы: база очевидна.
- Индукционный переход. Пусть $\lambda$ - корень характеристического многочлена. То есть $\chi_A(t)=(-1)^n(t-\lambda)g(t)$. \[3]\[6]
- Рассмотрим ЛОп $L_A:\underset{x\mapsto Ax}{\mathbb{C}^n\longrightarrow\mathbb{C}^n}$. Выберем такой базис, что первый базисный вектор равен собственному вектору, отвечающий собственному значению $\lambda$, дополненный до базиса. В этом базисе матрица оператора $L_A$ будет иметь блочно-треугольный вид:$\begin{bmatrix}\lambda&X&..&X\\0&&&\\..&&B&\\0&&&\end{bmatrix}$.
- Получится: $\chi_A(t)=(\lambda-t)\chi_B(t)$\[4], то есть $g(t)=(-1)^{n-1}\chi_B(t)$. Подставляем\[5]: $$(t-\lambda)g(t)\biggr|_{t=A'}=g(t)(t-\lambda)\biggr|_{t=A'}=\begin{bmatrix}g(\lambda)&X\\0&g(B)\end{bmatrix}\begin{bmatrix}\lambda-\lambda&X\\0&B-\lambda E\end{bmatrix}=\begin{bmatrix}g(\lambda)&X\\0&0\end{bmatrix}\begin{bmatrix}0&X\\0&B-\lambda\end{bmatrix}=0$$Чем и доказали искомое
**Доказательство** (более общее)
- Пусть S - коммутативное кольцо, $R=M_n(S)$. Аналогично предыдущему пункту рассматриваем $\chi_A(t)\in S[t]\hookrightarrow M_n(S)[t]$. По схеме Горнера\[7] представим данный многочлен как $\chi_A(t)=(t-A)(b_{n-1}t^{n-1}+...+b_1t+b_0)+r$. Докажем, что $r=0$, а также что коэффициенты, которые на самом деле уже являются сами по себе матрицами, принадлежат подкольцу: $b_i\in S[A]\subset M_n(S)\;$\[8].
- Второй пункт (про комм. подкольцо) прямо следует из схемы Горнера. В ней мы представляли элементы как: $$\begin{aligned}&b_{n-1}=a_{n}\\&b_{n-2}=a_{n-1}+cb_{n-1}\\&...\\&b_{0\;}\;\;\;=a_1+cb_1\\&r_{\;_{}}\;\;\;\;=a_0+cb_0\end{aligned}$$А значит каждое $b$ таки представляется через некоторую комбинацию их скалярных матриц и матрицы $A$ (в данном представлении вместо $c$ мы поставляем $A$)\[7]. Получается, что для доказательства теоремы достаточно сослаться на теорему Безу\[9] и сказать, что из равенства $r$ нулю следует и само доказательство. 
- $r=0$ следует из формулы Крамера для присоединённых матриц. Рассмотрим $A-tE\in M_n(S[t])$. По обозначенной выше формуле $(A-tE)(\text{adj }(A-tE))=\det (A-tE)E=\chi_A(t)E$.
- Рассмотрим теперь $(A-t)\in M_n(S)[t])$. Окажется, что $\text{adj }(A-tE)=(b_{n-1}t^{n-1}+...+b_1t+b_0)$.\[11].
**Пояснение**
1. Можно в качестве иллюстрации рассмотреть матрицу $M_{p(t)}^T$ из прошлого параграфа. При сужении действия $S$ только на пространстве последовательностей, удовлетворяющих $p(t)$ получим, что искали
2. Ещё один пример - диагональная матрица. Её характеристический многочлен равен произведению всех скобок вида $t-\lambda$, умноженное на $(-1)^n$. При подстановке туда матрицы получим произведение одинаковых матриц, в которых последовательно вычеркнуты каждая строка. Произведение это равно нулю
3. Этот момент показывает, что если у характеристического многочлена нет кратных корней, то теорема верна автоматически, ведь характеристический многочлен ЛОп не зависит от выбора базиса, а значит можно рассмотреть только диагональную матрицу с собственными значениями. Сама матрица оказывается диагонализируемой как раз по факту того, что собственных значений $n$ и они все различны
4. характеристический многочлен ЛОп не зависит от выбора базиса, см. параграф про характеристический многочлен.
5. Вычисление над блочно-диагональными матрицами происходит так: при умножении матриц с блоками одинакового размера (Типа $\begin{bmatrix}A&X\\0&B\end{bmatrix}\begin{bmatrix}A'&X\\0&B'\end{bmatrix}$) вычисления над блоками происходят изолированно друг от друга. То есть по итогу получится матрица формата $\begin{bmatrix}AA'&X\\0&BB'\end{bmatrix}$ (это требует лишь тривиальной проверки)
6. Поле комплексных важно как раз для этого -- чтобы можно было многочлен представит как произведение линейных полиномов
7. Про схему Горнера. Пусть R - ассоциативное кольцо, R\[t]. Для любого такого многочлена существует представление формата $(t-c)(b_{n-1}t^{n-1}+...)+r$. Причём для любого многочлена данный набор вычисляется однозначно (!!!) (это работает точно так же, как и в обычной схеме Горнера)
8. То есть представляют из себя некоторый многочлен от $t$, в который вместо $t$ подставили $A$
9. Нам была важна коммутативность кольца\[10]. Мы показали, что характеристический многочлен лежит в коммутативном кольце. Значит, можно использовать теорему Безу
10. [Теорема Безу](https://ru.wikipedia.org/wiki/%D0%A2%D0%B5%D0%BE%D1%80%D0%B5%D0%BC%D0%B0_%D0%91%D0%B5%D0%B7%D1%83) работает лишь над коммутативным кольцом с единицей
11. по т. Безу\[10] + схеме Горнера\[7], потому что представление единственно
**Замечание**
- Рассмотрим следующую конструкцию: $\det (A-tE)=\chi_A(t)\;\;\Rightarrow\;\;\det (A-AE)=\chi_A(A)$. Она ошибочна, потому что в первом случае подразумевается наличие матрицы $\begin{bmatrix}X-t&X&..&X\\X&X-t&..&X\\..&..&..&..\\ X&X&..&X-t\end{bmatrix}$. То есть, подставляя матрицу $A$, получим:$\begin{bmatrix}X-A&X&..&X\\X&X-A&..&X\\..&..&..&..\\ X&X&..&X-A\end{bmatrix}$, что вообще не то же самое, что вычесть из $A$ матрицу $A$. Короче говоря, в первом случае $t$ представлялось как скаляр. А во втором $t$ уже может представлять матрицу, что изначально не подразумевалось. Короче говоря, идёт проблема в неправильном восприятии кольца, в котором лежит $t$.
## Пример применения теоремы Гамильтона-Кэли
**Алгебраическое комплексное число**
$$\text{$c\in\mathbb{C}$ называется алгебраическим, если это корень $p(x)\in \mathbb{Q}[x]$}$$

**Предложение**
$a$ - алгебраическое число, то для любого рационального многочлена $f(a)$ тоже алгебраическое число. Это так, потому что если существует $p(x)$ что $p(a)=0$, то тогда $f(a)$ - корень $\chi_{f(M_{p(x)})}(x)$\[3]  
**Доказательство**
- Будем считать, что $p(x)$ неприводим над $\mathbb{Q}$. Тогда $\mathbb{Q}[X]/p(x)$ это поле, причём данное поле изоморфно полю $\underset{\;\;\;\;\;\;\;[f(x)] \xmapsto{\;\;\;\;\;\;\;\;\;\;\;\;\;\;} f(a)}{\mathbb{Q}[X]/p(x)\;\;\backsimeq\backsimeq\backsimeq\;\;\mathbb{Q}[a]}\subset\mathbb{C}$.\[1]
- Для многочлена $p$ очевидно, что $M_p\Rightarrow p(M_p)=0$. (т. Гамильтона-Кэли, первое пояснение)
- Этот факт означает корректность определения $\underset{\;\;[f(x)] \xmapsto{\;\;\;\;\;\;\;\;\;\;\;\;\;\;} f(M_p)}{\mathbb{Q}[t]/p(t)\;\;\longrightarrow\;\;M_n(\mathbb{Q})[t]}$.\[2]
- При этом известен изоморфизм данного кольца вычетов с $\mathbb{Q}[a]$, то есть можно отобразить $f(a)$ в $f(M_p)$. То есть кольцо $\mathbb{Q}[a]$ изоморфно некоторому подкольцу кольца $M_n(\mathbb{Q})[t]$, состоящему из матричных многочленов формата $c_nM_p^n+...+c_0E$.
**Пояснение**
1. То, что $\mathbb{Q}[a]\subset\mathbb{C}$ очевидно. Изоморфизм доказывается так: это очевидно (или в худшем случае тривиально) что это биекция. Инъекция: кёрнел отображения равен нулю. Пусть отображаем $g(x)$ и приходим в ноль, тогда, раз $g(a)=p(a)=0$ и $p(x)$ неприводим над $\mathbb{Q}$, то $g$ делится на $p$, то есть $[g(x)]=0$ (обобщённая теорема Безу). Сюръекция: $[x]\mapsto a$, следовательно, $f(a)=q_0+q_1a+...+q_na^n=q_0+q_1\theta([x])+...+q_n\theta([x^n])=\theta([q_0])+...+\theta([q_nx^n])=\theta([q_0+...+q_nx^n])$$[q_0+...+q_nx^n]\mapsto\theta([q_0+...+q_nx^n])$
2. Пусть $[f]=[g]$, но $f(M_p)\ne g(M_p)$. Тогда $(f-g)(M_p)\ne0$, $f-g$ не делится на $p$, то есть $[f]\ne[g]$
3. Расшифрую этот ужас. $f(a)$ является АЧ, если оно является корнем некоторого многочлена над $\mathbb{Q}$. Справа имеем: матрицу а элементами из $\mathbb{Q}$, которую подставили в многочлен $f$, получив снова матрицу из $\mathbb{Q}$, от которой взяли характеристический многочлен, то есть многочлен от $\mathbb{Q}$. Нам нужно доказать, что $f(a)$ его корень. 
## Симметричные и ортогональные матрицы
**Симметричная матрица**
Матрица из $M_n(F)$ называется **симметричной**, если $A^T=A$
Матрица из $M_n(\mathbb{R})$ называется **вещественно-симметричной**, если $A=A^T$
Матрица из $M_n(\mathbb{C})$ называется **эрмитово-симметричной**, если $A=\overline{A^T}$. 
Матрица из $M_n(\mathbb{C})$ называется **унитарной**, если  $A^{-1}=\overline{A^T}$.
**Пояснение**
1. Далее я буду использовать соответствующие сокращения ВСМ и ЭСМ

**Замечание**
$A^T=\overline{A}$ влечёт $\chi_A(t)=\chi_{\overline{A}}(t)=\chi_{A^T}(t)=\overline{\chi_A(t)}$. (Потому что сопряжение сохраняет арифметические операции, а потому нет разницы, когда его брать -- до взятие или после)
Из равенства первого и последнего следует, что характеристический многочлен ЭСМ (а следовательно и ВСМ, если числа вещественные) состоит из вещественных чисел

**Теорема**
Все комплексные собственные числа вещественно симметричной или эрмитово-симметричной матрицы -- вещественные
**Доказательство**
- Уже известно, что характеристический многочлен сам состоит из вещественных чисел
- Пусть $a$ комплексный корень. Тогда есть (комплексный) собственный столбец, то есть такое x (не равное нулю!), что $Ax=ax$.
- Сопрягаем: $\overline{Ax}=\overline{ax}$, то есть сопряжённое число тоже собственное. Потом транспонирование: $x^TA^T=ax^T$
- Рассмотрим $x^TA^T\overline{x}$. Получим: $ax^T\overline{x}=x^TA^T\overline{x}=x^T\overline{ax}$. Тогда $a=\overline{a}$. 
**Пояснение**
1. Здесь важны две вещи: первое, мы можем перенести $a$ в правом равенстве влево, потому что не так важно, когда брать сопряжение. Второе, важно, что умножение идёт между транспонированным столбцом и сопряжённым к нетранспонированному столбцу. Потому что тогда получается сумма квадратов модулей чисел, которая не равна нулю. Если бы было не сопряжённое, то была бы сумма квадратов комплексных чисел, которая могла бы дать ноль и мы бы не могли сократить на это произведение

**Ортогональность столбцов**
Собственные столбцы вещественно симметричной матрицы, отвечающие различным собственным числам, **ортогональны друг другу** в $\mathbb{R}^n$. (потому что их скалярное произведение будет равно нулю)
Аналогичный факт есть и для ЭСМ, но тут потребуется дополнительно взять сопряжение у второго множителя в скалярном произведении ($\langle x,\overline{y} \rangle=0$)
**Пояснение**
- Достаточно дважды посчитать $x^TA^T\overline{y}$.

**Ортогональные матрицы**
Вещественная матрица называется **ортогональной**, если $A^T=A^{-1}$
По равносильным определениями обратной матрицы: $AA^T=A^TA=E$. Однако это разные свойства:
1. $AA^T$ - строчки матрицы $A$ попарно ортогональны в $\mathbb{R}^n$, что даст ноль в не-диагонали ноль, а скалярный квадрат каждой строчки равен 1
2. $A^TA$ - то же самое, только для столбцов
**Замечание**
- Отображение, задающееся такой матрицей, сохраняет расстояние между векторами (то есть данное отображение - **изометрия**)

**Предложение**
Собственные числа ортогональной матрицы - это комплексные числа, лежащие на единичной окружности
**Доказательство**
- $\overline{Cx}=\overline{ax}$ => $C\overline{x}=\overline{ax}$.
- $ax^T\overline{ax}=x^TC^TC\overline{x}=x^T\overline{x}$ => $a\overline{a}=1$ => $|a|^2=1$

**Лемма**
Унитарные матрицы образуют группу по умножению\[1]
**Доказательство**
- $\overline{(C_1C_2)^T}=\overline{C_2^T}\times\overline{C_1^T}=C_1^{-1}C_2^{-1}$
- $\overline{(C_1^{-1})^T}=\overline{(C_1)^T}^{-1}=C$
**Замечание**
- Данную группу обозначают (группу унитарных матриц размера nxn) $U_n(\mathbb{C})$.
- Группу ортогональных матриц при этом обозначают $O_n(\mathbb{C})$.
- $SU_n(\mathbb{C}), SO_n(\mathbb{R})$ - то же самое, но для матриц с определителем, равным единице. Так же можно обозначить за $SL_n(F)=\{A\in M_n(F)\;|\;\det A = 1\}$ 
**Пояснение**
1. То есть произведение двух унитарных матриц это унитарная матрица и обратное к унитарной матрице это тоже унитарная матрица. Единица (то есть $E$) очевидно унитарная.
## Диагонализация вещественно-симметричных матриц
**Лемма 1**
Если $A$ ЭСМ, $C$ - унитарная. Тогда $C^{-1}AC$ тоже ЭСМ.
**Доказательство**
$$\overline{(C^{-1}AC)^T}=\overline{C^T}\times\overline{A^T}\times C=C^{-1}AC$$

**Лемма 2**
Любой вектор длины один можно дополнить до ортнормированного базиса
**Доказательство**
- Дополнить до любого базиса, а после применить процесс ортогонализации (который проходили в курсе Аналитической Геометрии). После этого каждый вектор нормировать до единицы

**Предложение**
Пусть $A\in M_n(\mathbb{C})$\[1] эрмитово-симметрична. Пусть также $\chi_A(t)$ раскладывается на _различные линейные множители_.\[2]. Тогда существует унитарная матрица $C\in M_n(\mathbb{C})$, что\[3]\[4] $$C^{-1}AC = 
\begin{bmatrix}
\lambda_1&0&\cdots&0\\
0&\lambda_2&\cdots&0\\
\vdots&\vdots&\ddots&\vdots\\
0&0&\cdots&\lambda_n
\end{bmatrix}$$
**Доказательство**
- Возьмём для матрицы $A$ её собственные столбцы. Уже было доказано, что они попарно ортогональны, то есть $\langle x,\overline{y}\rangle = x^T\overline{y}=0$ для разных столбцов. Если же столбцы одинаковы, то $\langle x,\overline{x}\rangle\overset{[5]}=\sum_{i=1}^n |x_i|^2=||x||^2\;(\text{квадрат длины вектора }x)$, то есть положительное вещественное число.
- Возьмём для каждого такого столбца $v=\frac{x}{\sqrt{||x||^2}}=\frac{x}{||x||}$. Получим ортнормированный базис $\mathbb{C}^n$. Тогда матрица $C$, построенная из столбцов $v$, будет ортогональной\[6] 
- При этом $C$ - матрица перехода от стандартного базиса $\mathbb{C}^n$ к ортнормированному базису. В итоге: исходный линейный оператор в стандартном базисе выражается как умножение на $A$, а этот же оператор, выраженный в базисах $\{v_i\}$ и $\{v_i\}$ - как умножение на $C^{-1}AC$. Ну а диагональна она потому, что $C$ составлена из (почти) собственных векторов $A$.\[7]  
**Следствие**
- Если матрица вещественно-симметричная с тем же условием на характеристический многочлен, то данная матрица $C$ ортогональна
**Пояснение**
1. Для вещественной это тоже верно, ведь взятие сопряжённого не меняет вещественное число
2. Ранее было доказано, что это вещественные числа
3. Соответственно, там на диагонали собственные числа
4. Уже известен тот факт, что для матрицы (над любым полем), характеристический многочлен которой раскладывается на различные линейные полиномы, всегда существует некоторая обратимая матрица, что при таком сопряжении она приведётся к диагональному виду. В данный момент теорема утверждает, что (для $\mathbb{C}$) эта будет унитарной. 
5. $(a+bi)\overline{(a+bi)}=(a+bi)(a-bi)=a^2-i^2b^2=a^2+b^2$.
6. Посчитаем $\overline{C^T}C$. Каждый элемент этого произведения - это скалярное произведение ортнормированных столбцов $v$. То есть скалярный квадрат - он и есть на диагоналях - даст 1, а в остальных местах (из-за ортогональности) будет ноль. То есть $\overline{C^TC}=E$.
7. С другой стороны, можно сделать такое рассуждение: посмотрим на произведение $C^{-1}AC=C^{-1}A\begin{bmatrix}\overline{v_1}&\overline{v_2}&\cdots&\overline{v_n}\end{bmatrix}=C^{-1}\begin{bmatrix}\lambda_1\overline{v_1}&\lambda_2\overline{v_2}&\cdots&\lambda_n\overline{v_n}\end{bmatrix}=C^{-1}CV=V$, где под $V$, во-первых, подразумевается сама искомая диагональная матрица, а во-вторых, элементарная матрица умножения каждого столбца на число

**Теорема**
Пусть $A\in M_n(\mathbb{C})$ эрмитово-симметрична и имеет собственные значения (возможно, кратные). Тогда существует унитарная матрица $C\in M_n(\mathbb{C})$, что \[1] $$C^{-1}AC = 
\begin{bmatrix}
\lambda_1&0&\cdots&0\\
0&\lambda_2&\cdots&0\\
\vdots&\vdots&\ddots&\vdots\\
0&0&\cdots&\lambda_n
\end{bmatrix}$$
**Доказательство**
- Индукция по размеру матрицы. Для $n=1$ очевидно, делаем переход
- Возьмём матрицу $A$, найдём у неё некоторый собственный вектор $v$. Пусть его длина равна 1
- По лемме 2 её можно дополнить до ортнормированного базиса. То есть можно составить унитарную матрицу $D=\begin{bmatrix}v&x_2&x_3&\cdots&x_n\end{bmatrix}$. При этом $D^{-1}AD=\begin{bmatrix}\lambda_1&&&&\\0&&&&\\0&&X&&\\\vdots&&&&\\0&&&&\end{bmatrix}$
- По лемме 1 эта $D^{-1}AD$ является ЭСМ. Из того, что после транспонирования (и сопряжения) этой матрицы получится та же матрица следует, что её первая строчка тоже заполнена нулями. То есть эта матрица принимает блочно-диагональный вид. $D^{-1}AD=\begin{bmatrix}\lambda_1&0&\cdots&0\\0&&&\\\vdots&&B&\\0&&&\end{bmatrix}$
- Раз так, к матрице $B$ можно применить индукционное предположение\[3] Для матрицы $B$ её унитарной пусть будет матрица $U$. Далее достаточно заметить, что $\begin{bmatrix}1&0&\cdots&0\\0&&&\\\vdots&&U^{-1}&\\0&&&\end{bmatrix}\begin{bmatrix}\lambda_1&0&\cdots&0\\0&&&\\\vdots&&B&\\0&&&\end{bmatrix}\begin{bmatrix}1&0&\cdots&0\\0&&&\\\vdots&&U&\\0&&&\end{bmatrix}\overset{[4]}=\begin{bmatrix}\lambda_1&0&\cdots&0\\0&&&\\\vdots&&U^{-1}BU&\\0&&&\end{bmatrix}$, которая примет диагональный вид. То есть заметить, что достаточно $D^{-1}AD$ умножить слева и справа на указанные выше матрицы\[5].
**Пояснение**
1. Да, это теорема подозрительно похожа на предыдущую. Просто здесь мы убрали условие на различность разложения $\chi_A(t)$. Многие пояснения по изложению отнесены к прошлой теореме.
2. Данную нормировку в общем случае провести достаточно просто
3. Важно заметить, что свойство ЭСМ переносится и на матрицу $B$. Достаточно внимательно посмотреть на то, что с ней происходит при транспонировании-сопряжении $D^{-1}AD$.
4. Умножение на блочно-диагональных матрицах выполняется поблочно. Это было доказано ранее
5. По лемме из прошлого параграфа унитарность при произведении не потеряется, потому что унитарные матрицы образуют группу
# Квадратичные и билинейные формы

## Билинейная форма.  Ортогональное дополнение и его  простейшие свойства. Теорема Лагранжа
**Билинейная форма**
Если $V$ - векторное пространство над полем $F$, то билинейное отображение формата $\varphi:\;V\times V \rightarrow F$ называется билинейной формой. 

**Билинейная форма в координатах**
Пусть $\{v_i\}$ - базис $V$, $\varphi:\;V\times V \rightarrow F$ - билинейная форма. Рассмотрим $\varphi(\overline{x}_{\in V},\overline{y}_{\in V}) = \varphi(x_1v_1+...+x_nv_n,\;y_1v_1+...+y_nv_n)=\sum_{i=1}^n\sum_{j=1}^nx_iy_j\varphi(v_i,v_j)=\begin{bmatrix}x_1&\cdots&x_n\end{bmatrix}\begin{bmatrix}\sum_{j=1}^ny_j\varphi(v_1,v_j)\\\vdots\\\sum_{j=1}^ny_j\varphi(v_n,v_j)\end{bmatrix}$
$=\begin{bmatrix}x_1&\cdots&x_n\end{bmatrix}\begin{bmatrix}\varphi(v_1,v_1)&\cdots&\varphi(v_1,v_n)\\\vdots&\ddots&\vdots\\\varphi(v_n,v_1)&\cdots&\varphi(v_n,v_n)\end{bmatrix}\begin{bmatrix}y_1\\\vdots\\ y_n\end{bmatrix}=\overline{x}^T\cdot G_{\varphi,\{v_i\}}\cdot \overline{y}$
Матрица, которая здесь была обозначена как $G_{\varphi,\{v_i\}}$, называется **матрица билинейной формы** (Грама). 
Первое определение: Матрица билинейной формы - это матрица, которая позволяет вычислять в координатах значение данной билинейной формы. 
Второе определение: Матрицы билинейной формы - это матрица вида $(G_{\varphi,\{v_i\}})_{ij}=\varphi(v_i,v_j)$
Матрица определена однозначно (и определения эквивалентны), потому что на место векторов $x$,$y$ можно поставить векторы базиса. Тогда и получится, что $\varphi(v_i,v_j)=[0,...0,\overset{i}{1},0,...,0]G_{\varphi,\{v_i\}}[0,...,0,\overset{j}{1},0,...,0]^T=(G_{\varphi,\{v_i\}})_{ij}$

**Смена базиса**
Пусть мы имеем два базиса $\{v_i\},\{u_i\}$ и матрицу перехода между ними $C$:  $[u_1,...,u_n]=[v_1,...,v_n]C$. Тогда матрица билинейной формы: $$C^TG_{\varphi,\{v_i\}}C=G_{\varphi,\{u_i\}}$$
**Доказательство**
$$\overline{x_u}^TC^TG_{\varphi,\{v_i\}}C\overline{y_u}=(C\overline{x_u})^TG_{\varphi,\{v_i\}}\overline{y_v}=\overline{x_v}^TG_{\varphi,\{v_i\}}\overline{y_v}$$

**Симметрия и кососимметрия**
**Кососимметричная билинейная форма**: $\varphi(x,y)=-\varphi(y,x)$
**Симметричная билинейная форма**: $\varphi(x,y)=\varphi(y,x)$
Если билинейная форма симметричная, то и её матрица тоже симметричная

**Отношение ортогональности**
Если $\varphi$ билинейная форма, то на $V$ возникает отношение ортогональности (относительно данной билинейной формы): $v\perp_{\varphi} u\;\;\Leftrightarrow\;\;\varphi(v,u)=0$. Если при этом $\varphi$ симметрична или кососимметрично, то тогда это симметричное отношение
**Замечание** (о диагональности)
Матрица билинейной формы (Грама) в данном базисе диагональна тогда и только тогда, когда векторы базиса попарно ортогональны (относительно данной билинейной формы).

**Ортогональное дополнение**
Пусть $L \subset V$. Тогда ортогональным дополнением $L^{\perp_\varphi}$ называется множество векторов, которые ортогональны всем векторам, лежащим в $L$. То есть: $$L^{\perp_\varphi}=\{x\in V\;\;|\;\;\forall v \in L:\;\varphi(v,x)=0\}$$
**Теорема Лагранжа**
Для любой симметричной матрицы $A\in M_n(F)$, $\text{char }F\ne2$. Тогда для неё существует обратимая матрица, что $C^TAC$ диагонально. 
**Доказательство**
- Пусть матрица билинейного отображения невырожденная\[4], а вообще говоря матрица не нулевая. Найдём вектор $v_1$ такой, что $\varphi(v_1,v_1)\ne0$. Он есть, потому что можно отыскать $\varphi(u,v)\ne0$. Тогда $\varphi(u+v,u+v)=\varphi(u,u)+2\varphi(u,v)+\varphi(v,v)$, где какой-то из них не ноль\[5]. Тогда можно взять какой-то $u$, $v$ или $u+v$. 
- Построим базис, в котором все векторы попарно ортогональны относительно данной билинейной формы. Построить его можно по индукции (имея k векторов, k+1 можно построить как решение ОСЛУ формата $\varphi(v_1,x)=0\;\land\;...\;\land\;\varphi(v_k,x)=0$\[2]\[3]).
- Решение данного ОСЛУ не только существует, но и является ортогональным дополнением выбранных по индукционному предположению k векторов. А по линейности отображения $\varphi$ можно заключить, что найденный вектор лежит в $\langle v_1,\cdots, v_k\rangle^{\perp_\varphi}$. 
- По построению каждый вектор $v_i$ не ортогонален сам себе ($\varphi(v_i,v_i)\ne0$), но ортогонален остальным (при $i\ne j$: $\varphi(v_i,v_j)=0$). Из этого следует, что $\langle v_1,\cdots, v_k\rangle \cap \langle v_1,\cdots, v_k\rangle^{\perp_\varphi}=0$\[6]. Из этого же следует их линейная независимость. При этом до завершения процесса построения базиса оба данных множества не пусты и не заполнены лишь нулём\[7]. При этом $\varphi(v_{k+1},v_{k+1})\ne0$\[8].
- В этом базисе матрица и станет диагональной. А если матрица была вырожденной, то базис изначально и был ортогонален
**Пояснение**
1. Условие на не равенство характеристики поля двум крайне важно. Смотри параграф про билинейные отображения в главе про определители.
2. Это ОСЛУ, потому что при фиксации в билинейном отображении одной переменной получится линейное отображение. В свою очередь имеет место утверждение: $g:\;V\rightarrow F^k\text{ линейно }\;\Leftrightarrow\;\forall i:\;X_i\circ g:\;V\rightarrow F\text{ линейны}$, где $X_i$ - координатные функции
3. Решения существуют всегда. На момент нахождения $k<n$ векторов у нас имеется $k$ уравнений. Если раскрыть координаты $x$ по старому базису, получится, что на матрицу из $k$ строк имеется $n$ столбцов. Значит, ядро линейного отображения не пустое. То есть, имеется как минимум одно нетривиальное решение
4. То есть её определитель не равен нулю.
5. В этот момент и становится важным условие на $\text{char }F\ne2$: если не-ноль был второе слагаемое, то оно превратится в ноль из-за умножение на два.
6. $0=\varphi(\alpha_1v_1+\cdots+\alpha_k v_k, v_i)=\alpha_i \cdot [\varphi(v_i,v_i)_{\ne0}]$. То есть $\alpha_i=0$.
7. Потому что размерность ортогонального дополнения (которое, как говорилось выше, есть ядро построенного линейного отображения \[иллюстрации решения ОСЛУ\]) больше или равна $n-k$. Однако из того, что пересечения лишь по нулю следует, что размерность линейной оболочки и его ортогонального дополнения в данном случае в сумме и даст $n$ (короче говоря, что сумма прямая), то есть размерность ортогонального дополнения равно $n-k$, то есть пока $k$ не $n$, размерность ненулевая.
8. Построим матрицу грамма от базиса линейной оболочки и его ортогонального дополнения. Её определитель не равен нулю, потому что не равен нулю определитель исходной матрицы, а данная получается некоторым преобразованием координат (то есть умножением слева и справа на обратимые матрицы, определитель которых не ноль). С другой стороны, сама матрица разбивается на блочно-диагональную матрицу с двумя блоками: $G=\begin{bmatrix}X&0\\0&Y\end{bmatrix}$. Где Х -- диагональная матрица от уже выбранных k векторов, а Y - матрица от новых векторов. При этом определитель новой матрицы не ноль, а значит существует хотя бы один ненулевой элемент (далее смотрим на пункт 1 доказательства)
9. Реально осуществимый алгоритм реализации чего-то похожего - процесс ортогонализации

**Свойства ортогонального дополнения**
Пусть $\dim V = n$, $L\subset V$ подпространство. Тогда
0. $L^\perp\subset V$ и $L^\perp=\langle L\rangle^\perp$ (очевидно)
1. $\dim L^\perp \ge n - \dim L$
2. $\dim L^\perp = n - \dim L$, если $\det G_{\varphi|_L}\ne 0$ (то есть ограничение $\varphi$ на $L$ не вырождено) 
3. $\dim L^\perp = n - \dim L$, если $\det G\ne 0$ (то есть $\varphi$ не вырождено)
**Доказательство**
- Первые два пункта уже были доказаны во время доказательства теоремы. Докажем пункт 3
- Рассмотрим $v_i$ базис $L$ размерности $k$. Размерность ортогонального дополнения -- это размерность линейного отображения, заданного $\varphi$ на векторах-базисах $V$: $\begin{bmatrix}\varphi(v_1,x)\\\cdots\\ \varphi(v_n,x)\end{bmatrix}:V\longrightarrow F^n$, но ограниченного на выбранный базис $L$; данная же матрица просто равна матрице Грама (достаточно подставить std базис). Раз исходная матрица не вырождена, то данное отображение обратимо, а строки - линейно независимы
- Тогда сужение будет иметь $k$ линейно независимых строк (для первых $k$) векторов. Тогда ранг матрицы равен $k$, размерность образа равна $k$, а размерность ортогонального дополнения $n-k$, что и требовалось доказать

**Пример**
Для билинейной формы, заданной матрицей Грама $\begin{bmatrix}0&1\\1&0\end{bmatrix}$ оказывается, что вектор $e_1$ перпендикулярен сам себе, равно как и вектор $e_2$.
**Дополнение**
Как можно заметить, симметричная билинейная форма вводит структуру, несколько напоминающую по свойствам скалярное произведение. Действительно, за данную симметричную билинейную форму мы можем взять обычное скалярное произведение, и тогда пространство окажется Евклидовым. В общем, в некотором роде это всё обобщение понятия скалярного произведения
## Дополнительные свойства ортогонального дополнения
**Предложение** (о невырожданности билинейной формы)
Для симметричной билинейной формы следующие условия равносильны:
1. Существует базис, в котором матрица Грама не вырождена
2. Для любого базиса матрица Грама не вырождена
3. Если $\varphi(u,x)=0\;\;\forall x\in V$, то $u=0$ (то есть $V^{\perp_\varphi}=0$)\[1]
4. $\forall v \ne0:\;\;\exists x\in V:\;\varphi(v,x)\ne0$
**Доказательство**
- 1 <=> 2 очевидно из связи матрицы Грама в разных базисах
- 2 => 3: см. пункт номер три _Свойств ортогонального дополнения_
- 3 => 4: 4й пункт просто переформулировка 3го с отрицанием
- 3 => 1: Данный $u$ является решением системы линейных уравнений формата $\varphi(u,v_i)=0$. Система от $n$ переменных с $n$ уравнениями имеет лишь тривиальное решение, а размерность решения равна $n-\text{rank }$G => матрица Грама обратима, потому что её ранг равен $n$.
**Пояснение**
1. Для несимметричных форм данное условие распадается на два: для левого и правого дополнения. Однако это лишь тривиально усложняет доказательство

**Дополнительные свойства ортогонального дополнения** (для невырожденной матрицы)
Для невырожденной симметричной билинейной формы и $L,M\subset V$ выполнены свойства:
1. ${(L^{\perp_\varphi})}^{\perp_\varphi}=L$
2. $(L+M)^{\perp_\varphi}=L^{\perp_\varphi}\cap M^{\perp_\varphi}$ \[1]
3. $(L\cap M)^{\perp_\varphi}=L^{\perp_\varphi}+ M^{\perp_\varphi}$
4. $L\subset M \Leftrightarrow L^\perp\supset M^\perp$

**Доказательство**
1. $\dim L^\perp = n - \dim L$, если $\det G\ne 0$ => $\dim {L^\perp}^\perp = n - \dim L^\perp =\dim L$. При этом $L\subset {(L^{\perp_\varphi})}^{\perp_\varphi}$ по определению
2. $u \in (L+M)^{\perp_\varphi} \;\;\Leftrightarrow\;\; \forall x\in L, \;\forall y\in M:\;\;\varphi(u,x+y)= 0 =\varphi(u,x)+\varphi(u,y) \;\;\Leftrightarrow\;\;\begin{cases}\forall x\in L:\varphi(u,x)=0\\ \forall y\in M:\varphi(u,y)=0\end{cases}$. Импликация вправо следует из того, что под "любым" $y$ для данного $x$ может подразумеваться и $0$. Аналогично и для данного $y$ может быть выбран и $x=0$. Влево -- сумма двух нулей равна нулю
3. По свойству 1 понятно, что $L=M\Leftrightarrow L^{\perp_\varphi} = M^{\perp_\varphi}$ \[2]. Проверим следующее свойство: ${((L\cap M)^{\perp_\varphi})}^{\perp_\varphi}={(L^{\perp_\varphi}+ M^{\perp_\varphi})}^{\perp_\varphi}$. Слева стоит $L\cap M$. Справа (по свойству 2) стоит оно же
4. Следует из пункта 1 (вправо -- по определению, влево -- разворотом импликации и свойству 1)

**Пояснение**
1. Вообще-то тут невырожденность матрицы и не нужна
2. Вправо просто очевидно, влево -- по свойству 1 потому что пространство может быть записано как ${(L^{\perp_\varphi})}^{\perp_\varphi}=L$

**Дополнение**
Благодаря описанным выше свойствам ортогональные дополнения могут быть использованы для решения задач на нахождение пересечения подпространств
## Квадратичная форма
**Определение**
1. **Квадратичная форма** -- многочлен от n переменных, где сумма степеней каждого одночлена равна двум \[1]
2. Отображение $\pi:\;V\longrightarrow F$ называется квадратичной формой, если существует базис, в котором данная форма записывается как однородный многочлен степени два от кординат вектора в векторном пространстве $V$ над полем $F$ (то есть как $\sum_{i,j=1}^na_{ij}x_ix_j)$.\[2]

**Пояснение**
1. То есть каждый одночлен данного многочлена имеет равную сумму степеней. Такие многочлены называются **однородными**
2. Здесь мы сделали вид, будто характеристика поля не равна двум. Потому что при характеристике, равной двум, могут возникнуть определённые сложности

**Замечание**
При линейной замене переменных (т.е. такой, что выражается через обратимую матрицу в виде: $\begin{bmatrix} x_1' \\ \vdots \\ x_n' \end{bmatrix}=C\begin{bmatrix} x_1 \\ \vdots \\ x_n \end{bmatrix}$) в квадратичной форме \[форме степени $k$] у нас также получится квадратичная форма \[форма в степени $k$]

**Предложение** (матричная форма записи квадратичной формы)
$$\overline{x}^T\begin{bmatrix}a_{11}&\cdots&a_{1n}\\\vdots&\ddots&\vdots\\ a_{n1}&\cdots&a_{nn}\end{bmatrix}\overline{x}=\sum_{i,j=1}^na_{ij}x_ix_j$$
**Предложение** (вид матрице при замене базиса)
$$\begin{bmatrix}a_{11}'&\cdots&a_{1n}'\\\vdots&\ddots&\vdots\\ a_{n1}'&\cdots&a_{nn}'\end{bmatrix}=C^T\begin{bmatrix}a_{11}&\cdots&a_{1n}\\\vdots&\ddots&\vdots\\ a_{n1}&\cdots&a_{nn}\end{bmatrix}C$$
**Пояснение**
1. Первое вычисляется прямо
2. Второе - через ассоциативность умножения матриц
3. Важно, что в самом многочлене перед $x_ix_j$ стоит коэффициент, равный сумме $a_{ij}+a_{ji}$, оттого запись данной матрицы неоднозначен: для другой записи той же квадратичной формы достаточно, чтобы эта сумма при разных коэффициентах оставалась той же. **Матрицей Грама** квадратичной формы в данном базисе называется симметричная матрица данной формы (то есть $a_{ij}=a_{ji}$). При замене базиса симметричность сохраняется

**Замечание**
- Пусть $\gamma: V\longrightarrow V$ - линейное преобразование. $D$ - его матрица в данном базисе над $V$. 
- Рассмотрим $X_\pi=\{v\in V: \pi(v)=1\}$ (гиперповерхность второго порядка). 
- Рассмотрим $\gamma(X_\pi)=\{\gamma(v)\in V:\;\pi(v)=1\}$
Напишем уравнение данного образа $\gamma(X_\pi)$. Оно будет записано в виде $\pi_\gamma: V\longrightarrow F$, что $\gamma(X_\pi)=\{v\in V:\;\pi_\gamma(v)=1\}$. Известно, что изначальная гиперповерхность имела вид $$\overline{x}^TA\overline{x}=1$$
Применяем преобразование над $x$. Получим: $$\overline{y}^T{D^{-1}}^TAD^{-1}\overline{y}=1,\;\;\;\;\text{ где } \begin{bmatrix} y_1 \\ \vdots \\ y_n \end{bmatrix}=D\begin{bmatrix} x_1 \\ \vdots \\ x_n \end{bmatrix}$$
То есть в качестве $\pi_\gamma$ можно взять _в том же базисе_ матрицу формата ${D^{-1}}^TAD^{-1}$. Также: $\pi_\gamma(v)=\pi(\gamma^{-1}(v))$.


## Соответствие между квадратичными и (симметричными) билинейными формами
**Теорема**
1. Если $\varphi:\;V\times V\longrightarrow F$ - симметричная билинейная форма, то $\pi(v)=\varphi(v,v)$ - квадратичная форма.
2. Если $\pi: V\longrightarrow F$ - квадратичная форма, то соответствующая симметричная билинейная форма - $\varphi(u,v)=\frac12(\pi(u+v)-\pi(u)-\pi(v))$
3. Данные конструкции являются взаимнообратными
**Доказательство**
- $\varphi(u,v)=\varphi(\sum x_ie_i, \sum y_ie_i)=\sum x_i(\sum y_j\varphi(e_i,e_j))=\sum x_iy_i\varphi(e_i,e_j)$. При этом для $\varphi(u,u)$ мы получим квадратичную форму с той же матрицей Грама (получим аналогичную формулу)
- $\frac12[(\sum (x_i+y_i)(x_j+y_j)a_{ij}-\sum x_ix_ja_{ij}-\sum y_iy_ja_{ij}]$ =$\frac12[(\sum (x_ix_j+x_iy_j+y_ix_j+y_iy_j-x_ix_j-y_iy_j) a_{ij}]$ = $\frac12[(\sum (x_iy_j+x_jy_i)a_{ij}]$ = $\sum x_iy_ia_{ij}$. Аналогичное можно расписать и через матрицы
- Из того, что матрицы Грамма при переходе сохраняются, следует взаимная однозначность данного "преобразование" форм друг в друга
**Пояснение**
1. Если билинейную форму взять не симметричной, то будет меняться матрица Грама (на $\frac{A+A^T}2$)
## Процесс ортогонализации
**Теорема**
Пусть $V$ - пространство с заданной симметричной билинейной формой. Причём данная симметричная билинейная форма не вырождена на любом своём сужении относительно векторов данного базиса ($h|_{{\langle v_1,...,v_n\rangle}}$ не вырождено для любого $k$)
Тогда существует ортогональный базис, что $\langle e_1,...,e_k\rangle=\langle v_1,...,v_k\rangle\;\;\forall k$\[1]
**Доказательство**
- Докажем по интукции по $n$. Для одного вектора доказывать нечего
- Делаем переход. Пусть имеется ортогональный базис  $\langle e_1,...,e_k\rangle=\langle v_1,...,v_k\rangle$ для любого $k$ от $1$ до $n-1$. Теперь найдём такой базис для $n$. Пусть теперь $e_n=v_n-\sum a_ie_i$ (методом неопредпределённых коэффициентов). Для этого нам нужно систему уравнений вида $\varphi(e_k,e_n)=0=\varphi(e_k,v_n)-\sum a_i\varphi(e_k,e_i)\overset{[2]}{=}\varphi(e_k,v_n)-a_k \varphi(e_k,e_k)$. 
- Отсюда следует, что $a_k=\frac{\varphi(e_k,v_n)}{\varphi(e_k,e_k)}$\[3]
- Осталось проверить, что $\langle e_1,...,e_n\rangle=\langle v_1,...,v_n\rangle$. Известно, что $e_k\in\langle v_1,...,v_n\rangle$, $v_k\in\langle e_1,...,e_n\rangle$ для всех $k$ от $1$ до $n-1$. Осталось проверить принадлежность для $k=n$. В обоих случаях эта принадлежность есть по построению ($e_n\in\langle e_1,...,e_{n-1},v_n\rangle\subset\langle v_1,...,v_n\rangle$)
**Пояснение**
1. Это равносильно тому, что матрица перехода от обычного базиса к ортогональному верхне-треугольная. Действительно, рассмотрим следующее уравнение: $\begin{bmatrix}e_1\\\vdots\\ e_n\end{bmatrix}=\begin{bmatrix}a_{11}&\cdots&0\\ \vdots&\ddots&\vdots\\ X & \cdots & a_{nn}\end{bmatrix}\begin{bmatrix}v_1\\\vdots\\ v_n\end{bmatrix}, \;\;\;\text{ где } e_k=\sum v_ie_{ki}$. При этом оказывается, что элементы на диагонали -- единицы
2. Потому что известна ортогональность векторов $\{e\}$ между собой. Тогда $\varphi(e_i,e_k)=0$ только если $k=i$
3. Мы имеем право так сделать, потому что $\varphi(e_k,e_k)$ не равно нулю. Матрица Грама $\varphi$ над бизисом из $\{e\}$ диагональна (потому что все остальные перпендикулярны) и при этом эта же матрица не вырождена при любом $k$, поэтому на диагонали не могут стоять нули 

**Матричная переформулировка теоремы**
Если имеется симметричная матрица $A\in M_n(F)$ и для любого её **главного углового минора** $\det A_{1,2,...,k}^{1,2,...,k}\ne0\;\;(\forall k)$, то существует верхнетреугольная матрица $V\in M_n(F)$, что $V^TAV$ диагональна (потому что получается матрица Грама этой же билинейной формы в ортогональном базисе)
Это же называется приведением квадратичной формы к сумме квадратов - потому что в таком выбранном базисе квадратичная форма будет записана в диагональном виде, а значит ненулевыми будут коэффициенты лишь при квадратах  

**Переформулировка Теоремы Лагранжа**
Для симметричной билинейной формы $\varphi$. 
- Возьмём индукцию по $n$. Если $\varphi$ вырождена, то берём вектор, который ортогонален всем ($v_1\in V^\perp$), дополним до базиса. Рассмотрим $V'=\langle v_2,...,v_n\rangle$. По индукционному предположению в этом $V'$ найдётся ортогональный базис $\{u_i\}$, тогда и $\langle v_1,u_1,...,u_n\rangle$ (при этом $\langle v_1\rangle\oplus V'=V$ по одному из равносильных определений базиса). Матрица Грама при этом будет выглядеть как $\begin{bmatrix}0&0&\cdots&0\\0&X&\ddots&0\\\vdots&\ddots&\ddots&\vdots   \\0&\cdots&\cdots&X\end{bmatrix}$ (окаймлённая нулями диагональная матрица)
- Если $\varphi$ не вырождена, то найдутся такие $u,v\in V:\;\;\varphi(u,v)\ne0$.  Если $\varphi(v,v)\ne0$, то $V=\langle v\rangle\oplus \langle v\rangle^\perp$. Если $\varphi(v,v)=\varphi(u,u)=0$, то матрица Грама на сужении $\varphi|_{\langle v,u\rangle}$ будет выглядеть как $\begin{bmatrix}0&c\\ c&0\end{bmatrix}$, $c=\varphi(u,v)\ne0$, то есть не вырожденная, а значит $V=\langle u,v\rangle\oplus\langle u,v\rangle^\perp[1]$. Ортогональное дополнение диагонализуется по ИП, осталось диагонализовать данную матрицу Грама. Для этого достаточно умножить её на $\begin{bmatrix}1&1\\ 1&-1\end{bmatrix}$ слева и на её (транспонированную, которая такая же) справа\[2]\[3]
**Пояснение**
1. Прямая сумма потому, что $L\cap L^{\perp_\varphi}$ при невырожденной $\varphi$ равно только лишь нулевому вектору
2. Если характеристика 2, то данная матрица имеет нулевой определитель. Поэтому условие на характеристику, не равную двум, по-прежнему остаётся важным 
3. Эта матрица отвечает за замену $x = x'+y',\;y=x'-y'$
## Классификация квадратичных форм
**Эквивалентные квадратичные формы**
Назовём две квадратичные формы $\pi \text{ и } \pi'$ эквивалентными, если существует такое обратимое линейное преобразование $\gamma$, что $\pi'=\pi_\gamma$.
В общем виде вопрос о том, какие КФ эквивалентны, нетривиален. Пример: квадратичные формы $2x^2+y^2$ и $3x^2+y^2$ эквивалентны над $\mathbb{R}$ и не эквивалентны над $\mathbb{Q}$. Для эквивалентных КФ верно такое выражение: $A'=C^T\times A\times C$, то есть $\det A' = (\det C)^2(\det A)$. В данном случае получится $2=3c^2$, тогда $c=\sqrt{\frac32}\notin \mathbb{Q}$. 
Условие на существование при этом является хоть и необходимым, но не достаточным. Оказывается, что КФ $x^2+6y^2$ и $2x^2+3y^2$ не эквивалентны в $\mathbb{Q}$, но связаны таким уравнением (а не эквивалентны они потому, что у правой существует решение, при котором она равна двум (x=1, y=0), а у левой - нет \[задача из теории чисел])

**Предложение**
Две квадратичные формы над $\mathbb{C}$ эквивалентны $\Leftrightarrow$ их размерности равны (то есть если они от одного числа переменных) и равны ранги их матриц
**Доказательство**
- => очевидно по соотношению $A'=C^TAC$
- <= очевидно, потому что каждая из данных КФ приводится к диагональному виду. После такого приведения достаточно одну из них умножить на необходимую $C$, которую достаточно выбрать диагональной, а действия над диагональными матрицами выполняются покомпонентно. Равенство рангов важно, так как при диагонализации должно остаться одинаковое количество ненулевых значений

**Классификация КФ над полем вещественных чисел**
- Заметим, что над $\mathbb{R}$ любая квадратичная форма эквивалентна следующей: $$\begin{bmatrix}1&&|&&&|\\&\underset{k\text{ шт.}}{\ddots}&|&&&|\\-&-&1&&&|\\&&&-1&&|\\&&&&\underset{l\text{ шт.}}{\ddots}&|\\-&-&-&-&-&-1\\&&&&&&0\\&&&&&&&\ddots\end{bmatrix}\;\;\approx\;\;x_1^2+\cdots+x_k^2-x_{k+1}^2-\cdots-x_{k+l}^2$$ Здесь $k+l$ равен рангу матрицы Грама данной КФ. Это так, потому что каждую $\lambda_kx_k^2$ можно представить как $\frac{\lambda_k}{|\lambda_k|}(\sqrt{|\lambda_k|}x_k)^2=\pm(\sqrt{|\lambda_k|}x_k)^2$, откуда очевиден вид линейного преобразования
- **Закон интерции Сильвестра**. Если две квадратичные формы эквивалентны, они эквивалентны одной и той же форме, представленной выше. Доказательство этого факта следующее: рассмотрим два таких приведения $x_1^2+\cdots+x_k^2-x_{k+1}^2-\cdots-x_{k+l}^2\sim x_1^2+\cdots+x_p^2-x_{p+1}^2-\cdots-x_{p+q}^2$. Очевидно, что $p+q=k+l$ (потому что это ранг соответствующих матриц, при неравенстве они неприводимы даже над большим полем $\mathbb{C}$). Допустим, что $k>p$, тогда $l<q$. Обозначим базис слева как $u_1,...,u_{k+l}$, справа - $v_1,...,v_{p+q}$. Рассмотрим такие пространства: $\langle u_1,...,u_k,u_{k+l+1},...,u_n \rangle$ и $\langle v_{p+1},...,u_{p+q} \rangle$. Сумма размерностей этих пространств больше размерности изначального пространства (то есть больше $n$). То есть пересечение этих пространств ненулевое. Тогда существует некоторый ненулевой вектор $v$ из пересечения. Однако при подсчёте значений квадративных форм для первого пространства получим неотрицательное число, а для второго - строго меньше нуля, чего быть не может, ведь квадратичная форма одна и та же. Противоречие 
Таким образом для того, чтобы две КФ были эквивалентны над $\mathbb{R}$ необходимо и достаточно, чтобы они имели одинаковую размерность, ранг их матриц был одинаков, а также если $\pi$ и $\pi'$ и количество + и - в приведении должно быть одинаково
## Сигнатура, правило знаков Якоби, критерий Сильвестра
**Сигнатура**
Сигнатурой квадратичной формы называется кортеж $(k,l)$, соответствующий расстановке знаков в указанном выше приведении данной КФ $$x_1^2+\cdots+x_k^2-x_{k+1}^2-\cdots-x_{k+l}^2$$
Именование КФ размерности $n$ над $\mathbb{R}$:

| Сигнатура       | Название                                            | Значение                  |
| --------------- | --------------------------------------------------- | ------------------------- |
| $(n,0)$         | Положительно определённая (для невырожденной)       | $\forall v\ne0: \pi(v)>0$ |
| $(r,0), r\le n$ | Неотрицательно определённой (для вырожденной в т.ч) | $\forall v:\pi(v)\ge0$    |

**Правило знаков Якоби**
Рассмотрим невырожденную квадратичную форму $\pi$ над $\mathbb{R}$. Пусть все главные миноры $\Delta$ - ненулевые. Тогда количество знаков минус, указанное в сигнатуре, равно количеству перемен знака от $\Delta_i$ к $\Delta_{i+1}$, то есть сама $\pi$ эквивалентна КФ:$$\frac{\Delta_1}{\Delta_0}x_1^2+\frac{\Delta_2}{\Delta_1}x_2^2+...+\frac{\Delta_n}{\Delta_{n-1}}x_n^2$$

**Критерий Сильвестра**
$\pi$ положительно определена $\Leftrightarrow$ все её главные миноры положительны
**Доказательство**
- Следствие правила знаков Якоби. Рассмотрим $\pi$ и соответствующую ей билинейную форму $\varphi$. По условию известно, что билинейная форма $\varphi$ невырождена на любом своём сужении $\varphi|_{\langle v_1,...,v_k\rangle}$\[1]
- В этом случае (=>) существует базис, в котором $\pi$ принимает диагональный вид (<=) существуют базисы каждого из сущений, в которых матрицы принимают диагональный вид. Всё это ортогональные базисы, где $\langle e_1,...,e_k\rangle=\langle v_1,...,v_k\rangle$. При этом матрица перехода между базисами имеет определитель, равный единице\[2]
- Переходим к этому базису. Получается: $\Delta_k=\det C^T (d_1\cdot...\cdot d_k) \det C=d_1\cdot...\cdot d_k$. Таким образом $d_k=\frac{\Delta_k}{\Delta_{k-1}}$, сами элементы $d_k$ стоят в диагонали матрицы Грама, а значит определяют вид приведённой к указанному в правиле знаков Якоби виду квадратичной формы
**Пояснение**
1. (=>) потому что она положительно определена, а значит не вырождена (<=) потому что определители матриц Грама каждого такого сужения - главные миноры, которые положительны
2. Об этом говорилось в параграфе про процесс ортогонализации. Матрица перехода верхнетреугольная формата $\begin{bmatrix}e_1\\\vdots\\ e_n\end{bmatrix}=\begin{bmatrix}a_{11}&\cdots&0\\ \vdots&\ddots&\vdots\\ X & \cdots & a_{nn}\end{bmatrix}\begin{bmatrix}v_1\\\vdots\\ v_n\end{bmatrix}$. Определитель такой матрицы считается как произведение элементов, стоящих на диагонали. На диагонали стоят единицы
# Многочлены от нескольких переменных
## Определение многочлена от нескольких переменных
**Определение 1** (на примере многочлена от двух переменных)
$$R[x,y]=(R[x])[y],\;\;a\in R[x,y]:\;a=a_0(x)+...+a_n(x)y^n, \text{ где }a_i(x)\in R[x]$$
Иная форма записи:
$$a\in R[x,y]:\;\;\sum_{i,j=0}a_{ij}x^iy^j$$
#PURGE видимо, два свойства: $(x^iy^k)(x^jy^l)=x^{i+j}y^{k+l}$, $(0,...,0,\underset{k}{x},0,...)(0,...,0,\underset{l}{x},0,...)=(0,...,0,\underset{k+l}{x},0,...)$

**Определение 2**
Пусть $(M,\circ)$ - моноид, $R$ - ассоциативное кольцо с единицей. Рассмотрим множество $R[M]=\{f: M\longrightarrow R, \text{ для почти всех[1] }m\in M:\;f(m)=0\}$
- Сложение задаётся почленно: $(f+g)(m)=f(m)+g(m)$
- Умножение - свёрткой: $(fg)(m)=\sum_{m_1\circ m_2=m}f(m_1)g(m_2)$
**Пояснение**
1. Для почти всех - для всех (бесконечного числа), за исключением конечного числа элементов

**Предложение**
Заданное на $R[M]$ умножение - корректно определённая ассоциативная операция
**Доказательство**
- Корректность (здесь под корректностью подразумеваем конечность итоговой суммы): определим $\text{supp}f=\{m\in M:\;f(m)\ne0\}$. Понятно, что $|\text{supp }f|<+\infty$ 
- Ассоциативность: $((fg)h)(m)=\sum_{m_1\circ m_2=m}(fg)(m_1)h(m_2)=\sum_{m_3\circ m_4=m_1}\bigl[f(m_3)g(m_4)\sum_{m_3\circ m_4\circ m_2=m}h(m_2)\bigr]$$=\sum_{m_3\circ m_4\circ m_2=m}f(m_3)g(m_4)h(m_2)$$(f(gh))(m)=\sum_{m_1\circ m_2=m}f(m_1)(gh)(m_2)=\sum_{m_1\circ m_2=m}\bigl[f(m_1)\sum_{m_3\circ m_4= m_2}g(m_3)h(m_4)\bigr]$=$\sum_{m_1\circ m_3\circ m_4=m}f(m_1)g(m_3)h(m_4)$ 
  Получили аналогичную запись с разницей только в обозначениях
**Свойства**
- $(fg)(m)\ne0\Rightarrow\exists m_1,m_2:\;f(m_1)\ne0,\;g(m_2)\ne0,\;m_1\circ m_2=m$
- $\text{supp }(f+g)\subset \text{supp }f +\text{supp }g$
**Доказательство**
1. очевидно
2. Пусть $A,B\subset M$. Пусть $AB=\{x\circ y:\;\;x\in A,\;y\in B\}$. Тогда $|AB|\le|A||B|$ (очевидно, потому что некоторые суммы могут совпадать, тогда как произведение мощностей задаёт количество всех возможных сумм без учёта повторения)

**Дельта-функция, нейтральный элемент**
- Пусть $\delta_m(x)=\begin{cases}1&\text{if }x=m\\0&\text{otherwise }\end{cases}$. Такую функцию называют **дельта-функцией с носителем в точке $m$**. 
- $(\delta_m\delta_n)(z)=\sum_{x\circ y=z}\delta_m(x)\delta_n(y)=\delta_{m\circ n}$. 
- Также можно задать готометию: $\underset{m\longmapsto \delta_m}{M\hookrightarrow R[m]}$ 
- Если не различать $\delta_m$ и $m$, то $f_{\in R[m]}=\sum_{m\in M}a_mm$, $a_m\in R$
- Пусть $e\in M$ - нейтральный элемент. Тогда $\sum_{m_1\circ m_2=m}f(m_1)\delta_e(m_2)=f(m)$, потому что $m_2=e\Rightarrow m_1=m$ 

**Примеры**
- Обычное кольцо многочленов: $M=(N_0,+)$, $f_{\in R[M]}=a_0+a_1[1]+a_2[2]+...=a_0+a_1x+...$
- Многочлен от двух переменных: $M=(N_0\times N_0,+_{\text{почленное}})$, $f\in R[M]=a_{00}+a_{01}[0,1]+a_{10}[1,0]+...=a_{00}+a_{01}y+a_{10}x+a_{11}xy+...$
В конечном итоге в дальнейшем будет использоваться оба определения, преимущественно будет идти речь про формальные линейные комбинации - то есть по подобию первого определения

**Пример: групповая алгебра циклической группы**
Пусть $C_n$ - циклическая группа. $C_n=\{e,s,s^2,...,s^{n-1}\}$
**Утверждение**
Пусть $R$ - коммутативное кольцо с единицей
$R[C_n] \cong R[X]/(X^n-1)$. Это вообще говоря очевидно, так как все возможные остатки от деления на $X^n-1$ и представляют из себя все возможные многочлены степени максимум $n-1$. 

**Пример: расширенная моноидная алгебра**
Предположим, что в данном моноиде выполнено следующее условие: $\forall m\in M$ существует лишь конечное число пар формата $(x,y)\in M\times M:\;\; x\circ y=m$. Тогда свёртка (умножение) определена на всех функций $R^M$. Обозначнение: $R[[M]]$. Примером такого кольца является $R[[N_0]]$ - кольцо [формальных степенных рядов](https://ru.wikipedia.org/wiki/%D0%A4%D0%BE%D1%80%D0%BC%D0%B0%D0%BB%D1%8C%D0%BD%D1%8B%D0%B9_%D1%81%D1%82%D0%B5%D0%BF%D0%B5%D0%BD%D0%BD%D0%BE%D0%B9_%D1%80%D1%8F%D0%B4).
## Теорема Виета
**Определение**
- Пусть $F[x_1,...,x_n]$. Многочлен называется симметричным, если при любой перестановке переменных $s:\;[1,2,...,n]\longrightarrow [1,2,...,n]$: $f(x_1,...,x_n)=f(x_{s(1)},...,x_{s(n)}):= ^sf$. Ранее уже было доказано, что $^{sg}f= ^s(^gf)$.
- **Элементарный симметрические многочлены** степени $k$ - $\sigma_k(x_1,...,x_n)=\sum_{1\le j_1<...< j_k\le n}x_{j_1}\cdot...\cdot x_{j_k}$
- **Однородные симметрические многочлены** степени к - $h_k(x_1,...,x_n)=\sum_{1\le j_1\le ...\le j_k\le n}x_{j_1}\cdot...\cdot x_{j_k}$

**Замечание**
Симметрические многослены образуют подкольцо, то есть произведение и сумма симметрических многочленов симметричны (это прямое следствие того, что нет никакой разницы, сначала поменять элементы и сложить или сначала сложить, а потом поменять местами элементы)

**Теорема Виета**
Раскрываем скобки в $(T-x_1)(T-x_2)...(T-x_n)\in F[x_1,...,x_n][T]$. Тогда коэффициенты перед степенью $T$ равны элементарным симметрическим функциям от $x_1,...,x_n$.
**Доказательство**
Тривиально
**Следствие** (теорема, обратная теореме Виета)
Если многочлен $f=a_0+...+a_nT^n$ раскладывается на линейные множители, то $a_k=(-1)^{n-k}\sigma_k(\alpha_1,...,\alpha_n)$.
**Доказательство**
- Имеется гомоморфизм подстановки значения $F[x_1,...,x_n][T]\longrightarrow F[T]$. Просто подставим в произведение $(T-x_1)(T-x_2)...(T-x_n)$ значения $\alpha_i$ вместо $x_1,...,x_n$. Слева сначала подставим значение, а потом перемножим. Справа - сначала раскроем скобки, а потом подставим. Получим искомое

## Формула Ньютона для степенных рядов
#PURGE???
**Замечание**
Рассмотрим $F[x_1,...,x_n][[T]]$ (кольцо формальных степенных рядов). В нём рассмотрим $$\frac{1}{1-Tx_1}\frac{1}{1-Tx_2}...\frac{1}{1-Tx_n}=\prod(1+Tx_i+T^2x_i^2+...)=\sum_{k=0}^\infty h_k(x_1,...,x_n)T^k$$
**Следствие**
$$\prod(1-Tx_i)=\sum(-a)^k\sigma_k(x_1,...,x_n)T^k$$
Перемножим с формулой, написанной выше. Получим: $$\sum^k_0 (-1)^i\sigma_ih_k=0$$
**Формулы Ньютона**
Рассмотрим **степенную сумму** $p_k(x_1,...,x_n)=x_1^k+...+x_n^k$. Рассмотрим выражение $p_k$ через элементарные симметрические многочлены $\sigma_k$ $$\displaylines{p_k-p_{k-1}\sigma_1+...+(-1)^{k-1}p_1\sigma_{k-1}+(-1)^kk\sigma_k=0,\;\;\;k\in[1,n]\\p_k-p_{k-1}\sigma_1+...+(-1)^{n-1}p_{k-n+1}\sigma_{n-1}+(-1)^kp_{k-n}\sigma_n=0,\;\;\;k>n}$$
**Доказательство**
- Рассмотрим многочлен $$f(y)=(y-x_1)(y-x_2)...(y-x_n)=y^n-\sigma_1y^{n-1}+...+(-1)^n\sigma_n$$ над $F[x_1,...,x_n,y]$. Подставив $y=x_i$, получим: $$x_i^n-\sigma_1x_i^{n-1}+...+(-1)^n\sigma_n=0$$Пусть $k\ge n$, умножим на $x_i^{k-n}$, получим: $$x_i^k-\sigma_1x_i^{k-1}+...+(-1)^n\sigma_nx^{k-n}_i=0$$Из его посредством суммирования получается формула для $k>n$ и для $k=n$.
- Рассмотрим симметрический однородный многочлен степени $k\le n$$$h_k(x_1,...,x_n)=p_k-p_{k-1}\sigma_1+...+(-1)^{k-1}p_1\sigma_{k-1}+(-1)^kk\sigma_k$$Докажем его тождественное равенство нулю. Доказывать будем по индукции $r=n-k$. Для $r=0$ (то есть для $n=k$) равенство нулю уже установлено. Рассмотрим теперь многочлен $$h_k(x_1,...,x_{n-1},0)=\overline{p_k}-\overline{p}_{k-1}\overline{\sigma}_1+...+(-1)^{k-1}\overline{p}_1\overline{\sigma}_{k-1}+(-1)^kk\overline{\sigma}_k,\;\;x_n=0$$И заметим, что $\overline{p}_i,\overline{\sigma}_i$ над $F[x_1,...,x_{n-1},0]$ выглядят так же, как над $F[x_1,...,x_{n-1}]$. Тогда заключим, что $h_k(x_1,...,x_{n-1},0)=h_k(x_1,...,x_{n-1})\overset{\text{по ИП[1]}}{=}0$.
- Этот факт влечёт то, что многочлен $h_k(x_1,...,x_n)$ делится на $x_n$. Проводя аналогичные действия с остальными $x_i$ получим, что $h_k$ делится на них всех, то есть содержит их всех в качестве множителей. Тогда $h_k=x_1\cdot...\cdot x_n\cdot g(x_1,...,x_n)$, но $\deg h_k=k <n$, а в свою очередь $\deg(x_1x_2...x_n)=n$. То есть это возможно лишь когда $g(x_1,...,x_n)=0$. Таким образом, $h_k(x_1,...,x_n)=0$
 **Пояснение**
 1. $h_k(x_1,...,x_{n-1})\in F[x_1,...,x_{n-1}]$. Для него $r'=n-1-k<n-k=r$, то есть применимо ИП.

**Выражение через определитель**
$$p_n=\begin{bmatrix}\sigma_1&1&0&\cdots&\\2\sigma_2&\sigma_1&1&0&...\\\vdots&&\ddots&\ddots\\&&&\ddots\\n\sigma_n&\sigma_{n-1}&\sigma_{n-2}&\cdots&\sigma_1\end{bmatrix}$$

## Основная теорема о симметрических многочленах
**Определение**
- Заметим, что при подстановки $y_k=\sigma_k$ в одночлен $y_1^{i_1}...y_n^{i_n}$, входящий в $g$, мы получим многочлен от $x_1,...,x_n$ степени $i_1+2i_2+...+ni_n$. Эту сумму степеней назовём весом такого одночлена. Вес многочлена - максимальный из весов его одночленов
- Одночлены мы будем расставлять в **лексикографическом порядке**. Это значит, что одночлен $u=\alpha x_1^{i_1}...x_n^{i_n}$ стоит раньше $v=\beta x_1^{j_1}...x_n^{j_n}$ тогда и только тогда, когда последовательность разности степеней $\{i_1-j_1,i_2-j_2,...,i_n-j_n\}$ имеет вид $\{0,0,...,0,t_{>0},...\}$.
- Одночлен, стоящий в лексикографическом порядке первее всех, называется **высшим членом** многочлена $f$. Обозначим его как $LM(f)$.
- Одночлен $u=\alpha x_1^{i_1}...x_n^{i_n}$ назовём монотонным, если $i_1\ge i_2 \ge...$

**Лемма 1**
Высший член произведения $h=h_1...h_r$ - произведение высших членов $h_1,...,h_r$.
**Доказательство**
- Для количества переменных $n=1$ это утверждение очевидно. Далее рассмотрим $h=g_s\cdot x_1^s+g_{s-1}\cdot x_1^{s-1}+...$ с помощью итеративного деления с остатком на $x_1$. Этот же $g_s$ у нас получится, если разложить каждый из сомножителей $h_1,...,h_r$ по $x_1$, а затем "раскрыть скобки". Тогда $LM(h)=LM(g)\cdot x_1^s$. Но в многочлене $g_s$ не останется ни одного $x_1$, а значит в $g$ мы уменьшили количество слагаемых на 1. По индукционному переходу получим искомое равенство

**Лемма 2**
Высший член симметрического многочлена всегда монотонен
**Доказательство**
- Допустим, это не так. Рассмотрим $LM(f)=\alpha x_1^{i_i}...x_k^{i_k}x_{k+1}^{i_{k+1}}...$. Где в членах $k,k+1$ нарушена монотонность. Переставим местами $x_k,x_{k+1}$. Получим, с одной стороны, больший одночлен, а с другой - вновь входящий в $f$ по его симметричности. Значит, новый одночлен больше максимального - противоречие.  

**Теорема** (основная теорема о симметрических многочленах)
Любой симметрический многочлен $f$ степени $m$ над $F[x_1,...,x_n]$ представим как многочлен $g$ веса $m$ над $F[y_1,...,y_n]$ в виде:  $$f(x_1,...,x_n)=g(\sigma_1,...,\sigma_n)$$
**Доказательство** (существование)
- Заметим, что любой многочлен $f$ может быть разложен на однородные многочлены $f_i$ степени $i$. Причём данное разложение единственно (это в худшем случае тривиально доказывается). Одновременно с этим можно считать его симметрическим (тривиально, например, потому, что перестановка переменных в многочлене- это гомоморфизм). По причине возможности такого разложения мы будем далее считать $f$ однородным
- Рассмотрим монотонный $LM(f)$ = $\alpha x_1^{i_1}x_2^{i_2}...x_n^{i_n}$. Рассмотрим многочлен $\alpha \sigma_1^{i_1-i_2}\sigma_2^{i_2-i_3}...$, отвечающий за одночлен $\alpha y_1^{i_1-i_2}...$ веса $i_1+i_2+...=n=\deg f$. Рассмотрим высшие члены $\sigma_i$ - это $x_1...x_i$, таким образом выший член $\alpha \sigma_1^{i_1-i_2}\sigma_2^{i_2-i_3}...=\alpha x_1^{i_1}x_2^{i_2}...x_n^{i_n}$. Рассмотрим многочлен $f_{(1)}=f-\alpha \sigma_1^{i_1-i_2}\sigma_2^{i_2-i_3}...$ Очевидно, что $LM(f_{(1)})<LM(f)$. Продолжая действия итеративно строим строго убывающую последовательность высших членов, которая обрывается, так как одночленов фиксированной степени конечное число. В результате получим, что $f=f_{(1)}+f_{(2)}+...$ которые суть есть многочлены от $\sigma_i$
**Доказательство** (единственность)
- Допустим, существуют два различных $f=g_1=g_2$. В таком случае должны существовать два различных над $F[y_1,...,y_n]$ многочлена $g=g_1-g_2$ веса $\deg f$, что $g(\sigma_1,...,\sigma_n)=0$.
- Рассмотрим некоторый одночлен $a\sigma_1^{i_1}\sigma_2^{i_2}...$ Понятно, что $LM(a\sigma_1^{i_1}\sigma_2^{i_2}...)$$=ax_1^{i_1+i_2+...}x_2^{i_2+...}...x_n^{i_n}$. На этом основании можно заключить, что различным по сумме степеней одночленам над $F[y_1,...,y_n]$ соответствуют различные по сумме степеней одночлены $F[x_1,...,x_n]$. Таким образом всем одночленам, входящим в $g$ соответствуют разные одночлены после подстановки. Они все различны по степени, значит, какой-то из них будет иметь максимальную степень. А значит $LM(g(\sigma_1,...\sigma_n))\ne0$ 
## Факториальные кольца
**Определение**
Факториальным кольцом называется такое кольцо (Область Целостности, она же коммуникативное кольцо с единицей без делителей нуля), в котором верна Основная Теорема Арифметики (для любого ненулевого необратимого элемента существует разложение на неприводимые, которое единственно с точностьь до порядка сопрожителей и ассоциативности)

**Теорема** (уже доказанная ранее)
Критерий факториальности - ОЦ $R$ факториально тогда и только когда (одновременно выполнены следующие условия):
1. Любой неприводимый элемент -- простой
2. Выполнена Лемма о стабилизации (рассмотрена недалеко от ОТА)
**Доказательство**
- => Возьмём неприводимый $p$. Возьмём $ab\;|\;p$. Получится $ab=\frac{ab}{p}p$. Раскладываем $a,b,\frac{ab}{p}$ на множители. Слева от знака равно окажется $p$, значит, по единственности разложения, он окажется и справа, то есть будет ассоциирован с одиним из элементов разложения или $a$, или $b$. Получается, или $a\;|\;p$, или $b\;|\;p$. То есть элемент простой. Второе свойство следует из того, что каждый следующий элемент в последовательности имеет меньшее количество неприводимых множителей в разложении, чем предыдущий, пока мы не столкнёмся с ассоциированными элементами
- <= Аналогично доказательству для ОГИ, рассмотренному ранее, только лемма о стабилизации здесь постулируется.

**Каноническое разложение на множители** в факториальном кольце
Для любого необратимого элемента сущесвтует $a=e\prod_{p\in\mathbb{P}}p^{k_p}$, где $\mathbb{P}$ - система представителей классов ассоциированности простых элементов. Через них легко найти НОД и НОК (см. конспект ранее). То есть НОД существует!
## Содержание многочлена. Лемма Гаусса
**Содержание**
Пусть $R$ - факториальное кольцо. Тогда **содержанием** многочлена $p(x)\in R[X]$ называется НОД его коэффициенов. Обозначение - $\text{cont }p$.
- Многочлен называют **примитивным**, если его содержание равно единице.
- То есть у коэффициентов многочлена нет общего простого делителя
- Также из любого многочлена можно вынести его содержание. Получится, что каждый многочлен можно разложить на примитивный, умноженный на его содержание

**Лемма 1**
Пусть $p$ - простой элемент области целостности $R$. Тогда кольцо вычетов $R/pR$ - это область целостности. Причём это верно в обе стороны
**Доказательство**
- Это просто переформулировка определения на языке классов вычетов. Элемент простой: $ab\;|\;p\;\;\Rightarrow\;\; a\;|\;p\lor\;b\;|\;p$. Аналогично: $[a][b]=[ab]=0\;\;\Rightarrow\;\;[a]=0\;\lor\;[b]=0$. 

**Лемма 2**
Если $S$ область целостности, то $S[X]$ тоже область целостности
**Доказательство**
- Рассомтрим произведение старших коэффициентов. Раз $S$ область целостности, то их произведение не ноль. Тогда в произведении старших коэффициентов будет не ноль

**Лемма Гаусса**
Пусть $R$ факториальное кольцо. Тогда
1. Произведения примитивных многочленов примитивно
2. Для любых двух многочленов содержание их произведения равно произведению их содержаний
3. 1 и 2 равносильны
**Доказательство**
- Пусть $f,g$ примитивны. Допустим, что $fg$ не примитивно, тогда $fg=(\text{cont }fg)\cdot(f_0g_0)$. Само содержание раскладывается в неприводимые, они же простые. Рассмотрим простой $p$ из этого разложения. Переведём $R[S]\longrightarrow(R/pR)[X]$ (то есть в **редукцию** многочленов). Получим: $f\cdot g=fg\longrightarrow [f][g]=[fg]=0$\[1]. Но известно, что $[f]$ и $[g]$ не ноль, раз они не делятся на $p$ (потому что они примитивные). Противоречие лемме 1. 
- 2=>1 очевидно, 1=>2 тривиально (просто выносим содержание за скобки)
**Пояснение**
1. Этот перевод допускается потому, что редукция многочлена -- это гомоморфизм.

**Следствие**
Пусть $R$ - факториальное кольцо. Пусть $F$ - его поле частных. Тогда: многочлен $f\in R[X]$ степени больше 0 неприводим над $R$ тогда и только когда, когда выполнено два условия: его содержание равно 1 и он неприводим над $F$. 
**Доказательство**
1. =>. Равенство содержания единице очевидно (иначе его можно вынести и получить нетривиальное разложение). Допустим, что он приводим над $F$ на $g,h$. Тогда существует $c:\;\;cf=gh$ ($c$ - "общий знаменатель"  коэффициентов из разложения над полем частных). Значит, по условию 2 леммы Гаусса, из $g$ и $h$ можно вынести их содержания так, что они в произведении дадут $c$. Тогда $f$ приводим над $R$ - противоречие.  
2. <= очевидно (допустим, он приводим. Тогда он или раскладывается на два многочлена, что делает и над $F$, или раскладывается на константу и многочлен, что противоречит первому условию)

**Теорема** (Гаусса)
Если $R$ - факториальное кольцо, то и $R[X]$ тоже факториальное кольцо.
**Доказательство**
- Проверим критерий факториальности
- Возьмём неприводимый многочлен $f$. Если этот многочлен - скаляр, то он прост как элемент $R$. По лемме 1: $f$ прост в $R[X]$ равносильно тому, что $R[X]/pR[X]$ - область целостности. Рассмотрим $R[X]/pR[X]=(R/pR)[X]$\[1]. $(R/pR)[X]$ очевидно область целостности. 
- Если это не скаляр, то получаем следствие леммы Гаусса: пусть $g(x)h(x)\;|\;f(x)$. $F[X]$ - ОГИ (потому что коэффициенты из _поля_ частных), поэтому его неприводимый -- прост. Тогда оказывается, что $g(x)\;|\;f(x)$ или $h(x)\;|\;f(x)$ над полем $F$. Допустим, что вырно первое, тогда $g(x)=f(x)d(x)$ над $F[X]$. Значит, существует $c:\;\;cg=fd$ над $R[x]$. Отсюда следует, что $\text{cont }(cg)=c=\text{cont }(d)$, потому что $\text{cont }(f)=1$, иначе он не неприводимый, а значит $g=\frac{d}{c}f$, а значит $g\;|\;f$ в $R[X]$
- Проверка второго условия. В искомой последовательности сначала рассмотрим содержание каждого из многочленов. Они, очевидно, будут убывать по количеству простых сомножителей, пока не дойдут до ассоциированных членов. Короче говоря, равно или позно $\text{cont }f_i$ начнут быть ассоциированы между собой
- Рассмотрим данные многочлены над полем частных. Раз оно поле, то оно -- область главных идеалов. Для неё лемма о стабилизации верна автоматически, значит, многочлены становятся ассоциативны в $F[X]$. Тогда $f_i=df_{i+1}$, где $d$ - элемент из $R$. Это же означает, что содержание $f_i$ равно содержанию $f_{i+1}$, умноженному на $d$, но мы уже говорили, что с некоторого номера и то, и то содержания будут ассоциированы. Значит, $d$ обратим в $R$ и многочлены ассоциативны в $R[X]$. 
**Пояснение**
1. Потому что делимость многочлена на $p$ это тоже самое, что делимость каждого коэффициента на $p$
**Дополнение**
- В частоности, факториальным кольцом является кольцо $\mathbb{Z}[X]$, которое при этом не является ОГИ (потому что не выполнена теорема о линейном представлении НОД: $\gcd(2,x)=1$, но $A(x)2+B(x)x=1$ не существует \[подставим ноль, получим, что 1 делится на 2, что неправда над $\mathbb{Z}$])
**Следствие**
Если $R$ факториально, то и $R[x_1,...,x_n]$ факториально (очевидно по индукции формата $((R)[x_1]))[x_2]...$. В том числе количество переменных может быть бесконечным

_____
#TODO
[6 минута тут](https://www.youtube.com/watch?v=0TwNvAdnEAo&list=PLSpQmaEvFhCQyUsrMQ8kMUVxW6EDKzIvR&index=4). Там есть небольшой интересный рассказ, который, наверно, имеет смысл сюда вписать
- Пример, где не работает лемма о стабилизации: кольцо целыз алгебраических чисел (это те комплексные числа, которые являются решением уравнения с целыми коэфф). В них не стабилизируется последовательность 2, sqrt(2), 2^(1/4), 2^(1/8),....
- Ещё интересная теорема на 45-46 минуте
____
## Признак Эйзенштейна
**Замечание**
Пусть $R$ - факториальное кольцо, $p$ - простой элемент в нём. Для многочлена $f(x)\in R[X]$ рассмотрим его редукцию по модулю $p$ : $[f(x)]\in (R/pR)[X]$. Тогда: если $f$ - унитальный многочлен\[1] и его редукция неприводима, то $f$ неприводим
**Доказательство**
- От противного. Посмотрим разложение $f(x)=g(x)h(x)$. Раз $f(x)$ унитальный, то $g(x),h(x)$ имеют обратимые элементы в старших моночленах. То есть $[f(x)]=[g(x)][h(x)]$. Получается, что если $f(x)$ приводим над $R[X]$, то и его редукция приводима
**Пояснение**
 1. Унитальный - значит старший коэффициент равен единице. Унитальность нужна, чтобы запретить ситуацию, когда в многочлене только свободный коэффициент не делится на $p$, а остальные делятся. В таком случае редукция получится тривиальной, что мы хотим запретить
 2. Данное условие не является необходимым. Только достаточным

**Признак Эйзенштейша**
Пусть $R$ - факториальное кольцо, $p$ - простой элемент в нём. Пусть $f$ - унитальный многочлен, все коэффициенты которого (кроме старшего) делятся на $p$, и не делятся на $p^2$. Тогда $f$ неприводим в $R[X]$.
**Доказательство**
- Допустим он приводим. Тогда $f(x)=g(x)h(x)$. Получится, что $[X^n]=[g(x)][h(x)]$. То есть сами $[g(x)]$ и $[h(x)]$ - некоторые $[X^k]$. В таком случае, например, свободный коэффициент и $g$, и $h$ делится на $p$, а значит свободный коэффициент $f(x)$ делится на $p^2$, противоречие
**Следствие**
Круговой многочлен $\Phi=\frac{x^p-1}{x-1}$ неприводим над $\mathbb{Z}[X]$. Это видно при замене переменной на $x=y+1$. Тогда $\Phi = \frac{(y+1)^p-1}{y}$. 
## Определение поле частных и его единственность
**Определение**
**Поле частных** области целостности $R$ (ккс1) - это поле $F$ вместе с вложением $R\hookrightarrow F$ со следующим свойством (**универсальное свойство**): для любого _инъективного_ гомоморифизма в некоторое поле $\varphi:\;R\hookrightarrow L$ существует единственный гомоморфизм $\overline\varphi:\;F\longrightarrow L$, который продолжает $\varphi$, то есть $\overline\varphi|_R=\varphi$. Это может быть проиллюстрированно с помощью следующей коммутативной диаграммы:
$$\begin{CD}
R @>\text{вложение}>> F\\
@VV\varphi V @VVV\\
L @. \overset{\exists!\overline\varphi}{\leftarrow}
\end{CD}$$
По сути это означает, что $F$ будет подкольцом в $L$. Также по сути это означает, что $F$ - минимальное поле, содержащее $R$.

**Замечание**
Любой ненулевой гомоморфизм полей инъективен. 
**Доказательство**
- Пусть $f:F\longrightarrow L$ гомоморфизм полей. Тогда если $f(x)=f(y)$, то $f(x-y)=f(x)-f(y)=0$, значит $x-y=0$. Последнее выполнимо вот почему: допустим, оно не выполнимо. Тогда $x-y=a$. Тогда у него есть обратный $a^{-1}$. Тогда $f(1)=f(aa^{-1})=f(a)f(a^{-1})=0$. Но тогда гомоморфизм нулевой.

**Замечание**
Поле частных определено однозначно с точностью до изоморфизма
**Доказательство**
- Пусть $F,F_1$ - поля частных. Тогда существует гомоморфизм между ними. Рассмотрим две картинки: $$\begin{CD}
R @>i_1>> F_1\\
@VVi_2 V @VVV\\
F_2 @. \overset{\exists!\overline\varphi_1}{\leftarrow}
\end{CD}\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;
\begin{CD}
R @>i_2>> F_2\\
@VVi_1 V @VVV\\
F_1 @. \overset{\exists!\overline\varphi_2}{\leftarrow}
\end{CD}$$
- Окажется, что $\overline{\varphi_2} \circ \overline{\varphi_1}=id_{F_1}$, $\overline{\varphi_1} \circ \overline{\varphi_2}=id_{F_2}$. Получится, что $\overline{\varphi_1}\circ i_1=i_2$, $\overline{\varphi_2}\circ i_2=i_1$. Это значит, что $\overline{\varphi_1}\circ\overline{\varphi_2}\circ i_2=i_2$. Откуда и следует то, что искалось \[из того, что отображение формата $\overline{\varphi_1} \circ \overline{\varphi_2}$, во-первых, очевидно существует, а во-вторых, из того, что оно должно быть единственно, ведь если существует какое-то другое, то неверно изначальное универсальное свойство\]

## Построение поля частных
**Построение поля частных**
- Введём отношение эквивалентности на множестве пар $R\times(R\setminus\{0\})$ \[напомню, что $R$ это ОЦ, то есть ккс1] с отношением пропорциональности: $(a,b)\sim(c,d)$, если $ad=bc$. 
- Проверяем, что это отношение эквивалентности. Рефлексивность и симметричность очевидна. Транзиттивность: $ad=bc \land cf=de\;\;\Rightarrow\;\;adf=bcf\;\land\;bcf=bde\;\;\Rightarrow\;\;adf=bde\;\;\Rightarrow\;\;af=be$.
- Введём операции: умножение $(a,b)(c,d)=(ac,bd)$ и сложение $(a,b)+(c,d)=(ad+bc,bd)$
- Корректность умножение проверяется тривиально. Для корректности нам необходимо, чтобы $\begin{cases}(a,b)\sim(a',b')\\(c,d)\sim(c',d')\end{cases}\Rightarrow(a,b)(c,d)\sim(a',b')(c',d')\Rightarrow(ac,bd)\sim(a'c',b'd')\Rightarrow$ $\Rightarrow acb'd'=bda'c'\Leftarrow \begin{cases}ab'=ba'\\ cd'=dc'\end{cases}\Leftarrow\begin{cases}(a,b)\sim(a',b')\\(c,d)\sim(c',d')\end{cases}$
- Нейтральный элемент - класс эквивалентности $[(1,1)]$, обратный - $[(a,b)]^{-1}=[(b,a)]$, где $a\ne0$
- Корректность сложения проверяется также и тривиально. Коммутативность, ассоциативность сложения тривиальны. Нейтральный по сложению - $[(0,1)]$. Противоположный _класс_ (не пара, а класс пар): $[(a,b)]+[(-a,b)]=[(0,b^2)]=[(0,1)]$
- Дистрибутивность проверяется тривиально
Обозначим данную конструкцию как $F$. По построению это поле. Как искомое вложение $R\hookrightarrow F$ используем соответствие $a\mapsto [(a,1)]$. Это инъективный гомоморфизм \[тривиально].
- Проверяем универсальное свойство. Пусть имеется некоторое вложение $\varphi: R\hookrightarrow L$. Единственность $\overline{\varphi}$: $\overline{\varphi}([(a,1)])=\varphi(a)$, $\overline\varphi([(1,b)])=\varphi(b)^{-1}$, потому что $\varphi(b)\overline\varphi([1,b])=\overline\varphi([b,1])\overline\varphi([1,b])=\overline\varphi([(b,1)][(1,b)])=\overline\varphi(1)=1_L$
- Существование: Полагаем $\overline{\varphi}(\frac{a}{b})=\varphi(a)\varphi(b)^{-1}$. Проверим корректность определения: нужно проверить $\frac{a}{b}=\frac{a'}{b'}\Rightarrow\varphi(a)\varphi(b)^{-1}=\varphi(a')\varphi(b')^{-1}$. Домножим обе части, получим $\varphi(a)\varphi(b')=\varphi(a')\varphi(b)$. Это значит, что $\varphi(ab')=\varphi(a'b)$, что следует из $ab'=a'b$.
- $\overline\varphi(x)$ сохраняет умножение (следует из покомпонентности) и сохраняет сложение $\frac{\varphi(ad+bc)}{\varphi(bd)}=\overline\varphi(\frac{ad+bc}{bd})=\overline\varphi(\frac{a}{b})+\overline\varphi(\frac{c}{d})=\varphi(a)\varphi(b)^{-1}+\varphi(c)\varphi(d)^{-1}=\varphi(ad+bc)\varphi(bd)^{-1}$

**Замечание**
Если $R$ - ккс1, $S$ - мультипликативно замкнутое подмножество. Тогда существует кольцо $S^{-1}R$ вместе с гомоморфизмом $i:R\longrightarrow S^{-1}R$, таким что
1. $\forall s\in S:\;\;i(s)$ обратим
2. Для любого аналогичного гомоморфизма в $A$ будет существовать единственный $\overline\varphi:\;\;S^{-1}R\longrightarrow A$
Конструкция такого множества похожа на рассмотренную конструкцию поля частных. Но: $R\times S/\sim$, где $(a,s)\sim(a',s')\Leftrightarrow\exists\lambda\in S:\;\lambda(ab'-a'b)=0$
Таким путём можно сделать обратимым любое мультипликативно замкнутое подмножество. Название такого фокуса - [локализация](https://ru.wikipedia.org/wiki/%D0%9A%D0%BE%D0%BB%D1%8C%D1%86%D0%BE_%D1%87%D0%B0%D1%81%D1%82%D0%BD%D1%8B%D1%85)
Если при этом $S=\{1,s,s^2,...\}$, то $S^{-1}R$ обозначается как $R[\frac1s]$. Примером является кольцо многочленов над полем и множество степеней от одного многочлена. 
___
Вообще [тут](https://www.youtube.com/watch?v=tUckAq0x3RQ&list=PLSpQmaEvFhCQyUsrMQ8kMUVxW6EDKzIvR&index=7) немного побольше информации про это на 22 минуте
___
## Разложение в примарные дроби
**Определение**
Дробь $\frac{f(x)}{g(x)}\in F(x)$ газывается правильной, если $\deg f<\deg g$. Заметим, что данное определение корректно. Проверяем: $\frac{f}{g}=\frac{f'}{g'}$ означает, что и там, и там степень числителя меньше степени знаменателя. Это так, потому что $fg'=f'g$, то есть $\deg f + \deg g' = \deg f' +\deg g$. Равенство не будет выполнено, если где-то окажется, что $\deg f > \deg g$.  

**Выделение целой части**
Любую дробь можно записать в виде $$\frac{f(x)}{g(x)}=q(x)+\frac{r(x)}{q(x)}$$По сути это переформулировка теоремы о делении с остатком

**Лемма**
Рассмотрим $\frac{f(x)}{g(x)h(x)}$ с $\gcd(g,h)=1$. Тогда существуют такие $f_1,f_2\in F[X]$, что $\frac{f(x)}{g(x)h(x)}=\frac{f_1}{g(x)}+\frac{f_2}{h(x)}$. Причём если изначальная дробь правильная, то и получившиеся дроби можно выбрать правильные. Причём представить правильную дробь в виде суммы правильных можно единственным образом
**Доказательство**
- Следствии теорема о линейном представлении НОД \[представляем 1 как сумму, подставляем единицу в числитель исходной дроби]
- Почему возможно рассмотрение в виде правильной дроби? По выделению целой части. $\frac{f(x)}{g(x)h(x)}=q_1(x)+q_2(x)+\frac{r_1(x)}{g(x)}+\frac{r_2(x)}{h(x)}$. Домножим на $gh$. Получим: $f_{\deg<\deg g+\deg h}=(q_1+q_2)gh_{\deg\ge\deg g+\deg h}+r_1h_{\deg<\deg g+\deg h}+r_2h_{\deg <\deg g+\deg h}$. После переноса двух последних слагаемых налево получим, что многочлен со степенью меньше указанной суммы степеней равен многочлену со степенью больше 
- Почему представление единственно? Пусть оно не единственно. Тогда $\frac{f_1-f_1'}{g}=\frac{f_2'-f_2}{h}$, то есть $(f_1-f_1')h=(f_2'-f_2)g$. Обе части равны и делятся одновременно на $h$ и на $g$, а раз они взаимнопросты, то и на $gh$. То есть изначальные дроби не были правильными или были нулевыми. 

**Определение**
Несократимая правильная дробь формата $\frac{f}{p^k}$ называется **примарной**.

**Разложение в примарные дроби**
Следствием вышесказанного является тот факт, что любую правильную дробь можно представить в виде суммы несократимых дробей виде $\frac{f_i}{p^k}$, где $p$ - неприводим. Причём это представление единственно
**Доказательство**
- Существование - следствие Леммы и ММИ
- Единственность - Пусть не единственно. Тогда $\sum \frac{f_i}{p_i^{k_i}}=\sum \frac{f_i'}{p_i^{l_i}}$. Покажем, что $k_1=l_1$, $f_1=f'_1$, для остальных доказательство будет аналогично. Пусть $k_1<l_1$. Домножим на произведение неприводимых с максимальными из $k_i,l_i$ степенями. Тогда слева останутся слагаемые, которое будут делиться на $p_1$, тогда как справа один делиться не будет. Противоречие. Значит, $k_i=l_i$. 
- Равенство между $f_i=f_i'$ проверяется рассмотрением такого же произведения по модулю $p_i$. Слева и справа все слагаемые, кроме одного, делятся на $p_1$. Значит, получим: $f_i\prod_{j\ne i}p_j^{k_j}\overset{\text{mod } p}{=}f_i'\prod_{j\ne i}p_j^{k_j}$. Получится, что $f_i\overset{\text{mod } p}{=}f_i'\overset{\text{mod } p}{=}r_i$, где $r_i$ - некоторый остаток от деления
- Рассмотрим теперь индукцию по степени $k_i$. Рассмотрим сумму $\sum \frac{f_i}{p_i^{k_i}}=\sum \frac{f_i'}{p_i^{l_i}}$, только на некотором месте вместо $f_i$ и $f_i'$ будет стоять их разность с остатком. Тогда: если $k_i=1$, то мы получим неправильную дробь в случае, если $f_i\text{ и }f_i'\ne r_i$. Если $k_i>1$, то сокращаем дробь и получаем индукционный переход на степень ниже.
## Разложение в простейшие дроби
**Определение**
**Простейшей дробью** называется несократимая дробь формата $\frac{f}{p^a}$, где $\deg f<\deg g$.

**Лемма**
Примарную дробь можно представить в виде суммы простейших, причём единственным образом.
**Доказательство**
- Достаточно представить $f(x)=a_0(x)+a_1(x)p(x)+...$. Для этого достаточно сделать итеративно деление с остатком. 

**Замечание**
Пусть $F$ поле. Тогда $F[x]$ - векторное пространство с базисом $1,x,x^2,...$ и т.д.

Рассмотрим задачу построения явного базиса для векторного пространства рациональных функций $F(x)$.

**Замечание**
Базис $F(x)$ состоит из $1,\;x,\;x^2,\;...$ а также дробей вида $\frac{x^i}{p^k(x)}$, $k\in \mathbb{N}$, $p$ - неприводимый и унитальный, $i<\deg p$. Это следует из указанной леммы (любая рациональная функция представима через этот базис единственным образом по разложению).
Для $\mathbb{C}(x),\mathbb{R}(x)$ - размерность континуума (ведь если в числителе $(x-a)$, то каждое $a$ даст разные базис-векторы, а их "континуум-штук").

## Максимальный идеал
**Лемма 1**
Пусть $R$ - коммутативное кольцо. Тогда: 
- $I$ максимальный идеал\[1] $\Leftrightarrow$ $R/I$ - поле
**Доказательство**
- => Рассмотрим $[a]_{\ne0}\in R/I$. Рассмотрим идеал, порождённый $(I+Ra)\supset I$. Причём равенства нет, ведь $a\notin I$. Раз так, то $I+Ra=I$ запрещён, а значит $I+Ra=R$. Это означает, что возможно равенство $x+\lambda a=1$. А это значит, что $\lambda a-1 \in I$, то есть $[\lambda][a]\overset{\text{mod I}}{=}[1]$
- <= По сути аналогичное доказательство, но в обратном порядке. Нам достаточно доказать, что любой идеал формата $I+Ra$ равен $R$. Он для этого должен содержать единицу, что следует из $x+\lambda a=1$, которое следует из $\lambda a - 1 \in I$.
**Пояснение**
1. Максимальный идеалом кольца называется идеал кольца, отличный от самого кольца, не содержащийся ни в каком другом идеале кольца

Рассмотрим многочлен $F[x_1,...,x_n]$ и тождественный гомоморфизм в надполе $L\supset F$. Понятно (по обобщённой теореме о вычислении значения) что существует такой вектор $\overline{a}\in L^n$, что существует гомоморфизм $\theta_{\overline{a}}:\underset{\varphi(\overline{x})\mapsto\overline{a}}{F[x_1,...,x_n]\longrightarrow L}$.
Пусть данный гомоморфизм сюръективный. Тогда $\ker \theta=I_\theta$ является максимальным идеалом, а кольцо вычетов $F[x_1,...,x_n]/I_\theta$ изоморфно $L$
**Доказательство**
- Максимальность идеала. Для максимальности нам достаточно, чтобы кольцр вычетов было полем. Внутри данного кольца вычетов лишь один элемент из кёрнела - ноль. Получается, что для любого представителя существует $\theta(h)=c$. Раз отправились в поле, да ещё и сюръективно, то существует $\theta(h')=c^{-1}$. То есть $\theta(h)\theta(h')=1=\theta(hh')$. При этом гомоморфизм между $F$ и $L$ тождественный, то есть в единицу $L$ отображается единица из $F$. То есть $hh'_{\in F[x_1,...,x_n]/\ker\theta}=1$, то есть мы для каждого элемента из кёрнела нашли обратный. То есть это поле. То есть идеал максимальный
- $\theta(f)=\theta(g)\;\Leftrightarrow\;\theta(f-g)=0\;\Leftrightarrow\;f-g\in I_\theta\;\Leftrightarrow\;[f]=[g]\;\;\text{в }F[x_1,...,x_n]/I$
## Расшинения
**Определение**
- Пусть $L\supset F$, оба из них поля. Тогда $L$ называется **расшинением** поля $F$.
- При этом $L$ является _векторным пространством_ над полем $F$. Его размерность ($\dim_FL$) называют **степенью расширения** ($[L:F]$).
- Если $[L:F]<+\infty$, то расшинение называют **конечным**, иначе - **трансцедентным**
- Расширение, порождённое одним элементом, называется **простым**.

**Определение**
Элемент $\alpha\in L$ называется **алгебраическим над F**, если выполнено одно из равносильных условий:
1. $\exists p(t)\in F[t]:\;p(\alpha)=0$
2. $\{1,\alpha,\alpha^2,...\}$ ЛЗ над $F$.
3. Подкольцо $F[\alpha]$ является полем
4. $F[\alpha]$ - конечное расширение поля $F$

**Доказательство** равносильности условий
1. (1=>2) Пусть $p(t)=a_0+...+a_nt^n$. Тогда $p(\alpha)=\sum_{i=0}^na_i\alpha^i=0$, а значит набор $\{1,\alpha,...,\alpha^n\}$ ЛЗ, а значит и весь $\{1,\alpha,\alpha^2,...\}$ линейно зависим
2. (2=>3) 
   - Пусть $n$ - минимальное такое число, что $\{1,\alpha,...,\alpha^n\}$ ЛЗ. Тогда существует такой набор, что $a_0+...+a_{n-1}\alpha^{n-1}=-a_n\alpha^{n}$, то есть $\alpha^n\in\langle1,\alpha,...,\alpha^{n-1}\rangle_F$. По индукции легко показать, что для любого $k>n:\;\alpha^k\in\langle1,\alpha,...,\alpha^{n-1}\rangle_F$\[1]. 
   - Покажем, что многочлен $g(t)=a_0+...+a_nt^n$ неприводим над $F$. Допустим, он приводим. Тогда $g(t)=h(t)h'(t)$. Тогда $g(\alpha)\overset{\text{т.к. }\alpha\text{ ЛЗ}}{=}0=h(\alpha)h'(\alpha)$. Значит, $g$ ассоциативен с одним из многочленов, иначе идёт противоречие с условием минимальности степени $n$.
   - Получается, что $g(t)$ простой (потому что $F[t]$ - ОГИ, потому что построено над полем, а значит неприводимый=простой). Поэтому $F[t]/\langle g(t)\rangle$ - поле.
   - Рассмотрим гомоморфизм $\theta_{\alpha}:\underset{\varphi(x)\mapsto\varphi(\alpha)}{F[t]\longrightarrow L}$. Понятно, что $F[\alpha]=\text{Im}\theta_\alpha$. Построим гомоморфизм $\pi:\underset{[\varphi(x)]\mapsto\varphi(\alpha)}{F[t]/g(t)F[t]\longrightarrow \text{Im }\alpha}$. Сам гомоморфизм строим как "выбор некоторого представителя" из $F[t]$: $[f(t)]\longrightarrow f(t)\longrightarrow f(\alpha)$. Инъективность гомоморфизма: $\pi(f)=\pi(h)\;\;\Rightarrow\;\;\pi(f-h)=0\;\;\Rightarrow\;\;(f-h)(\alpha)=0\;\;\Rightarrow\;\;(f-h)\;\text{делятся на }\;g$ то есть $[f]=[h]$ в $F[t]/g(t)F[t]$. Сюръективность: любой объект $\text{Im }\theta_\alpha$ это некоторый $f(\alpha)$. Поделим с остатком: $f = gq + r$. Тогда $f(\alpha)=g(\alpha)q(\alpha)+r(\alpha)=0+r(\alpha)$, то есть значение на многочлене равно значению на его остатке, то есть $f(\alpha)=[f](\alpha)$
   - Таким образом, построенное кольцо вычетов $F[t]/g(t)F[t]$ (которое поле), изоморфно $F[\alpha]$, а значит, $F[\alpha]$ - поле
3. (3 => 4) Если $\{1,\alpha,...,\alpha^n\}$ - ЛЗ, то это влечёт выполнение условия 2, что влечёт $F[\alpha]\cong F[t]/g(t)F[t]$, что очевидно влечёт конечномерность. Если вдруг  $\{1,\alpha,...\}$ ЛНЗ, то тогда $\theta_{\alpha}:\underset{\varphi(x)\mapsto\varphi(\alpha)}{F[t]\longrightarrow L}$ инъективный гомоморфизм\[2]. Он одновременно сюръективен на свойм образе, получается, что не-поле $F[t]$ изоморфно образу гомоморфизма, то есть $F[\alpha]$, то есть $F[\alpha]$ не поле -- противоречие с условием 3
4. (4 => 1) Пусть $[F[\alpha]:F]=n$. Тогда линейная комбинация $\{1,\alpha,...,\alpha^n\}$ будет ЛЗ над $F$, из чего следует 1
**Пояснение**
1. Пусть $\alpha^k=b_0+...+b_{n-1}\alpha^{n-1}$. Тогда $\alpha^{k+1}=\alpha^k\cdot\alpha=b_0\alpha+...+b_{n-2}\alpha^{n-1}+b_{n-1}\alpha^{n}$, где $\alpha^n$ раскладывается в многочлен $(a_0+...+a_{n-1}\alpha^{n-1})\frac{1}{-a_n}$. То есть снова получаем многочлен с максимальной степенью при $\alpha$ равной $n-1$.
2. Потому что кёрнел состоит только из нуля, потому что если не только из нуля, то есть многочлен, который в точке $\alpha$ даст ноль, а значит есть некоторая конечная линейная комбинация степеней $\alpha$, которая даст ноль, то есть $\{1,\alpha,...,\alpha^n\}$ - ЛЗ

**Определение**
- Расширение, в котором каждый элемент алгебраический относительно $F$, называется **алгебраическим расширением**
- Пример **простого алгебраического расширения**: $\mathbb{C}\supset\mathbb{R}$. Вообще говоря в любом конечном алгебраическом расширении можно взять подрасширение, которое будет простым

**Замечание**
Если $\alpha$ трансцендентен над $F$, то минимальное подполе $L$, содержащее $F$ и $\alpha$, изоморфно $F(t)$.
**Доказательство**
- Раз $\alpha$ трансцедентен, то гомоморфизм $F[t]\longrightarrow L$ инъективен. По универсальному свойству, верному для поля частных $F(t)$, оно минимальное подполе $L$, содержащее $F[t]$, то есть содержащее $F[\alpha]$, то есть $F$ и $\alpha$

_____
#PURGE замечание с картинки????
_____
## Степень расширения
**Теормема**
Мультипликативность степени: $K\supset L\supset M$ конечные расширения $\Leftrightarrow$  $K\supset M$ конечное и $[K:M]=[K:L][L:M]$
**Доказательство**
- <= очевидно
- Пусть имеем два базиса: {xi} в K относительно L и {yj} в L относительно M. Проверим, что {xiyj} - базис K над M. 
- Это порождающая система, потому что любой вектор над K представим как ЛК векторов базиса {xi}, а каждая его координата представима как ЛК векторов из M. Получим, что искали. 
- Линейная независимость - от противного. Пусть существует такая линейная комбинация $\sum \alpha_{ij}x_iy_j=0$. Тогда $\sum (\sum y_ja_{ij})x_i=0$. Но так как {xi} ЛНЗ, то каждая такая сумма равна нулю. Пусть $\sum y_ja_{ij}=0$ (j фиксировано). Тогда {yi} ЛЗ - противоречие

___
#PURGE #TODO **поле алгебраических чисел** - это конечное (а следовательно — алгебраическое) расширение поля рациональных чисел Q. Таким образом — это поле, содержащее Q и являющееся конечномерным векторным просранством над ним
____
## Слабая форма теоремы Гильберта о нулях
**Теорема** (слабая формулировка т. Гильберта о нулях)
Рассмотрим $\mathbb{C}[x_1,...,x_n]$. Любой максимальный идеал данного кольца имеет вид:
- $I_{(a_1,...,a_n)}=\{\varphi(\overline{x})\in C[x_1,...,x_n]:\;\;\varphi(\overline a)=0,\;\overline a\in \mathbb{C}^n\}$
**Доказательство**
- Пусть $I$ - максимальный идеал. Рассмотрим поле $L=\mathbb{C}[x_1,...,x_n]/I$. По сути своей оно изоморфно $L=\mathbb{C}[a_1,...,a_n]=\mathbb{C}[\overline{a}]$ (можно рассмотреть гомоморфизм подстановки). Если $a_1$ алгебраическое, то: есть многочлен, где $a_1$ корень, то есть есть унитальный многочлен первой степени, где $a_1$ корень \[раз $\mathbb{C}$ алгебраически замкнуто, то есть неприводимые многочлены имеют степень 1], а значит $a_1\in\mathbb{C}$. Проделывая эти же действия с остальными получаем, что $L=\mathbb{C}$
- Пусть $k$ - первый индекс, где мы встретили неалгебраическое число. Рассмотрим $\mathbb{C}[a_1,...,a_k]=\mathbb{C}[a_k]\cong\mathbb{C}[t]$. При этом $L\supset\mathbb{C}(t)$, потому что $\mathbb{C}(t)$ - минимальное подполе поля $L$, содержащее $\mathbb{C}$ и $a_k$\[1]. Противоречит размерности: с одной стороны счётна, раз $a_1^{k_1},...,a_n^{k_n}$ - порождающая система, а с другой - несчётна, раз $\mathbb{C}(t)$ содержит ЛНЗ базисы формата $\frac{1}{T-a}$.
**Пояснение**
1. По замечанию, доказанному ранее.

**Следствие**
Обозначим за $z(f_1,...,f_k)$ множество таких $\overline{a}\in\mathbb{C}^n$, что функции в них принимают ноль одновременно. Тогда:
- $z(f_1,...,f_k)=\varnothing\;\;\Leftrightarrow\;\;$ идеал, порождённый этими $f_i$, совпадает с $\mathbb{C}[x_1,...,x_n]$, то есть существует ЛК: $1=\lambda_1(x)f_1+...+\lambda_k(x)f_k(x)$.
**Доказательство**
- => Допустим, не совпадает. Тогда по лемме Цорна существует максимальный идеал между $I$ и $\mathbb{C}[x_1,...,x_n]$. Он, как известно, принимает вид $I_{\overline{a}}$. То есть все одновременно принимают ноль в $\overline{a}$
## Сильная форма теоремы Гильберта  о нулях. Алгебраические множества в C^n
**Определение**
- Алгебраическим множеством называется множество решений некоторой (возможно, бесконечной) системы уравнений вида $f_\alpha(x_1,...,x_n)_{\in\mathbb{C}[x_1,...,x_n]}=0$. Такое множество обозначается как $V(f_\alpha)$.
- Иным путём можно обозначить алгебраическое множество через множество общих нулей $z$:  $\forall I\subset\mathbb{C}[x_1,...,x_n]:\;\;z(I)=\{\overline(a)\in\mathbb{C}:\;\;\forall f\in I:\;f(\overline{a}=0)\}$.

**Замечание**
- Понятно, что если $X\subset\mathbb{C}^n$, то $X\longrightarrow I(X)_{=\{f\in\mathbb{C}[...]:\;\forall \overline{a}\in X: f(\overline{a})=0\}}\longrightarrow z(I(X))$, причём $z(I(X))\supset X$. $z(I(X))$ - наименьшее по включению алгебраическое подмножество, содержащее $X$. Также очевидно, что $X_1\subset X_2:\;I(X_1)\supset I(X_2)$
- Аналогично можно построить $I\longrightarrow z(I)\longrightarrow I(z(I))$, $I_1\subset I_2:\;z(I_1)\supset z(I_2)$

**Определение**
**Радикалом** идеала $I$ над $R$ называется множество $\sqrt{I}\;:=\;\{r\in R:\;\;\exists k\in \mathbb{N}:\;r^k\in I\}$

**Теорема** (сильная формулировка т. Гильберта о нулях)
Пусть $I=\langle f_1,...,f_k\rangle$, то $I(z(I))=\sqrt{I}$.\[1]
**Доказательство**
- Пускай $f$ зануляется на всех точках $z(I)$. В таком случае многочлены $f_1,...,f_k$ и многочлен $1-tf$ не имеют общих нулей, то есть $\langle f_1,...,f_k,(1-tf)\rangle=\mathbb{C}[t,x_1,...,x_n]$\[2]. Иными словами, число 1 представимо как линейная комбинация элементов $f_1,...,f_k,(1-tf)$, причём с коэфициентами из $\mathbb{C}[t,x_1,...,x_n]$.
- Заменим $t=\frac{1}{f}$. Получим: $1=\sum g_if_i$, где $g_i\in\mathbb{C}[x_1,...,x_n][\frac{1}{f}]$.
- Приводя дроби к общему знаменателю, получим: $1=\frac{\sum h_if_i}{f^r}$, где $h_i\in\mathbb{C}[x_1,...,x_n]$. Значит, $f^r= \sum h_if_i$. То есть представим как линейная комбинация из элементов $f_1,...,f_k$, то есть лежит в $\langle f_1,...,f_k\rangle=I$, что доказывает "многословную" формулировку теоремы
**Пояснение**
1. Более многословная формулировка: если $I$ - обственный идеал $F$. Тогда если $f\in F[x_1,...,x_n]$ зануляется на всех точках $z(I)$, то $f^r$ входит в $I$
2. По слабой формулировке т. Гильберта
**Следствие**
Если $X=z(I)$, то $z(I(X))=X$
**Доказательство**
- Из т. Гильберта о нулях: $z(I(X))=z(I(z(I)))=z(\sqrt{I})\overset{[1]}{=}z(I)=X$
**Пояснение**
1. $z(\sqrt{I})\subset z(I)$: если многочлен обращается в ноль в точке $a$, то и его степень обращается в ноль в точке $a$.  $z(\sqrt{I})\supset z(I)$: любой корень многочлена, обращающегося в ноль в точке $a$, обращается в ноль в этой точке

## Проективное пространство
**Определение**
- Пусть $V$ - векторное пространство над полем $F$. Тогда множество прямых, проходящих через 0, называют проективным пространством ($P(V)$) Для $V=\mathbb{R}^n$. Тогда $P(V)=P^{n-1}(\mathbb{R})$
- Проективное пространство над $\mathbb{R}^n$ можно описать как фактор-множество векторов по отношению эквивалентности направлений: $[a,b,...]~[a',b',...]\;:=\;\exists c:\;\;[a,b,...]=[ca',cb',...]$ 

**Пример**
- $\mathbb{R}^3$, плоскость $z=1$. В этом случае все прямые, кроме параллельных плоскости $xy$, находятся в биективном отношении с плоскостью. Точки, отвечающие прямым, параллельным $xy$ называются **бесконечно удалёнными** от данной плоскости
- Пусть имеется плоскость $z=1$ и две параллельные прямые в ней. Эти же прямые лежат в проективном пространстве и представляют собой проекцию плоскости (прямую можно сформировать с помощью двух "точек" проективного пространства - двух векторов; в обычном пространстве через них задаётся плоскость) ![[Pasted image 20240628215201.png]]
  Можно заметить, что эти две параллельные прямые в проективном пространстве имеют общую точку - бесконечно удалённую точку данной плоскости. Плоскости $u$ и $u'$ пересекаются по прямой, проходящей через ноль и лежащей в $Oxy$. Она в проективном пространстве становится точкой. Тогда бесконечно-удалённая точка отвечает классу параллельных прямых

## Дискриминант многочлена
**Определение**
- **Дискриминант многочлена** степени $n$ - полиномиальное выражение от его коэффициентов, которое обращается в ноль тогда и только когда, когда данный многочлен имеет кратный множитель
- Пусть$$a_0T^n+...+a_{n-1}^T+a_n=p(T)\in F[T],\;\;a_i\in F$$$\text{disc}$ - это многочлен от переменных $A_0,A_1,...,A_n$ c целыми коэффициентами, что при подстановке $A_i\mapsto a_i$:  дискриминант обращается в ноль тогда и только тогда, когда $p(T)$ имеет кратный корень
Важно, что под дискриминантом подразумевается формула для всех многочленов данной степени, в которую должны подставляться коэфициенты, а не конкретное приложение к одному многочлену
- Многочлен вида $A_0(T-x_1)...(T-x_n)\in L[T]=Q(x_1,...,x_n,A_0)[T]$ называется общим многочленом степени $n$.

**Принцип выбора показателя степени**
Рассмотрим $p(x)=a_0x^n+...+a_{n-1}^T+a_n=a_0\prod(x-\alpha_i)$. 
$\text{disc }p=a_0^{2n-2}\prod_{i>j}(\alpha_i-\alpha_j)^2$ по основной теореме о симметрических многочленах выражается через $\frac{a_1}{a_0},...,\frac{a_n}{a_0}$.\[1]
_Почему степень 2n-2?_
Рассмотрим многочлен $\overline{p}(x)=x^np(\frac{1}{x})=a_nx^n+...+a_0=a_n\prod(x-\frac{1}{\alpha_i})$. (кстати, старший коэффициент может быть ноль). Показатель же выбран такой, чтобы $\text{disc }p=\text{disc }\overline{p}$. Видно, что $$\text{disc }\overline{p}=a_n^{2n-2}\prod_{i>j}(\frac{1}{\alpha_i}-\frac{1}{\alpha_j})^2=a_n^{2n-2}\prod_{i>j}(\frac{1}{\alpha_i\alpha_j})^2\prod_{i>j}(\alpha_i-\alpha_j)^2=(\frac{a_0^{n-1}}{a_n^{n-1}})^2\frac{a_n^{2n-2}}{a_0^{2n-2}}\text{disc }p=\text{disc }p$$
Помимо прочего, данная степень наименьшая. Допустим, это не так. Рассмотрим многочлен, в котором свободный коэффициент равен нулю. Легко придумать многочлен, в котором при этом не будет кратных корней (например, $x(x-1)(x-2)$), а дискриминант не будет равен нулю. Если бы степень была не наименьшей, то какой-то множитель бы остался и весь дискриминант обратился бы в 0
**Пояснение**
1. Потому что данный многочлен симметрический. Построили мы его для общего многочлена, выраженного в $L$. Это многочлен над $\mathbb{Z}[\frac{a_1}{a_0},...,\frac{a_n}{a_0}]\in Q(A_0,...,A_n)$, а по теореме такой многочлен выражается через элементарные симметрические многочлены от $\frac{a_1}{a_0},...,\frac{a_n}{a_0}$

**Замечание** (о второй формулировке определения дискриминанта)
Многочлен задаёт множество точек на прямой. Рассмотрим **гомогенизацию (проективизацию)** его (общего!) многочлена $p(t)=0\longrightarrow y^np(\frac{x}{y})=a_0x^n+a_1x^{n-1}y+...+a_ny^n$. Раз $p(t)=a_0\prod(t-\alpha_i)$, то $p(x,y)=a_0\prod(x-\alpha_iy)$. Получается, что линейные множители однородного многочлена $p(x,y)$ отвечают за множество точек проективного пространства $\mathbb{R}(F^2)$, в которых многочлен обращается в ноль.\[1]
Пусть теперь имеется $p(x,y)\in\mathbb{C}[x,y]$ - однородный многочлен. Раз он над $\mathbb{C}$, то он разложим на линейные множители. В таком случае $\text{disc }p(x,y)=0\Leftrightarrow \text{у p(x) есть кратные корни}$. 
**Пояснение**
1. Важно помнить про бесконечно удалённую точку. К примеру рассмотрим многочлен $(t-1)(t-2)$. После подстановки ($t=\frac{x}{y}$) получится многочлен $y(x-y)(x-2y)$. Этот многочлен облащается в ноль в "точках" $y=x$, $y=\frac{1}{2}x$ и $y=0$. Если с первыми двумя всё ясно, то $y=0$ отвечает за прямую, параллельную оси $OY$, то есть бесконечно удалённой точке (соответственно, $t\longrightarrow \frac{x}{0}$, $t=\infty$) 
2. Такая формулировка от однородного многочлена может быть полезна для того, чтобы не обговаривать неравенство старшего коэффициента нулю. Если посмотреть на запись однородного многочлена, станет ясна равнозначность записи многочлена (с точки зрения построения дискриминанта) с коэффициентами в прямом порядке ($\sum a_{n-i}T^i$) и в обратном порядке ($\sum a_iT^i$) 

**Примеры дискриминантов**
- Сначала рисуем общую формулу дискриминанта, потом делаем из неё многочлен от элементарных симметрических многочленов с участием корней, а потом эти ЭСМ меняем на коэффициенты 

| Многочлен         | Дискриминант                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             |
| ----------------- | -------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| $a_0t^2+a_1t+a_2$ | $p(t)=a_0(t-c_1)(t-c_2)$. $\text{disc }p=a_0^2(c_1-c_2)^2=a_0^2((c_1+c_2)^2-4c_1c_2)=a_0^2([\frac{a_1}{a_0}]^2-4[\frac{a_2}{a_0}])=a_1^2-4a_2a_0$                                                                                                                                                                                                                                                                                                                                                                                                                                                        |
| $t^3+pt+q$\[1]    | $p(t)=(t-c_1)(t-c_2)(t-c_3)$. $\text{disc }p=(c_2-c_1)^2(c_3-c_2)^2(c_3-c_1)^2$. Воспользуемся следующим свойством: $\begin{bmatrix}3&p_1&p_2\\p_1&p_2&p_3\\p_2&p_3&p_4\end{bmatrix}=\begin{bmatrix}1&1&1\\\alpha_1&\alpha_2&\alpha_3\\\alpha_1^2&\alpha_2^2&\alpha_3^2\end{bmatrix}\begin{bmatrix}1&1&1\\\alpha_1&\alpha_2&\alpha_3\\\alpha_1^2&\alpha_2^2&\alpha_3^2\end{bmatrix}^T$. Справа получим искомый дискриминант. Слева: $p_1=\alpha_1+\alpha_2+\alpha_3=[\text{старший коэфф. полинома}]=0$, $p_2\overset{[2]}{=}-2p$, $p_3=-3q$, $p_4=2p^2$. Получим, что $D=-12p^3+8p^3-27q^2=-4p^3-27q^2$ |
**Пояснение**
1. Приведённый кубический многочлен. Обычный кубический $x^3+a_2x^2+a_1x+a_0$к приведённому кубическому сводится через замену $y=x+\frac13a_2$
2. $p_2=(\alpha_1+\alpha_2+\alpha_3)-2(\alpha_1\alpha_2+\alpha_2\alpha_3+\alpha_3\alpha2)=0-2p$
## Результант
**Определение**
- Пусть $f(x)=a_0x^n+...+a_n,g(x)=b_0x^m+...+a_m$. **Результант двух многочленов** это некоторое полиномиальное выражение от коэффициентов этих полиномов, которое обращается в ноль тогда и только тогда (если $a_0,b_0\ne0$)\[1], когда $\gcd(f,g)\ne1$.
- Формула 1 (с точностью до знака): $R_{f,g}=(-1)^?A_0^mB_0^n\prod(\alpha_i-\beta_j)$ ($\alpha$ - корни $f$, $\beta$ - корни $g$). Степень у минус единицы можно зафиксировать как $? := mn$
- Она же: $R_{f,g}=(\prod_{i=1}^m f(\beta_i))B_0^n(-1)^{mn}=(\prod_{j=1}^n g(\alpha_j))A_0^m(-1)^{mn}$.
**Пояснение**
1. Для избавление от условия на старший элемент можно рассмотреть гомогенизацию (проективизацию) многочленов $f,g$.

**Определение**
$$\text{[Матрица Сильвестра]}\;\;:=\;\;\begin{bmatrix}a_0&a_1&\cdots&0&\cdots&0\\0&a_0&a_1&\cdots&0&\cdots\\\vdots&\ddots&\ddots&\ddots&\ddots&\ddots\\0&\cdots&a_0&a_1&\cdots&a_n \\ b_0&b_1&\cdots&b_m&\cdots&0\\0&b_0&b_1&\cdots&b_m&\cdots\\\vdots&\ddots&\ddots&\ddots&\ddots&\ddots\\0&\cdots&b_0&b_1&\cdots&b_m\end{bmatrix}\begin{bmatrix} |\\| \\\text{m раз} \\| \\|| \\|| \\\text{n раз} \\|| \\|| \\ \end{bmatrix}$$

**Теорема**
Результант двух многочленов равен определителю матрицы Сильвестра с коэфф. этих двух многочленов
**Доказательство**
- Рассмотрим $F[X]/f(x)\oplus F[X]/g(x)\longrightarrow F[x]/f(x)g(x)$, где $(p,q)\mapsto fq+gp$. Это корректно определённое линейное отображение. То, что оно линейное, кажется очевидным. Коррентность следует из следующего: $$\begin{cases}p=p' \mod\; f\\ q=q'\mod\;g\end{cases}\;\Rightarrow\;\begin{cases}gp=gp' \mod\; fg\\ fq=fq'\mod\;fg\end{cases}\;\Rightarrow fq+gp=fq'+gp'\mod fg$$
- Размерность и области отправления, и области прибытия равны. В таком случае оказывается, что инъективность отображения и его сюръективность идут одновременно. Получается, что: $$\text{отобр. не биект}\Leftrightarrow \ker\ne0\Leftrightarrow\exists p,q:\;fq+gp=0\mod fg\Leftrightarrow\exists p,q: fq+gp\overset{[1]}{=}0$$
- Такое равенство происходит нулю происходит тогда (и только тогда), когда многочлены $f,g$ не взаимно просты.\[2]
- Матрица в данном отображении выглядит как транспонированная матрица Сильвестра\[3]. Получается, если многочлены не взаимнопростые, то определитель матрицы равен нулю как определитель матрицы небиективного линейного отображения. В ином случае определитель ненулевой.
- Свяжем теперь это значение с уже посчитанным результаном. Посчитаем определитель над общими многочленами $A_0\prod(T-x_i),\;B_0\prod(T-y_j)$. в $\mathbb{Q}[A_0,B_0,x_1,...,x_n,y_1,...,y_m]$. Рассмотрим определитель матрици как элемент $R(A_0,...,B_0,...)\in\mathbb{Q}[A_0,...,B_0,...]\subset\mathbb{Q}[A_0,B_0,x_1,...,x_n,y_1,...,y_m]$. Подставляем туда в числе прочих два равных элемента $x_i=y_j$, а на место остальных -- некоторые комплексные числа. В таком случае получится многочлен тождественно равный нулю как комплексный с одинаковыми корнями\[4]. Таким образом, подходя к процессу итеративно, выясняем, что этот многочлен делится на произведение $\prod(x_i-y_j)$. 
- Обратим внимание, что полученный определитель делится также на $A_0$ и $B_0$ - все коэффициенты можно заменить по правилу $A_k=A_0(-1)^k\sigma_k$ и аналогичному правилу для $B_k$, после чего просто вынеся множитель $A_0^nB_0^m$ из-под определителя
- А также что он является однородным многочленом от перемненых $x_1,...,y_1,...$ Для понимания этого обратим внимание на вид транспонированной матрицы Сильвестра после вынесения множителей $A_0B_0$. $$\begin{bmatrix}1&\sigma_1&\cdots&0&\cdots&0\\0&1&\sigma_1&\cdots&0&\cdots\\\vdots&\ddots&\ddots&\ddots&\ddots&\ddots\\0&\cdots&1&\sigma_1&\cdots&\sigma_n\\ 1&\sigma_1&\cdots&0&\cdots&0\\0&1&\sigma_1&\cdots&0&\cdots\\\vdots&\ddots&\ddots&\ddots&\ddots&\ddots\\0&\cdots&1&\sigma_1&\cdots&\sigma_m\end{bmatrix}^T$$ Чтобы взять определитель, нужно вытянуть по одному множителю из каждой строки. Домножим каждый столбец, отвечающий за первый многочлен на $u^i$ начиная с единицы заканчивая $n$. Также поступим с участком матрицы, отвещающим за второй многочлен. Теперь матрица будет иметь вид $Ru^{\frac{n(n+1)+m(m+1)}{2}}$. После этого каждая строка будет однородной, значит, каждый множитель будет иметь одну степень, а значит весь определитель будет однородный относительно $u,\{x_i\},\{y_j\}$. Степень многочлена будет равна при этом $1+2+...+m+n-1=\frac{(m+n-1)(m+n)}{2}$. Но тогда значит, что и изначальный $R$ был однородным, причём степени $mn$. ($\frac{(m+n-1)(m+n)-n(n+1)-m(m+1)}{2}=mn$)
- Таким образом было доказано, что данный определитель равен произведению $A_0^nB_0^m\prod(x_i-y_j)\cdot\text{const}$. Проверим константу. Рассмотрим многочлены $f(x)=a_0x^n,g(y)=b_m$. Определитель матрицы точно равен $a_0^mb_m^n$. Аналогичное же получаем и из $\prod_{j=1}^n g(\alpha_j))A_0^m$. Значит, $const=1$.
**Пояснение**
1. Достаточно просто выбрать наименьший из возможных по степени представителей данных $p,q$. Тогда понятно, что $fq+gp<m+n=\deg f + \deg g$. Если вдруг указанная сумма сравнима с нулём, но не тождественна ему, то она равна $fgh$, то есть равна многочлену степени больше, чем $m+n$. Противоречие.
2. Потому что: $$\begin{aligned} 1.&\; \gcd(f,g)=1\Rightarrow(fq=-gp \Rightarrow q|g)  \Rightarrow \text{противоречие, $\deg q<\deg g$ } \Rightarrow q=0   \\2.&\; \text{Пусть }\gcd(f,g)=d\Rightarrow q=\frac{g}{d},p=\frac{-f}{d} \end{aligned}$$
3. Базис прямой суммы будет равен объединению базисов "слагаемых". Получается мы переводим отображение из базиса $(1,0),(x,0)...,(0,1),(0,x),...$ в стандартный базис. Получается перевод $(1,0) \mapsto f,\;(x,0)\mapsto xf,...$ Если посмотреть на то, как выглядят столбцы такой матрицы как раз и окажется транспонированная матрица Сильвестра
4. Потому что при такой подстановке окажется, что многочлен, равный нулю, будет "делиться" на $(x_i-y_j)$. \[см. главу про определитель Вандермонда]

**Однородная версия результанта**
Пусть имеется $f(T,S)=\prod(\gamma_iT-\alpha_iS), \;\;g(T,S)=\prod(\delta_jT-\beta_jS)$. Тогда результант равен $R=\prod(\alpha_i\delta_j-\beta_j\gamma_i)\overset{\text{[пояснение]}}{=}(\prod \gamma_i)^n(\prod\delta_j)^m\prod(\frac{\alpha_i}{\gamma_i}-\frac{\beta_j}{\delta_j})$. 

**Связь результанта и дискриминанта**
$R(f',f)=a^{\deg f'}(\prod f'(\alpha_i))=a^na^{n-1}(\prod [a\prod_{i\ne j}(\alpha_i-\alpha_j)])=a^{n-1}a^n(-1)^{\frac{n(n-1)}{2}}\prod(\alpha_i-\alpha_j)^2=a\text{ disc }f$.
## Представление результанта как линейной комбинации. Исключение неизвестных из системы алгебраических уравнений

#TODO сделать две отдельные главы?

**Представление как линейной комбинации**
Пусть $f,g\in R[x]$, $R$ - комм. кольцо. $$\exists\;A(x),B(x)\in R[x]:\;Af+Bg=R_{fg}\in R$$
**Доказательство**
- Это следует из формулы Крамера для решения СЛУ. $$\begin{bmatrix}a_0&a_1&\cdots&0&\cdots&0\\0&a_0&a_1&\cdots&0&\cdots\\\vdots&\ddots&\ddots&\ddots&\ddots&\ddots\\0&\cdots&a_0&a_1&\cdots&a_n \\ b_0&b_1&\cdots&b_m&\cdots&0\\0&b_0&b_1&\cdots&b_m&\cdots\\\vdots&\ddots&\ddots&\ddots&\ddots&\ddots\\0&\cdots&b_0&b_1&\cdots&b_m\end{bmatrix}^T\begin{bmatrix}\Delta_1\\\Delta_2\\\vdots\\\vdots\\\vdots\\\vdots\\\vdots\\\Delta_{n,m}\end{bmatrix}=\begin{bmatrix}\Delta\\0\\0\\0\\0\\0\\0\\\vdots\\0\end{bmatrix}$$Под системой подразумевается система уравнение в виде отображения $F[X]/f(x)\oplus F[X]/g(x)\longrightarrow F[x]/f(x)g(x)$, $(p,q)\mapsto fq+gp=1$. $\Delta_i$ - это замена $i$-го столбца на вектор-столбец $\begin{bmatrix}1\\0\\\vdots\\0\end{bmatrix}$ - то, что мы хотим получить в итоге. 

**Исключение неизвестных из системы алгебраических уравнений**
1. Допустим мы решаем систему $\begin{cases}f(x,y)=0\\ g(x,y)=0\end{cases}$ над $\mathbb{C}$. Рассмотрим их как уравнения над $\mathbb{C}(x)[y]$ и запустим алгоритм Евклида. Если они не взаимно просты, то мы найдём $h(x,y)$ - из НОД. Из равенства НОДа нулю следует решение системы. А если взаимнопросты - мы найдём представление единицы в $\mathbb{C}(x)$, а по представлению линейной комбинации: $Af+Bg=R_{fg}\in\mathbb{C}[x]$. Таким образом мы свели систему из двух неизвестных в систему $R_{fg,\;Y}(x)=0$.
**Предложение**
Пусть $f,g\in \mathbb{C}[x,y]$. Тогда $$R_{fg}(\alpha)=0\;\;\Leftrightarrow\;\;(f(\alpha,y),g(\alpha,y)\text{ имеют общий корень})\;\lor\;(a_0(x)=b_0(x)=0)[1]$$**Доказательство**
1. (<=) следствие из второго условия очевидно (см. матрицу Сильвестра). Из первого тоже ($R_{fg}(\alpha)=R_{f(\alpha)g(\alpha)}$, далее тривиально)
2. (=>) Рассмотрим $f,g\in\mathbb{C}[x_1,...,x_n,S,T]$ однородный по $S,T$. Множество корней - $\mathbb{C}^n\times P(\mathbb{C})$. Рассмотрим $z(f,g)\subset (\mathbb{C}^n\times P(\mathbb{C}))$, спроектированное на $\mathbb{C}^n$. Это будет равно $z(R_{fg})$. Почему? потому что нахождение в проекции означает, что у многочленов $f_{c_1,...,c_n}(S,T),g_{c_1,...,c_n}(S,T)$, в которые подставили точку из множества $z(f,g)$, обобщив точки проективного пространства, есть общий линейный множитель. Это верно для любой точки из $z(f,g)$.
**Пояснение**
1. Это означает, что многочлены имеют общий корень на бесконечно удалённой точке проективного пространства

#TODO там ещё 5го числа была забавная лекция, первая часть которой была посвящена теории Исключений. Возможно, это имеет смысл послушать, я не пишу сейчас, потому что этого нет в билетах, а я этой сессии рот ебал и жопу тоже
## Теорема Безу о числе точек пересечения двух алгебраических кривых на проективной плоскости
**Теорема Безу** (об алгебраических кривых \[слабая форма])
Пусть имеется система $\begin{cases}f(x,y)=0\\ g(x,y)=0\end{cases}$. Где максимальная степень одночлена равна $m$ для $f$ и $n$ для $f$. Эта система задаёт кривые над полем $K^2$, $f,g\in K[x,y]$. Если $\gcd(f,g)=1$, то число общих точек (оно же - число решений) не превосходит $mn$
**Доказательство**
- Вместо $K^2$ рассмотрим проективизацию над $P(K^3)$, заменив: $\frac{X}{Z}=x,\frac{Y}{Z}=y$. $F(X,Y,Z)=Z^mf(\frac{X}{Z},\frac{Y}{Z})$. Получим однородный многочлен степени $m$. Аналогичное мероприятие проделываем с $g$. Теперь мы рассматриваем систему $\begin{cases}F(X,Y,Z)=0\\ G(X,Y,Z)=0\end{cases}$. Исключим из данной системы переменную $X$. Получим $R(Y,Z)=0$
- Доказательство с помощью матрицы Сильвестра: данная матрица от однородных многочленов однородна. В ней точкно есть член $a_0^mb_0^n$, что и определяет её размерность. Полученный многочлен раскладывается на $mn$ линейных множителей, каждый из которых задаёт точку пересечения в проективном пространстве\[1]
- Утверждается, что это однородный многочлен при условии, что $F(1,0,0)\ne0,G(1,0,0)\ne0$. Рассмотрим $F(X,Y,Z)\in K(Y,Z)[X]$. Рассмотрим $L\supset K(X,Y)$. В нём $F(X,Y,Z)=A\prod(x-\alpha_i)=A(X^m-a_1(Y,Z)X^{m-1}+a_2(Y,Z)X^{m-2}+...)$, На месте $a_i$ стоят некоторые ЭСМ\[2] степени $i$. Таким образом весь $F$ является однородным. Посмотрим на результант: $R_{FGX}=A^n\prod G(\alpha_i,Y,Z)$. Подставим вместо $\alpha_i$ независимую переменную $x_i$. В таком случае многочлен будет выглядеть как $\sum c_{kl}(x_1,...,x_m)Y^{k}Z^l=\sum d_{kl}(\sigma_1,...,\sigma_m)Y^kZ^l$. Степень $d_{kl}\overset{[3]}{=}mn-k-l$, что и требовалось
**Пояснение**
1. она же прямая, соединяющая начало координат и точку пересечения в обычном $K^2$
2. элементарные симметрические функции ($\sigma_k(\alpha_1,...,\alpha_m)$)
3. #TODO 
# Расширения полей

## Поле разложения многочлена
**Определение**
$L$ называется полем разложения многочлена $f(x)\in F[x]$, если:
1. $f$ раскладывается на линейные множители
2. $L=F[x_1,...,x_n]$.

**Предложение** (о расширении конечного гомоморфизма)
Пусть $E$ - поле, в котором $p(t)$ раскладывается на линейные множители. $L$ - поле разложения для $p(t)\in F[t]$. Пусть $F\subset K\subset L$. Тогда $\forall \gamma: K\longrightarrow E$, что $\gamma|_F=id_F$ существует продолжение $\overline\gamma: L\longrightarrow E: \overline\gamma|_K=\gamma$.
**Доказательство**
- Докажем, что существует нетривиальное расширение $K'$ и соответствующее продолжение $\gamma'$. Далее возьмём индукцию по степени до тех пор, пока степень не совпадёт с $L$.\[1]
- Допустим, что $\exists i:(\alpha_i\notin K)\land(\alpha_i\in L)$. Рассмотрим $K'=K[\alpha_i]$. Рассмотрим разложение $p(t)$ на неприводимые множители $p(t)=q_1(t)...q_n(t)$. Какой-то из них обнуляется в $\alpha$. Получим конструкцию: $L\supset K'=K[\alpha_i]\cong K[t]/q(t)$. Из последнего нам надо построить гомоморфизм в $E$.
- Строится он через кольцо $K[t]$. Очевидно, что существует инъективный комоморфизм подстановки $K[t] \underset{p(t)\mapsto p(\alpha_i)}{\longrightarrow} E$. В таком случае образ этого отображения изоморфен $K[t]/\ker I$ а на место $I$ подходит идеал от неприводимого над $K[t]$ и обнуляющегося в $\alpha_i$ многочлена. Например, $q(t)$. 
**Пояснение**
1. Если p(t) изначально раскладывался в линейные над F\[t], то толку его рассматривать не было, мы будем смотреть на отображение F -> F а если p(t) изначально не раскладывался, а потом в надполе L или E вдруг разложился, значит есть какой-то корень, которого мы не видим из F, но видим из L. Вот все такие корни, которые надо добавить, мы обозначили за $\alpha$. И их мы по индукции добираем
**Следствие**
- Если теперь вместо Е взять другое _поле разложения_. то они будут взаимозаменяемы, откуда следует изоморфность

**Теорема** (Существование поля разложения)
Очевидно. Возьмём поле, найдём максимальную степень неприводимого многочлена. Возьмём поле, добавим туда какой-то корень, чтобы дальше разложить многочлен. Выполняем это итеративно, процесс оборвётся, потому что степень многочлена уменьшается и будет или натуральной, или 1
## Количество элементов в конечном поле. Автоморфизм Фробениуса. Корни многочлена, неприводимого над Z/pZ
**Определение**
Конечное поле из $p^n$ элементов - это поле разложения $X^{p^n}-X$ над $\mathbb{Z}/p\mathbb{Z}$.

**Определение**
Пусть $R$ - комм. кольцо характеристики $p$ (простое число). Тогда **гомоморфизмом** (эндоморцизмом) **Фробениуса** называется $\text{Frob}:\;R\underset{a\mapsto a^p}{\longrightarrow} R$
Это действительно гомоморфизм: 
1. $\text{Frob }(ab)=\text{Frob }(a)\text{Frob }(b)$ очевидно
2. $\text{Frob }(a+b)=a^p+C_p^1a^{p-1}b+...+b^p$. Каждое число сочетаний делится на $p$, а потому обнуляется. Значит, $=a^p+b^p=\text{Frob }(a)+\text{Frob }(b)$

**Замечание**
Если $R$ при этом ещё и поле, то эндоморфизм обратим, а значит это - автоморфизм, потому что:
1. Любой нетривиальный гомоморфизм полей инъективен
2. Любой инъективный гомоморфизм в себя конечных множеств сюръективен

**Предложение**
Если $f\in \mathbb{Z}/p\mathbb{Z}[t]$ неприводимый многочлен степени $n$ и $\alpha\in L\supset \mathbb{Z}/p\mathbb{Z}$ корень $f$, то все корни $f(t)$ равны степеням $\alpha,\alpha^p,\alpha^{p^2},...,\alpha^{p^{n-1}}$. То есть $f=\prod(x-\alpha^{p^k})$. То есть $\mathbb{Z}/p\mathbb{Z}[\alpha]\subset L$ - поле его разложения
**Доказательство**
1. Если $\alpha$ корень, то и $\alpha^p$ тоже - $f(t)=(t-\alpha)g(t)\overset{\text{Frob}}{\longrightarrow} f(t)=(t-\alpha^p)g'(x)$
2. Раз поле конечное, то существует максимальное $l$, что все $\alpha^{p^l}$ различные. 
3. $\text{Frob }(a^{p^l})=a^k=\text{Frob }(a^{p^{k-1}})$. При $k\ge 1$. Из этого получается, что $k>l$, но $l\ge k$. То есть получилось противоречие при $k\ge1$, а так как оно нарутальное или ноль, получается, что $k=0, F(a^{p^l})=a$, то есть зацикливаемся именно на $a\rightarrow...\rightarrow a^{p^l}\rightarrow a$.
4. Из равенства многочленов в $L[t]$ после применения автоморфизма Фробениуса понятно, что все коэффициенты многочлена удовлетворяют $a^p=a$. Но тогда все они лежат в $\mathbb{Z}/p\mathbb{Z}$, как и сам многочлен в $\mathbb{Z}/p\mathbb{Z}$. Раз тогда для $f'(x)=\prod^l(x-a^{p^k})$ окажется, что он $f(t)$, а раз $f(t)$ неприводимый, то они равны. Значит это просто вопрос про размер многочлена
## Построение конечного поля из p^n элементов
**Определение**
Конечное поле из $p^n$ элементов - это поле разложения $X^{p^n}-X$ над $\mathbb{Z}/p\mathbb{Z}$.

**Теорема**
Конечное поле из $p^n$ элементов существует и единственно с точностью до изоморфизма
**Доказательство** (существование)
- Пусть $L$ - поле расширения $\mathbb{Z}/p\mathbb{Z}$, в котором $X^{p^n}-X$ разложим на линейные множители. Рассмотрим множество корней этого многочлена $K=\{g\in L:\;g^{p^n}=g\}$. Мощность этого множества равна $p^n$, потому что у данного многочлена нет кратных корней\[1]
- Также $K$ - множество неподвижных точек относительно автоморфизма $\text{Frob}^n$. Такое множество замкнуто относительно сложения, умножения и взятия обратного, то есть $K$ - подполе поля $L$.
**Доказательство** (единственность)
- Для любого поля $|E|=p^n\Rightarrow E\supset \mathbb{Z}/p\mathbb{Z}$, так как для такого поля $|E^*|=p^n-1$, то есть $g^{p^n-1}\overset{[2]}{=}1$, то есть $g^{p^n}=g$
- Это значит, что многочлен $X^{p^n}-X$ раскладывается на линейные множители, которые составляют все различные элементы данного поля, то есть $E$ - поле разложение. Тогда оно изоморфно $\mathbb{Z}/p\mathbb{Z}$.\[3]
**Пояснение**
1.  $p^n$ в обоих полях обнуляется, поэтому первый одночлен обнуляется, поэтому производная равна -1. 
2. по теореме Л-Эйлера
3. по теореме о единственности поля разложения, мы вевели это из предложения о расширении конечного гомоморфизма

**Предложение**
$|F|\;\Bigl|\;|K|\;\Leftrightarrow K\cong K'\subset F$
**Доказательство**
- (<=) очевидно, потому что тогда $|F|=|K|^r$ как векторное пространство большей размерности
- (=>) Пользуемся тем, что $K=\{g\in L:\;g^{p^k}=g\}$ подполе поля $F=\{g\in L:\;g^{p^n}=g\}$ при условии делимости. Получаем точно такое же доказательство, как и в существовании разложения.
**Следствие**
Разложение $X^{p^n}-X$ над $\mathbb{Z}/p\mathbb{Z}$ имеет вид $\prod f_i(x)$, каждый из которых неприводим над этим полем и имеет степень $d$ - делитель $n$
**Доказательство**
- Потому что выделенные таким образом мы выбираем такие $d$ корней, что формируем подполе $K=\{g\in L:\;g^{p^d}=g\}$ из них
## Мультипликативная группа конечного поля
**Теорема**
Если $A\subset E^*$ конечная подгруппа мультипликативной группы кольца, то она циклическая
**Доказательство**
- Воспользуемся следущим фактом: $n-\sum_{n|d,\;d\ne n}\varphi(d)=\varphi(n)\ge1$    \[1]
- Нужно доказать, что существует $a$ из $A,|A|=n$ получается, что $\text{ord }(a)=n$. Возьмём некоторое $a$, его порядок точно является делителем $n$. $A=\sqcup A_d$, в каждом из которых содержатся элементы с порядком $d$ (делителем $n$). Посмотрим на $A_n=A\setminus[\sqcup_{d\ne n}A_d]$, $|A_d|$ или ноль, или $\varphi(d)$.\[2]
- $|A_n|\ge n-\sum_{n|d,\;d\ne n}\varphi(d)=\varphi(n)\ge1$, то есть существует элемент порядка $n$.
**Пояснение**
1. $n=\sum_{n|d}\varphi(d)$ - формула Гаусса из т. чисел
2. Потому что ![[Pasted image 20240703024852.png]]
**Следствие**
Мультипликативная группа конечного поля циклическая, то есть $|L|=p^n\Rightarrow \exists a\in L:\;\text{ord}_{L^*}(a)=p^{n-1}$
**Следствие** (теорема о примитивном элементе)
Если $L\supset F$ конечное расширение и $F$ конечное поле, то существует $\alpha\in L:\;L=F[\alpha]$. Для доказательства просто возьмём $\langle\alpha\rangle = L^*$. 
**Cледствие**
Существует неприводимый многочлен степени $n$ над $\mathbb{Z}/p\mathbb{Z}$
**Доказательство**
- $F=\mathbb{Z}/p\mathbb{Z}$. пусть $L$ поле, $|L|=|F|^n$. Тогда $L=F[\alpha]=F[t]/p(t)$, который неприводимый. Тогда $\deg p=n$. 

![[Pasted image 20240703030815.png]]
## Нормальные расширения
**Определение**
- Для любого поля $F$ существует такое алгебраическое расширение $K$, что любой многочлен из $K[t]$ раскладывается на линейные множители. Такое поле называется **алгебраическим замыканием** поля $F$. Оно обозначается как $F^{\text{alg}}$
- Если $E\supset F$ и любой неприводимый многочлен $p\in F[t]$, имеющий хотя бы один корень в $E$, разложим в $E$ на линейные множители, то это расширение называется **нормальным**

**Теорема**
Для конечного расширения $L\supset F$ равносильны следующие условия:
1. Если $\sigma: L\longrightarrow F^{\text{alg}}$ вложение, то $\sigma(F)$ не зависит от $\sigma$
2. Для любого неприводимого многочлена из $F[t]$ из наличия корня в $L$ следует, что он распадается в $L$ там на линейные множители\[1]
3. Существует многочлен, что $L$ - его поле разложения
**Доказательство**
- (1 => 2) Пусть $\beta$ - корень $p(t)$ в $L$. Тогда $\sigma(\beta)$ - его корень в $F^{alg}$: $p(t)_{\in F^{alg}}=(t-\sigma(\beta))\prod(t-\gamma_i)$. Выполняя обратное отображение получим разложение на линейные в $L$. Это возможно, когда все полученные $\gamma\in\sigma(L)$. Вдруг он там не лежит? Тогда: $${}^{F[t]}/_{p(t)}\cong \underset{\underset{F}\uparrow}{\overset{\overset{L}\downarrow}{F[\beta]}}\overset{\beta\mapsto\gamma}\cong \underset{\underset{F}\uparrow}{F[\gamma_i]_{\subset F^{alg}}}\cong{}^{F[t]}/_{p(t)}$$По предложению о продолжении мы можем продолжить отображение $o:F[\beta]\longrightarrow F^{alg}$ до отображения $\overline{o}:L\longrightarrow F$ так, что $\overline{o}|_{F[\beta]}=o$. В таком случае образ $\gamma_i$ будет содержаться в образе $\overline{o}$. Но тогда (по независимости образа от выбора отображения) он есть и в исходном $\sigma$
- (2=>3) $L=F[\alpha_1,...,\alpha_n]$, где каждый добавленный элемент алгебраический. Очевидно, что можно найти такой $p_i(t)\in F[t]\longrightarrow F[\alpha_i]$, что он будет иметь корень в $L$\[2]. Тогда, по условию два, этот многочлен разложим на линейные над $L$. Берём все такие $p_i(t)$ и перемножаем. Получим многочлен, для которого $L$ - поле разложения
- (3 => 1) Рассмотрим $p(t)$ с корнями $\alpha_1,...,\alpha_k\in L=F[\alpha_1,...,\alpha_k]$. Зададим $\sigma$. Рассмотрим многочлен одновременно как переведённый в $F^{alg}$ через $\sigma$ и как уже находившийся там. $$\prod(t-\sigma(\alpha_i))=\prod(t-\beta(i))$$Отсюда и получается, что вне зависимости от выбора $\sigma$, образ один - $F[\beta_1,...,\beta_k]$
**Пояснение**
1. То есть расширение нормальное
2. Потому что базис от этой альфы имеет определённую размерность, выше которой существует ЛК, дающая ноль

**Примеры**
- ${\mathbb{Q}[\sqrt2]}\supset\mathbb{Q}$ - нормальное, ${\mathbb{Q}[\sqrt[3]{2}]}\supset\mathbb{Q}$ - нет

_____
Ещё нормальные
![[Pasted image 20240703074119.png]]

____

## Существование автоморфизма, переводящего один корень многочлена в другой. Примеры вычисления групп автоморфизмов
**Лемма**
Если $L$ - нормальное расширение, $\alpha,\beta$ - корни $p(t)$ в $L$. Тогда существует автоморфизм $w:L\longrightarrow L$, "переводящий $\alpha$ в $\beta$" 
**Доказательство**
$$L\longleftarrow F[\alpha]\cong F[\beta] \longrightarrow L$$В оба данных многочлена от корней мы приходим из $F$. 

____
Там есть ещё одна теорема, я пока не буду её трогать, надеюсь, меня Пименом не отпиздит за это. Теоремка начинается в саааааааааааамом конце слайда 14may и кончается на слайде 
general9. В одну строчку такая. Слушай, она кажется просто сломалась...
![[Pasted image 20240703071843.png]]
![[Pasted image 20240703071923.png]]
____

**Определение**
- Эти автоморфизмы, очевидно, образуют **группу автоморфизмов**
- Пусть $q\in F[t]$, $L$ - поле его разложения, $q$ не имеет кратных корней ($\gcd(q,q')=1$), $\deg q = n$. Тогда $L=F[\alpha_1,....,\alpha_n]$ от его корней. Группа автоморфизмов на расширении $F\supset L$, образованная как подгруппа перестановок корней этого многочлена, называется **группой Галуа** многочлена $q$. Важно, что переставляются именно корни многочлена. Вычислить группу - это значит найти подмножество $S_n$, образующее группу Галуа
- Она же - группа всех автоморфизмов поля $K$, сохраняющих элементы поля $P$: $\forall a\in P:\; f(a)=a$. Обычно обозначается как $G(K, P)$ или $Gal(K, P)$.

**Примеры вычисления групп автоморфизмов**
1. 
   - Пусть $k$ - поле, $\text{char } k = 0$ Пусть $k(X_1,...,X_n)=L$, $k(\sigma_1,...,\sigma_n)=F$. \[1]. Группой $S_n$ зададим перестановку переменных на $L$.
   - Утверждение: $L$ - поле разложения над $F$. Это следует из теоремы Виета: после раскрытия многочлена $t^n-\sigma_1 t^{n-1}+...=\prod(t-x_i)$. Количество автоморфизмов - $n!$
2. 
   - Рассмотрим $\mathbb{Q}[\xi_p], p$ простое (это комплексный корень из единицы). Это корень многочлена $t^{p-1}+t^{p-2}+...+t+1$. По критерию Эйзенштейна он неприводим и над $\mathbb{Z}$, и над $\mathbb{Q}$. Это нормальное расширение степери $p-1$.
   - Перевод может произойти в любой другой корень многочлена. А это, в свою очередь, любой другой корень из единицы. Тогда выполняется ряд простых свойств: $\sigma_k(\xi)=\xi^k, \;\sigma_k(\xi^i)=\xi^{ki}, \;(\sigma_k\circ\sigma_l)=\sigma_{kl}$. Таким образом получаем соответствие между мультипликативной группой $(\mathbb{Z}/p\mathbb{Z})^*$ и множеством автоморфизмов перевода координат
**Пояснение**
1. Поле инвариантов (что бы это не значило)

## Линейные реккуренты над конечным полем $F_{p^n}$
**Теорема**
Любая рекуррентная последовательность над конечным полем переодична
**Доказательство**
- Каждая такая последовательность задаётся отображением $\psi:\;F^m\longrightarrow F$.  Тогда её рекуррентность равнозначна тому, что существует период: $\psi(...)=v_k=v_l=\psi(...),\;k\ne l$, что очевидно из конечности поля. 
- Последовательность периода $n$ - это ЛРС с характеристическим многочленом $T^n-1$.
- Пусть многочлен $p(t)$ неприводим над $F$. Тогда длина периода равна или $\min n:\; T^n-1|p(t)$, или $ord_{L^*}\alpha;\;\; \alpha$ это корень из расшинения
- Если $t^n-1|p(t)$, то $n$ - период является периодом $a_k$.









